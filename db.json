{"meta":{"version":1,"warehouse":"4.0.0"},"models":{"Asset":[{"_id":"themes/hexo-theme-matery/source/favicon.png","path":"favicon.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/css/gitment.css","path":"css/gitment.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/css/my-gitalk.css","path":"css/my-gitalk.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/css/matery.css","path":"css/matery.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/css/my.css","path":"css/my.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/js/matery.js","path":"js/matery.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/js/search.js","path":"js/search.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/avatar.jpg","path":"medias/avatar.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/comment_bg.png","path":"medias/comment_bg.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/cover.jpg","path":"medias/cover.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/icp.png","path":"medias/icp.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/logo.png","path":"medias/logo.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/animate/animate.min.css","path":"libs/animate/animate.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/aos/aos.css","path":"libs/aos/aos.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/aos/aos.js","path":"libs/aos/aos.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/aplayer/APlayer.min.css","path":"libs/aplayer/APlayer.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/aplayer/APlayer.min.js","path":"libs/aplayer/APlayer.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/codeBlock/codeBlockFuction.js","path":"libs/codeBlock/codeBlockFuction.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/codeBlock/codeCopy.js","path":"libs/codeBlock/codeCopy.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/codeBlock/codeLang.js","path":"libs/codeBlock/codeLang.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/codeBlock/codeShrink.js","path":"libs/codeBlock/codeShrink.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/background/canvas-nest.js","path":"libs/background/canvas-nest.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/background/ribbon-dynamic.js","path":"libs/background/ribbon-dynamic.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/background/ribbon-refresh.min.js","path":"libs/background/ribbon-refresh.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/background/ribbon.min.js","path":"libs/background/ribbon.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/cryptojs/crypto-js.min.js","path":"libs/cryptojs/crypto-js.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/dplayer/DPlayer.min.css","path":"libs/dplayer/DPlayer.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/dplayer/DPlayer.min.js","path":"libs/dplayer/DPlayer.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/echarts/echarts.min.js","path":"libs/echarts/echarts.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/jqcloud/jqcloud-1.0.4.min.js","path":"libs/jqcloud/jqcloud-1.0.4.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/jqcloud/jqcloud.css","path":"libs/jqcloud/jqcloud.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/gitalk/gitalk.css","path":"libs/gitalk/gitalk.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/gitalk/gitalk.min.js","path":"libs/gitalk/gitalk.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/gitment/gitment-default.css","path":"libs/gitment/gitment-default.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/gitment/gitment.js","path":"libs/gitment/gitment.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/instantpage/instantpage.js","path":"libs/instantpage/instantpage.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/jquery/jquery.min.js","path":"libs/jquery/jquery.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/masonry/masonry.pkgd.min.js","path":"libs/masonry/masonry.pkgd.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/materialize/materialize.min.css","path":"libs/materialize/materialize.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/materialize/materialize.min.js","path":"libs/materialize/materialize.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/others/busuanzi.pure.mini.js","path":"libs/others/busuanzi.pure.mini.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/others/clicklove.js","path":"libs/others/clicklove.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/scrollprogress/scrollProgress.min.js","path":"libs/scrollprogress/scrollProgress.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/tocbot/tocbot.css","path":"libs/tocbot/tocbot.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/tocbot/tocbot.min.js","path":"libs/tocbot/tocbot.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/valine/Valine.min.js","path":"libs/valine/Valine.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/valine/av-min.js","path":"libs/valine/av-min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/banner/0.jpg","path":"medias/banner/0.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/banner/1.jpg","path":"medias/banner/1.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/banner/2.jpg","path":"medias/banner/2.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/banner/3.jpg","path":"medias/banner/3.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/banner/4.jpg","path":"medias/banner/4.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/banner/5.jpg","path":"medias/banner/5.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/banner/6.jpg","path":"medias/banner/6.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/0.jpg","path":"medias/featureimages/0.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/1.jpg","path":"medias/featureimages/1.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/10.jpg","path":"medias/featureimages/10.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/11.jpg","path":"medias/featureimages/11.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/12.jpg","path":"medias/featureimages/12.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/13.jpg","path":"medias/featureimages/13.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/14.jpg","path":"medias/featureimages/14.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/15.jpg","path":"medias/featureimages/15.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/16.jpg","path":"medias/featureimages/16.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/17.jpg","path":"medias/featureimages/17.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/18.jpg","path":"medias/featureimages/18.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/19.jpg","path":"medias/featureimages/19.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/2.jpg","path":"medias/featureimages/2.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/20.jpg","path":"medias/featureimages/20.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/21.jpg","path":"medias/featureimages/21.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/22.jpg","path":"medias/featureimages/22.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/23.jpg","path":"medias/featureimages/23.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/3.jpg","path":"medias/featureimages/3.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/4.jpg","path":"medias/featureimages/4.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/5.jpg","path":"medias/featureimages/5.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/6.jpg","path":"medias/featureimages/6.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/7.jpg","path":"medias/featureimages/7.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/8.jpg","path":"medias/featureimages/8.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/9.jpg","path":"medias/featureimages/9.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/reward/wechat.png","path":"medias/reward/wechat.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/css/all.css","path":"libs/awesome/css/all.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-brands-400.eot","path":"libs/awesome/webfonts/fa-brands-400.eot","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-brands-400.svg","path":"libs/awesome/webfonts/fa-brands-400.svg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-brands-400.ttf","path":"libs/awesome/webfonts/fa-brands-400.ttf","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-brands-400.woff","path":"libs/awesome/webfonts/fa-brands-400.woff","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-brands-400.woff2","path":"libs/awesome/webfonts/fa-brands-400.woff2","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-regular-400.svg","path":"libs/awesome/webfonts/fa-regular-400.svg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-regular-400.eot","path":"libs/awesome/webfonts/fa-regular-400.eot","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-regular-400.woff","path":"libs/awesome/webfonts/fa-regular-400.woff","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-regular-400.ttf","path":"libs/awesome/webfonts/fa-regular-400.ttf","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-regular-400.woff2","path":"libs/awesome/webfonts/fa-regular-400.woff2","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-solid-900.svg","path":"libs/awesome/webfonts/fa-solid-900.svg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-solid-900.ttf","path":"libs/awesome/webfonts/fa-solid-900.ttf","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-solid-900.eot","path":"libs/awesome/webfonts/fa-solid-900.eot","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-solid-900.woff","path":"libs/awesome/webfonts/fa-solid-900.woff","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-solid-900.woff2","path":"libs/awesome/webfonts/fa-solid-900.woff2","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/css/lightgallery.min.css","path":"libs/lightGallery/css/lightgallery.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/fonts/lg.eot","path":"libs/lightGallery/fonts/lg.eot","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/fonts/lg.svg","path":"libs/lightGallery/fonts/lg.svg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/fonts/lg.ttf","path":"libs/lightGallery/fonts/lg.ttf","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/fonts/lg.woff","path":"libs/lightGallery/fonts/lg.woff","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/img/loading.gif","path":"libs/lightGallery/img/loading.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/img/video-play.png","path":"libs/lightGallery/img/video-play.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/img/vimeo-play.png","path":"libs/lightGallery/img/vimeo-play.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/img/youtube-play.png","path":"libs/lightGallery/img/youtube-play.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/js/lightgallery-all.min.js","path":"libs/lightGallery/js/lightgallery-all.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/share/css/share.min.css","path":"libs/share/css/share.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/share/fonts/iconfont.svg","path":"libs/share/fonts/iconfont.svg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/share/fonts/iconfont.eot","path":"libs/share/fonts/iconfont.eot","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/share/fonts/iconfont.woff","path":"libs/share/fonts/iconfont.woff","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/share/fonts/iconfont.ttf","path":"libs/share/fonts/iconfont.ttf","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/share/js/social-share.min.js","path":"libs/share/js/social-share.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/share/js/jquery.share.min.js","path":"libs/share/js/jquery.share.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/wisesky.jpg","path":"medias/wisesky.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/reward/alipay.png","path":"medias/reward/alipay.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/ACG/1.jpg","path":"medias/ACG/1.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/ACG/2.jpg","path":"medias/ACG/2.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/ACG/3.jpg","path":"medias/ACG/3.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/ACG/4.jpg","path":"medias/ACG/4.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/ACG/5.jpg","path":"medias/ACG/5.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/ACG/6.jpg","path":"medias/ACG/6.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/ACG/7.jpg","path":"medias/ACG/7.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/ACG/8.jpg","path":"medias/ACG/8.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/ACG/9.jpg","path":"medias/ACG/9.jpg","modified":0,"renderable":1}],"Cache":[{"_id":"source/_posts/hello-world.md","hash":"8b7386961fcf8a46dc6cc34fa9d7422c423b08aa","modified":1602577934454},{"_id":"source/tags/index.md","hash":"6c223043ba32b7c76c33eafceeff9ed879520bfb","modified":1602576798016},{"_id":"source/about/index.md","hash":"48622c880dbd4a56f3346b15c7dc5c36d5e4239b","modified":1602570937056},{"_id":"source/categories/index.md","hash":"03ecf6ae4723c42f6eef84663eb50841513e4b62","modified":1602576755198},{"_id":"themes/hexo-theme-matery/.gitignore","hash":"727607929a51db7ea10968f547c26041eee9cfff","modified":1602570653689},{"_id":"themes/hexo-theme-matery/LICENSE","hash":"7df059597099bb7dcf25d2a9aedfaf4465f72d8d","modified":1602570653689},{"_id":"themes/hexo-theme-matery/README.md","hash":"56299cf1fe60a11fef61b3948fe148f995df747e","modified":1602570653690},{"_id":"themes/hexo-theme-matery/layout/404.ejs","hash":"9c8ca67377211e5d60fdde272a975faa9a91a22a","modified":1602570653691},{"_id":"themes/hexo-theme-matery/README_CN.md","hash":"0fdf818476a444663cc8ffa2f194199d9fd93508","modified":1602570653690},{"_id":"themes/hexo-theme-matery/_config.yml","hash":"9440d60860d7823cb6193934528caedb8ace2939","modified":1606210030449},{"_id":"themes/hexo-theme-matery/layout/archive.ejs","hash":"cdac701de8370f9f3794a0eed4165983993a1ca7","modified":1602570653697},{"_id":"themes/hexo-theme-matery/layout/about.ejs","hash":"41849f9300b8dc47048333fcf4a897dd8a2a13ca","modified":1602570653697},{"_id":"themes/hexo-theme-matery/layout/contact.ejs","hash":"72fb5af3fc2f8955e2eb10926bbe4532a04ccd1b","modified":1602570653698},{"_id":"themes/hexo-theme-matery/layout/category.ejs","hash":"00019bca11fb46477f22017cb1f5ad8444da0580","modified":1602570653698},{"_id":"themes/hexo-theme-matery/layout/categories.ejs","hash":"8e54665cc25d7c333da7d9f312987190be6215da","modified":1602570653697},{"_id":"themes/hexo-theme-matery/layout/friends.ejs","hash":"f5d6459bed0f4ecb214f2dbff5b2207a80c44f66","modified":1602570653698},{"_id":"themes/hexo-theme-matery/layout/index.ejs","hash":"4dc6f08e7709cc04e886be72dbf0d06469f0effc","modified":1602570653698},{"_id":"themes/hexo-theme-matery/layout/tag.ejs","hash":"85a4b05bd8a6ad0f17ff2e97dae56949b379c204","modified":1602570653699},{"_id":"themes/hexo-theme-matery/layout/post.ejs","hash":"90b5a4c1f70e4756db569c15a7c6cad0c77c4500","modified":1602570653699},{"_id":"themes/hexo-theme-matery/layout/tags.ejs","hash":"cf9517aa6a0111355121f44615d6923e312283c7","modified":1602570653699},{"_id":"themes/hexo-theme-matery/languages/default.yml","hash":"54ccc01b097c5bf6820f0edfcece1a87b78ab32d","modified":1602570653690},{"_id":"themes/hexo-theme-matery/layout/layout.ejs","hash":"746abd6bec5ed42bfeb54575fa613d38fb19fe96","modified":1602570653698},{"_id":"themes/hexo-theme-matery/languages/zh-CN.yml","hash":"ec0c18fb0e3ab3ee44268dc2b44fc832cffe3c1b","modified":1602580129662},{"_id":"themes/hexo-theme-matery/languages/zh-HK.yml","hash":"ae34ac0e175c3037675722e436637efbceea32f0","modified":1602570653691},{"_id":"themes/hexo-theme-matery/layout/_partial/back-top.ejs","hash":"47ee36a042bb6d52bbe1d0f329637e8ffcf1d0aa","modified":1602570653691},{"_id":"themes/hexo-theme-matery/source/favicon.png","hash":"774fee8c6d0be9dbb010b20f36c06848d06e3da0","modified":1602570653700},{"_id":"themes/hexo-theme-matery/layout/_partial/background.ejs","hash":"aef6edeeb11209831a11d8c7f5d59992e2573335","modified":1602570653691},{"_id":"themes/hexo-theme-matery/layout/_partial/baidu-push.ejs","hash":"2cebcc5ea3614d7f76ec36670e68050cbe611202","modified":1602570653691},{"_id":"themes/hexo-theme-matery/layout/_partial/bg-cover.ejs","hash":"02191109712f61c0e487b8f0b8466597181a9004","modified":1602570653692},{"_id":"themes/hexo-theme-matery/layout/_partial/bg-cover-content.ejs","hash":"28617bf2a35a4269eba6df466acd174e416d2d1e","modified":1602570653691},{"_id":"themes/hexo-theme-matery/layout/_partial/baidu-analytics.ejs","hash":"3bbcdb474ca1dcad514bdc4b7763e17c55df04fd","modified":1602570653691},{"_id":"themes/hexo-theme-matery/layout/_partial/disqus.ejs","hash":"b2dc2c8b5ed56815e55cc2ea54a6dc4eeba2375d","modified":1602570653692},{"_id":"themes/hexo-theme-matery/layout/_partial/gitalk.ejs","hash":"2aa8fbb04b046fa7679092a48372d7e036835dff","modified":1602570653692},{"_id":"themes/hexo-theme-matery/layout/_partial/github-link.ejs","hash":"3aeb581bd78ab8e15b858e4c44c03bcf92f20b9e","modified":1602570653692},{"_id":"themes/hexo-theme-matery/layout/_partial/gitment.ejs","hash":"90f6218512ef2eab63ada7ad2fc766ae635a2297","modified":1602570653692},{"_id":"themes/hexo-theme-matery/layout/_partial/footer.ejs","hash":"4b5476478ba12183b7c97a33d5545fc53be362a8","modified":1602570653692},{"_id":"themes/hexo-theme-matery/layout/_partial/google-analytics.ejs","hash":"5f4992205617da5f8cc5863c62b5ec46e414e2fb","modified":1602570653692},{"_id":"themes/hexo-theme-matery/layout/_partial/head.ejs","hash":"8d263ebccccd0f9e69539f402955296de6f24a62","modified":1602570653692},{"_id":"themes/hexo-theme-matery/layout/_partial/header.ejs","hash":"59e38c70f3d8e7165e686e5e84a627835f4321b0","modified":1602570653693},{"_id":"themes/hexo-theme-matery/layout/_partial/index-cover.ejs","hash":"76b4a37e0364380b143fdf94bf1a5e6941564414","modified":1602570653693},{"_id":"themes/hexo-theme-matery/layout/_partial/livere.ejs","hash":"9c3401b42ea7f26410a5593bae93ada7e57b43be","modified":1602570653693},{"_id":"themes/hexo-theme-matery/layout/_partial/minivaline.ejs","hash":"5f09386aece8f9cf31f6059bbde79cd6c5171493","modified":1602570653693},{"_id":"themes/hexo-theme-matery/layout/_partial/navigation.ejs","hash":"78b70ff24b3039c871331ebec114b936c1756cc8","modified":1602570653693},{"_id":"themes/hexo-theme-matery/layout/_partial/paging.ejs","hash":"e2df12cf92a82b1a7a7add2eac1db1d954bc5511","modified":1602570653693},{"_id":"themes/hexo-theme-matery/layout/_partial/post-cover.ejs","hash":"d1c873c5de54498c722e155aadb8c0ec39485dfa","modified":1602570653693},{"_id":"themes/hexo-theme-matery/layout/_partial/post-detail-toc.ejs","hash":"a8c9abd8cf806235cadb087a5acca3f9182b76ea","modified":1602570653694},{"_id":"themes/hexo-theme-matery/layout/_partial/post-statis.ejs","hash":"04889f9031743c6b081d02fa4027b0dbfcc45ecf","modified":1602570653694},{"_id":"themes/hexo-theme-matery/layout/_partial/mobile-nav.ejs","hash":"cb0cb452be1cd1857ba600f04025b506f3b6fc79","modified":1602570653693},{"_id":"themes/hexo-theme-matery/layout/_partial/prev-next.ejs","hash":"c76b78782ea82340104fccc089417572e0adece4","modified":1602570653694},{"_id":"themes/hexo-theme-matery/layout/_partial/reprint-statement.ejs","hash":"0ce3f9361f558b99cc2f059c5e50b0e2a152ae38","modified":1602570653694},{"_id":"themes/hexo-theme-matery/layout/_partial/post-detail.ejs","hash":"d05926e79aa6dfc235193b9d8c6aa03118b0eade","modified":1602570653694},{"_id":"themes/hexo-theme-matery/layout/_partial/reward.ejs","hash":"ffc55bc7e73bc698bfc58d8e3780c336b83282cf","modified":1602570653694},{"_id":"themes/hexo-theme-matery/layout/_partial/share.ejs","hash":"c941730a2471d6aab367cbb6e09ed08b56c83143","modified":1602570653695},{"_id":"themes/hexo-theme-matery/layout/_partial/search.ejs","hash":"b09872f69c962cb6dd9d4050a322fdea94903f84","modified":1602570653694},{"_id":"themes/hexo-theme-matery/layout/_partial/social-link.ejs","hash":"6f871bd3a70f720e4e451f1f4f625cbc6d8994a4","modified":1602570653695},{"_id":"themes/hexo-theme-matery/layout/_widget/artitalk.ejs","hash":"b14e486f12b9ac42a273b80e4d785fcb94cf04b2","modified":1602570653695},{"_id":"themes/hexo-theme-matery/layout/_partial/valine.ejs","hash":"0e4c0a6154aa34007849928ca88f05b6185b256e","modified":1602570653695},{"_id":"themes/hexo-theme-matery/layout/_widget/category-radar.ejs","hash":"1d8747fda89a0b2ca3c7008867cbfeecad0578a6","modified":1602570653696},{"_id":"themes/hexo-theme-matery/layout/_widget/music.ejs","hash":"e9e3e327d5de9d7aeadbde32e1d558652d9e9195","modified":1602570653696},{"_id":"themes/hexo-theme-matery/layout/_widget/category-cloud.ejs","hash":"1b3df1009234c0112424b497b18b4ad8240b3bc7","modified":1602570653696},{"_id":"themes/hexo-theme-matery/layout/_widget/my-gallery.ejs","hash":"65a2d2f9722f84c7fd98f6bdf79087a14848ebd8","modified":1602570653696},{"_id":"themes/hexo-theme-matery/layout/_widget/dream.ejs","hash":"9a472ad5591100cdb65d0df9d01034163bd6dd9d","modified":1602570653696},{"_id":"themes/hexo-theme-matery/layout/_widget/my-projects.ejs","hash":"ef60b64021fa349b0048425d858dfcf6c906fede","modified":1602570653696},{"_id":"themes/hexo-theme-matery/layout/_widget/my-skills.ejs","hash":"89a0092df72d23093128f2fbbdc8ca7f83ebcfd9","modified":1602570653696},{"_id":"themes/hexo-theme-matery/layout/_widget/post-calendar.ejs","hash":"48821e644bc73553d7c5c56d2e8ee111a70cd776","modified":1602570653696},{"_id":"themes/hexo-theme-matery/layout/_widget/post-charts.ejs","hash":"ab5f986f428215941aeaa0c88aefd440c47d3bcf","modified":1602570653697},{"_id":"themes/hexo-theme-matery/layout/_widget/recommend.ejs","hash":"8551137e94ca4e2e3b8b63d5626255884cb60cb5","modified":1602570653697},{"_id":"themes/hexo-theme-matery/layout/_widget/tag-cloud.ejs","hash":"fc42b72cddc231f7485cdc1fd6852b66be6add26","modified":1602570653697},{"_id":"themes/hexo-theme-matery/layout/_widget/tag-wordcloud.ejs","hash":"487aacb2454d6bf0d21cdb07ddd1fd5ddbca9038","modified":1602570653697},{"_id":"themes/hexo-theme-matery/layout/_widget/video.ejs","hash":"a0e002377af2a7f7e4da6d9a644de97adb035925","modified":1602570653697},{"_id":"themes/hexo-theme-matery/source/css/gitment.css","hash":"2bd15cc17dca35ac3ecc0acf167a23a1dd362acd","modified":1602570653699},{"_id":"themes/hexo-theme-matery/source/css/my-gitalk.css","hash":"eeda46a83d0db1cc239a9cd27d544faf663f9883","modified":1602570653700},{"_id":"themes/hexo-theme-matery/source/css/matery.css","hash":"87bd1dacf48c9daab7ea43466368247f1e4107d1","modified":1602570653700},{"_id":"themes/hexo-theme-matery/source/css/my.css","hash":"10577fbc30f241b126d1b51b1f56136ecba86b19","modified":1602570653700},{"_id":"themes/hexo-theme-matery/source/js/matery.js","hash":"b86de5fe3e9766b7ff80df12ea41c3a9e30825f7","modified":1602570653700},{"_id":"themes/hexo-theme-matery/source/js/search.js","hash":"d559d402b4d4a0931821fe6e22a8831fc43a953d","modified":1602570653700},{"_id":"themes/hexo-theme-matery/source/medias/avatar.jpg","hash":"2a6287308628881ce27b9a7de53ba15c2be00d02","modified":1602570653748},{"_id":"themes/hexo-theme-matery/source/medias/icp.png","hash":"27a96f31f7d0413c6ade6f40e06f021f501151c7","modified":1602570653776},{"_id":"themes/hexo-theme-matery/source/medias/comment_bg.png","hash":"dfc93d24081884fbc58cab0f8fd19e77d31d6123","modified":1602570653758},{"_id":"themes/hexo-theme-matery/source/medias/logo.png","hash":"d9095f5ea8719374d9d1ff020279426f5b2a1396","modified":1602570653776},{"_id":"themes/hexo-theme-matery/source/libs/aos/aos.css","hash":"191a3705a8f63e589a50a0ff2f2c5559f1a1b6b2","modified":1602570653701},{"_id":"themes/hexo-theme-matery/source/libs/animate/animate.min.css","hash":"97afa151569f046b2e01f27c1871646e9cd87caf","modified":1602570653701},{"_id":"themes/hexo-theme-matery/source/libs/aos/aos.js","hash":"02bfb40b0c4b6e9b0b4081218357145cbb327d74","modified":1602570653701},{"_id":"themes/hexo-theme-matery/source/libs/aplayer/APlayer.min.css","hash":"07372a2ba507388d0fed166d761b1c2c2a659dce","modified":1602570653702},{"_id":"themes/hexo-theme-matery/source/libs/aplayer/APlayer.min.js","hash":"22caa28ff6b41a16ff40f15d38f1739e22359478","modified":1602570653702},{"_id":"themes/hexo-theme-matery/source/libs/codeBlock/codeBlockFuction.js","hash":"c7ab06d27a525b15b1eb69027135269e9b9132fb","modified":1602570653727},{"_id":"themes/hexo-theme-matery/source/libs/codeBlock/codeCopy.js","hash":"6d39a766af62e625f177c4d5cf3adc35eed71e61","modified":1602570653727},{"_id":"themes/hexo-theme-matery/source/libs/codeBlock/codeLang.js","hash":"bac88b4d4e3679732d29bd037c34f089cf27cf05","modified":1602570653727},{"_id":"themes/hexo-theme-matery/source/libs/codeBlock/codeShrink.js","hash":"201e8cd761b4be557247bdaf1ebc7c11c83194f6","modified":1602570653727},{"_id":"themes/hexo-theme-matery/source/libs/background/canvas-nest.js","hash":"65333d0dbb9c1173a1b13031b230161fc42c8b2f","modified":1602570653726},{"_id":"themes/hexo-theme-matery/source/libs/background/ribbon-dynamic.js","hash":"052b80c29e6bc585aa28d4504b743bdbac220a88","modified":1602570653726},{"_id":"themes/hexo-theme-matery/source/libs/background/ribbon-refresh.min.js","hash":"6d98692b2cad8c746a562db18b170b35c24402f4","modified":1602570653726},{"_id":"themes/hexo-theme-matery/source/libs/background/ribbon.min.js","hash":"6a99d494c030388f96f6086a7aaa0f03f3fe532e","modified":1602570653727},{"_id":"themes/hexo-theme-matery/source/libs/cryptojs/crypto-js.min.js","hash":"5989527a378b55011a59522f41eeb3981518325c","modified":1602570653728},{"_id":"themes/hexo-theme-matery/source/libs/jqcloud/jqcloud-1.0.4.min.js","hash":"257eaae3020599e4939f50d5008a743827f25b8c","modified":1602570653738},{"_id":"themes/hexo-theme-matery/source/libs/dplayer/DPlayer.min.css","hash":"f7d19655f873b813ffba5d1a17145c91f82631b8","modified":1602570653728},{"_id":"themes/hexo-theme-matery/source/libs/jqcloud/jqcloud.css","hash":"20d9f11a19d95c70e27cb922e0d6dccbec4eae89","modified":1602570653738},{"_id":"themes/hexo-theme-matery/source/libs/gitment/gitment-default.css","hash":"2903c59ee06b965bef32e937bd69f5b0b2190717","modified":1602570653737},{"_id":"themes/hexo-theme-matery/source/libs/gitalk/gitalk.css","hash":"940ded3ea12c2fe1ab0820d2831ec405f3f1fe9f","modified":1602570653735},{"_id":"themes/hexo-theme-matery/source/libs/instantpage/instantpage.js","hash":"83ce8919b1a69b2f1809ffaf99b52a8627e650e9","modified":1602570653738},{"_id":"themes/hexo-theme-matery/source/libs/masonry/masonry.pkgd.min.js","hash":"ff940b4ea68368ca0e4d5560cbb79fb147dfc3c5","modified":1602570653741},{"_id":"themes/hexo-theme-matery/source/libs/others/busuanzi.pure.mini.js","hash":"6e41f31100ae7eb3a6f23f2c168f6dd56e7f7a9a","modified":1602570653743},{"_id":"themes/hexo-theme-matery/source/libs/others/clicklove.js","hash":"6a39b8c683ba5dcd92f70c6ab45d1cfac3213e8e","modified":1602570653743},{"_id":"themes/hexo-theme-matery/source/libs/scrollprogress/scrollProgress.min.js","hash":"777ffe5d07e85a14fbe97d846f45ffc0087251cc","modified":1602570653743},{"_id":"themes/hexo-theme-matery/source/libs/tocbot/tocbot.css","hash":"9ab8ef576c9a57115194152e79cca79b0a41dd70","modified":1602570653746},{"_id":"themes/hexo-theme-matery/source/libs/tocbot/tocbot.min.js","hash":"5ec27317f0270b8cf6b884c6f12025700b9a565c","modified":1602570653746},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/10.jpg","hash":"98e7f6fd9c97d4de9044b6871ca08ebf14db11b9","modified":1602570653761},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/13.jpg","hash":"35a320174f8e316e3eadaec658024276b651c6e9","modified":1602570653765},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/15.jpg","hash":"da0fbee3b7bde1607eace377ddf834c0be99edfe","modified":1602570653766},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/16.jpg","hash":"97a829c4bc94f9d2929b20a1a9b798c57b9f7205","modified":1602570653766},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/2.jpg","hash":"4bba691cf71a517ecaeaf42afd3e8f8b31e346c1","modified":1602570653768},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/21.jpg","hash":"b26edb128bb0bf58b23fd2f014e9555e89a2ca3b","modified":1602570653770},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/22.jpg","hash":"754579747a3e99747d890fca3162f370b96a7941","modified":1602570653770},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/23.jpg","hash":"7d7f37da3fa7128343adac23866449eb2c6a549a","modified":1602570653771},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/3.jpg","hash":"6ec646c2a70f5f11edacf225c1477f2200a37a96","modified":1602570653771},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/5.jpg","hash":"41ca20129a37fedc573eec28dd7d7b9e5b09228a","modified":1602570653773},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/7.jpg","hash":"7975141cd64e875122c0ea33daaca1a06bf00b8e","modified":1602570653774},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/8.jpg","hash":"8e4b7186352085483ca1174c7c0800114c48df8b","modified":1602570653775},{"_id":"themes/hexo-theme-matery/source/medias/reward/alipay.jpg","hash":"1abc719b95d1b26f1f898e6b0a9b7609146e332f","modified":1602570653777},{"_id":"themes/hexo-theme-matery/source/medias/reward/wechat.png","hash":"f1c84ceb948d0876b5ec7d4d55b654ef3f5132e1","modified":1602577429437},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-regular-400.woff","hash":"59439d3ad31d856d78ec3e2bd9f1eafa2c7a581c","modified":1602570653716},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-regular-400.eot","hash":"439c8afd3373acb4a73135a34e220464a89cd5e2","modified":1602570653713},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-regular-400.ttf","hash":"0f4bd02942a54a6b3200d9078adff88c2812e751","modified":1602570653716},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-regular-400.woff2","hash":"f6f653b4ea8fc487bdb590d39d5a726258a55f40","modified":1602570653717},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/fonts/lg.eot","hash":"54caf05a81e33d7bf04f2e420736ce6f1de5f936","modified":1602570653739},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/css/lightgallery.min.css","hash":"1b7227237f9785c66062a4811508916518e4132c","modified":1602570653739},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/fonts/lg.ttf","hash":"f6421c0c397311ae09f9257aa58bcd5e9720f493","modified":1602570653740},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/fonts/lg.svg","hash":"9c6632aeec67d3e84a1434884aa801514ff8103b","modified":1602570653739},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/fonts/lg.woff","hash":"3048de344dd5cad4624e0127e58eaae4b576f574","modified":1602570653740},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/img/loading.gif","hash":"15a76af2739482d8de7354abc6d8dc4fca8d145e","modified":1602570653740},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/img/video-play.png","hash":"2962e03ddbe04d7e201a5acccac531a2bbccddfc","modified":1602570653740},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/img/youtube-play.png","hash":"f8d11384d33b7a79ee2ba8d522844f14d5067a80","modified":1602570653740},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/img/vimeo-play.png","hash":"9b72fc0f86a01467ed0b68c9cc4d604ec316d517","modified":1602570653740},{"_id":"themes/hexo-theme-matery/source/libs/share/css/share.min.css","hash":"8a778a86f3ce9a042df6be63a9f1039631e351a5","modified":1602570653744},{"_id":"themes/hexo-theme-matery/source/libs/share/fonts/iconfont.svg","hash":"1d56c9d5db0273f07c43cc1397e440f98ba7827a","modified":1602570653744},{"_id":"themes/hexo-theme-matery/source/libs/share/fonts/iconfont.eot","hash":"00ff749c8e202401190cc98d56087cdda716abe4","modified":1602570653744},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/js/lightgallery-all.min.js","hash":"9f5ef4bc8a0a3c746ca4f3c3e6d64493b1a977d8","modified":1602570653741},{"_id":"themes/hexo-theme-matery/source/libs/share/js/social-share.min.js","hash":"a3090a02786dcd4efc6355c1c1dc978add8d6827","modified":1602570653746},{"_id":"themes/hexo-theme-matery/source/libs/share/fonts/iconfont.woff","hash":"2e3fce1dcfbd6e2114e7bfbeaf72d3c62e15a1bd","modified":1602570653745},{"_id":"themes/hexo-theme-matery/source/libs/share/fonts/iconfont.ttf","hash":"afd898f59d363887418669520b24d175f966a083","modified":1602570653745},{"_id":"themes/hexo-theme-matery/source/libs/share/js/jquery.share.min.js","hash":"41367dcb857e02e3c417ebe68a554ce1d4430806","modified":1602570653745},{"_id":"themes/hexo-theme-matery/source/libs/gitment/gitment.js","hash":"28c02c45ce568e084cd1041dc493f83f9c6c88c6","modified":1602570653737},{"_id":"themes/hexo-theme-matery/source/libs/dplayer/DPlayer.min.js","hash":"c3bad7b265574fab0ae4d45867422ea1cb9d6599","modified":1602570653729},{"_id":"themes/hexo-theme-matery/source/libs/jquery/jquery.min.js","hash":"2115753ca5fb7032aec498db7bb5dca624dbe6be","modified":1602570653739},{"_id":"themes/hexo-theme-matery/source/libs/valine/Valine.min.js","hash":"6cbdbf91e1f046dd41267a5ff0691a1fccba99df","modified":1602570653747},{"_id":"themes/hexo-theme-matery/source/medias/banner/0.jpg","hash":"69ec96cd9b4bc3aa631adc9da61353f50c39f031","modified":1602570653749},{"_id":"themes/hexo-theme-matery/source/medias/banner/2.jpg","hash":"39fb2535460ce66cc0b34e07ffb9411db1405f09","modified":1602570653752},{"_id":"themes/hexo-theme-matery/source/medias/banner/3.jpg","hash":"4ac047e92d0363b1a61ab756aca6dac13fb77494","modified":1602570653754},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/1.jpg","hash":"684ae89de8cb7acefae19f5aee6c612037c46393","modified":1602570653761},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/0.jpg","hash":"1c3300f029fc85d6dda6fa4f1d699551034cdaf7","modified":1602570653760},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/11.jpg","hash":"f55972ce7175684f2b11c3c9fc2b5b14bccbfae8","modified":1602570653762},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/12.jpg","hash":"8a4b2e7d92ae95c3b0c921db23c35aa9a41a7d58","modified":1602570653764},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/17.jpg","hash":"42d47903551ee81885c1386022982cae165841c5","modified":1602570653767},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/14.jpg","hash":"38e11221406785bcd93aa9cd23e568e164630ef1","modified":1602570653765},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/20.jpg","hash":"3b11f9b461168d907073f793190865fe621a8573","modified":1602570653769},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/19.jpg","hash":"eb250906fdbc0c408f42ae9933725bc1a05d79fb","modified":1602570653768},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/6.jpg","hash":"c8f2aa4bbb041158b4e73733a341e6a77c8583f7","modified":1602570653774},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/18.jpg","hash":"64829272ec85bb819d55ff89e5b5fd6f64aa436b","modified":1602570653767},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/4.jpg","hash":"e06c47de27619984be9d5d02947f8370a432dfea","modified":1602570653772},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/9.jpg","hash":"b956a2291a04b2132366b53666cf34858b8bdb1f","modified":1602570653776},{"_id":"themes/hexo-theme-matery/source/libs/awesome/css/all.css","hash":"ecc41e32ad2696877a1656749841f3b5543bbe3d","modified":1602570653703},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-brands-400.eot","hash":"22f9e7d5226408eb2d0a11e118257a3ca22b8670","modified":1602570653705},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-brands-400.ttf","hash":"91cbeeaceb644a971241c08362898599d6d968ce","modified":1602570653711},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-brands-400.woff2","hash":"a46bd47ff0a90b812aafafda587d095cdb844271","modified":1602570653713},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-brands-400.woff","hash":"18838f5260317da3c5ed29bf844ac8a4f7ad0529","modified":1602570653712},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-solid-900.woff","hash":"92803b8753ceda573c6906774677c5a7081d2fbb","modified":1602570653725},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-solid-900.woff2","hash":"9c081b88b106c6c04ecb895ba7ba7d3dcb3b55ac","modified":1602570653726},{"_id":"themes/hexo-theme-matery/source/medias/cover.jpg","hash":"d4957ff7cc5e88555cd840f2956ab0561e6f1ccf","modified":1602570653759},{"_id":"themes/hexo-theme-matery/source/libs/gitalk/gitalk.min.js","hash":"8fefe38f28804f90116bdcb74a0875c9de9f3b7d","modified":1602570653736},{"_id":"themes/hexo-theme-matery/source/libs/materialize/materialize.min.css","hash":"a69d456e3345e7f59cd0d47d1b3e70fd4a496a05","modified":1602570653742},{"_id":"themes/hexo-theme-matery/source/libs/materialize/materialize.min.js","hash":"c8b4c65651921d888cf5f27430dfe2ad190d35bf","modified":1602570653743},{"_id":"themes/hexo-theme-matery/source/libs/valine/av-min.js","hash":"541efb9edc1ce425cbe3897cfc25803211fe6a05","modified":1602570653747},{"_id":"themes/hexo-theme-matery/source/medias/banner/1.jpg","hash":"ab122a36998a4f62a61e61a4fc5e00248113413b","modified":1602570653751},{"_id":"themes/hexo-theme-matery/source/medias/banner/5.jpg","hash":"852418f4f09e796e12bc3bab7a1488d3f37d6486","modified":1602570653757},{"_id":"themes/hexo-theme-matery/source/medias/banner/6.jpg","hash":"ed7282cc129c4ff9f322d2f2897fb4aac5c48589","modified":1602570653758},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-regular-400.svg","hash":"3d3a49445343d80f3b553e3e3425b9a7bd49acaf","modified":1602570653714},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-solid-900.ttf","hash":"9521ed12274c2cbc910cea77657116fcf6545da3","modified":1602570653724},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-solid-900.eot","hash":"cab8e84ae5682d1d556e234df9c790985888def8","modified":1602570653718},{"_id":"themes/hexo-theme-matery/source/medias/banner/4.jpg","hash":"e5ac5033678afa9d69edffe9a61004f836cb5734","modified":1602570653756},{"_id":"themes/hexo-theme-matery/source/libs/echarts/echarts.min.js","hash":"9496f386a0da4601cad22c479cc5543913a4d67f","modified":1602570653735},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-brands-400.svg","hash":"5e2d2a159294576bea69cc3360efb5ffe110ab2d","modified":1602570653708},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-solid-900.svg","hash":"7da88b19e1486f8c968d3cf5ab3f194f01ea17fd","modified":1602570653722},{"_id":"public/atom.xml","hash":"425e803f9fe680b4cc793209c8066626cfc8473d","modified":1621496966152},{"_id":"public/search.xml","hash":"760c2a0f43e671ff2c1f24b94cc69c7f728a2070","modified":1621496966152},{"_id":"public/categories/index.html","hash":"ed7a98350f18395b33e0cdde9639a782c1684d03","modified":1621496966152},{"_id":"public/about/index.html","hash":"9ab943ddb2e42484143920869ce569868a9df888","modified":1621496966152},{"_id":"public/tags/index.html","hash":"337f02a4f1c32110b7591d55af117aab1dac6d66","modified":1621496966152},{"_id":"public/2020/10/13/hello-world/index.html","hash":"cd274fbb6171d22d206412e3c2ed506998a9444c","modified":1602576511910},{"_id":"public/archives/index.html","hash":"2d94a19279727710c5346ccfc7f27a1a00320660","modified":1621496966152},{"_id":"public/archives/2020/index.html","hash":"7f5db357bfea3607439873945cf28f5b4b7ae2e8","modified":1621496966152},{"_id":"public/archives/2020/10/index.html","hash":"99ec4bbed7d29c41bcdf00910c04e21fdd9d417f","modified":1621496966152},{"_id":"public/index.html","hash":"7319508bbf652c446652e56db67598f096f67be9","modified":1621496966152},{"_id":"public/favicon.png","hash":"774fee8c6d0be9dbb010b20f36c06848d06e3da0","modified":1602571742461},{"_id":"public/medias/comment_bg.png","hash":"dfc93d24081884fbc58cab0f8fd19e77d31d6123","modified":1602571742461},{"_id":"public/medias/icp.png","hash":"27a96f31f7d0413c6ade6f40e06f021f501151c7","modified":1602571742461},{"_id":"public/medias/logo.png","hash":"d9095f5ea8719374d9d1ff020279426f5b2a1396","modified":1602571742461},{"_id":"public/medias/featureimages/2.jpg","hash":"4bba691cf71a517ecaeaf42afd3e8f8b31e346c1","modified":1602571742461},{"_id":"public/medias/featureimages/22.jpg","hash":"754579747a3e99747d890fca3162f370b96a7941","modified":1602571742461},{"_id":"public/medias/featureimages/23.jpg","hash":"7d7f37da3fa7128343adac23866449eb2c6a549a","modified":1602571742461},{"_id":"public/medias/featureimages/5.jpg","hash":"41ca20129a37fedc573eec28dd7d7b9e5b09228a","modified":1602571742461},{"_id":"public/medias/featureimages/3.jpg","hash":"6ec646c2a70f5f11edacf225c1477f2200a37a96","modified":1602571742461},{"_id":"public/medias/featureimages/7.jpg","hash":"7975141cd64e875122c0ea33daaca1a06bf00b8e","modified":1602571742461},{"_id":"public/medias/reward/alipay.jpg","hash":"1abc719b95d1b26f1f898e6b0a9b7609146e332f","modified":1602571742461},{"_id":"public/medias/reward/wechat.png","hash":"f1c84ceb948d0876b5ec7d4d55b654ef3f5132e1","modified":1602577498584},{"_id":"public/libs/awesome/webfonts/fa-regular-400.woff","hash":"59439d3ad31d856d78ec3e2bd9f1eafa2c7a581c","modified":1602571742461},{"_id":"public/libs/awesome/webfonts/fa-regular-400.woff2","hash":"f6f653b4ea8fc487bdb590d39d5a726258a55f40","modified":1602571742461},{"_id":"public/libs/awesome/webfonts/fa-regular-400.ttf","hash":"0f4bd02942a54a6b3200d9078adff88c2812e751","modified":1602571742461},{"_id":"public/libs/lightGallery/fonts/lg.eot","hash":"54caf05a81e33d7bf04f2e420736ce6f1de5f936","modified":1602571742461},{"_id":"public/libs/lightGallery/fonts/lg.woff","hash":"3048de344dd5cad4624e0127e58eaae4b576f574","modified":1602571742461},{"_id":"public/libs/lightGallery/fonts/lg.ttf","hash":"f6421c0c397311ae09f9257aa58bcd5e9720f493","modified":1602571742461},{"_id":"public/libs/lightGallery/fonts/lg.svg","hash":"9c6632aeec67d3e84a1434884aa801514ff8103b","modified":1602571742461},{"_id":"public/libs/lightGallery/img/video-play.png","hash":"2962e03ddbe04d7e201a5acccac531a2bbccddfc","modified":1602571742461},{"_id":"public/libs/lightGallery/img/vimeo-play.png","hash":"9b72fc0f86a01467ed0b68c9cc4d604ec316d517","modified":1602571742461},{"_id":"public/libs/lightGallery/img/loading.gif","hash":"15a76af2739482d8de7354abc6d8dc4fca8d145e","modified":1602571742461},{"_id":"public/libs/lightGallery/img/youtube-play.png","hash":"f8d11384d33b7a79ee2ba8d522844f14d5067a80","modified":1602571742461},{"_id":"public/libs/share/fonts/iconfont.woff","hash":"2e3fce1dcfbd6e2114e7bfbeaf72d3c62e15a1bd","modified":1602571742461},{"_id":"public/libs/share/fonts/iconfont.eot","hash":"00ff749c8e202401190cc98d56087cdda716abe4","modified":1602571742461},{"_id":"public/libs/share/fonts/iconfont.svg","hash":"1d56c9d5db0273f07c43cc1397e440f98ba7827a","modified":1602571742461},{"_id":"public/libs/share/fonts/iconfont.ttf","hash":"afd898f59d363887418669520b24d175f966a083","modified":1602571742461},{"_id":"public/medias/avatar.jpg","hash":"2a6287308628881ce27b9a7de53ba15c2be00d02","modified":1602571742461},{"_id":"public/medias/banner/0.jpg","hash":"69ec96cd9b4bc3aa631adc9da61353f50c39f031","modified":1602571742461},{"_id":"public/medias/featureimages/10.jpg","hash":"98e7f6fd9c97d4de9044b6871ca08ebf14db11b9","modified":1602571742461},{"_id":"public/medias/featureimages/13.jpg","hash":"35a320174f8e316e3eadaec658024276b651c6e9","modified":1602571742461},{"_id":"public/medias/featureimages/15.jpg","hash":"da0fbee3b7bde1607eace377ddf834c0be99edfe","modified":1602571742461},{"_id":"public/medias/featureimages/16.jpg","hash":"97a829c4bc94f9d2929b20a1a9b798c57b9f7205","modified":1602571742461},{"_id":"public/medias/featureimages/17.jpg","hash":"42d47903551ee81885c1386022982cae165841c5","modified":1602571742461},{"_id":"public/medias/featureimages/19.jpg","hash":"eb250906fdbc0c408f42ae9933725bc1a05d79fb","modified":1602571742461},{"_id":"public/medias/featureimages/18.jpg","hash":"64829272ec85bb819d55ff89e5b5fd6f64aa436b","modified":1602571742461},{"_id":"public/medias/featureimages/20.jpg","hash":"3b11f9b461168d907073f793190865fe621a8573","modified":1602571742461},{"_id":"public/medias/featureimages/21.jpg","hash":"b26edb128bb0bf58b23fd2f014e9555e89a2ca3b","modified":1602571742461},{"_id":"public/medias/featureimages/4.jpg","hash":"e06c47de27619984be9d5d02947f8370a432dfea","modified":1602571742461},{"_id":"public/medias/featureimages/9.jpg","hash":"b956a2291a04b2132366b53666cf34858b8bdb1f","modified":1602571742461},{"_id":"public/medias/featureimages/8.jpg","hash":"8e4b7186352085483ca1174c7c0800114c48df8b","modified":1602571742461},{"_id":"public/libs/awesome/webfonts/fa-brands-400.woff","hash":"18838f5260317da3c5ed29bf844ac8a4f7ad0529","modified":1602571742461},{"_id":"public/libs/awesome/webfonts/fa-brands-400.woff2","hash":"a46bd47ff0a90b812aafafda587d095cdb844271","modified":1602571742461},{"_id":"public/libs/awesome/webfonts/fa-regular-400.eot","hash":"439c8afd3373acb4a73135a34e220464a89cd5e2","modified":1602571742461},{"_id":"public/libs/awesome/webfonts/fa-solid-900.woff","hash":"92803b8753ceda573c6906774677c5a7081d2fbb","modified":1602571742461},{"_id":"public/libs/awesome/webfonts/fa-solid-900.woff2","hash":"9c081b88b106c6c04ecb895ba7ba7d3dcb3b55ac","modified":1602571742461},{"_id":"public/medias/cover.jpg","hash":"d4957ff7cc5e88555cd840f2956ab0561e6f1ccf","modified":1602571742461},{"_id":"public/medias/banner/2.jpg","hash":"39fb2535460ce66cc0b34e07ffb9411db1405f09","modified":1602571742461},{"_id":"public/medias/banner/5.jpg","hash":"852418f4f09e796e12bc3bab7a1488d3f37d6486","modified":1602571742461},{"_id":"public/medias/featureimages/0.jpg","hash":"1c3300f029fc85d6dda6fa4f1d699551034cdaf7","modified":1602571742461},{"_id":"public/medias/featureimages/1.jpg","hash":"684ae89de8cb7acefae19f5aee6c612037c46393","modified":1602571742461},{"_id":"public/medias/featureimages/12.jpg","hash":"8a4b2e7d92ae95c3b0c921db23c35aa9a41a7d58","modified":1602571742461},{"_id":"public/medias/featureimages/11.jpg","hash":"f55972ce7175684f2b11c3c9fc2b5b14bccbfae8","modified":1602571742461},{"_id":"public/medias/featureimages/14.jpg","hash":"38e11221406785bcd93aa9cd23e568e164630ef1","modified":1602571742461},{"_id":"public/medias/featureimages/6.jpg","hash":"c8f2aa4bbb041158b4e73733a341e6a77c8583f7","modified":1602571742461},{"_id":"public/libs/awesome/webfonts/fa-brands-400.eot","hash":"22f9e7d5226408eb2d0a11e118257a3ca22b8670","modified":1602571742461},{"_id":"public/libs/awesome/webfonts/fa-regular-400.svg","hash":"3d3a49445343d80f3b553e3e3425b9a7bd49acaf","modified":1602571742461},{"_id":"public/css/gitment.css","hash":"2bd15cc17dca35ac3ecc0acf167a23a1dd362acd","modified":1602571742461},{"_id":"public/css/my-gitalk.css","hash":"eeda46a83d0db1cc239a9cd27d544faf663f9883","modified":1602571742461},{"_id":"public/css/my.css","hash":"10577fbc30f241b126d1b51b1f56136ecba86b19","modified":1602571742461},{"_id":"public/js/matery.js","hash":"b86de5fe3e9766b7ff80df12ea41c3a9e30825f7","modified":1602571742461},{"_id":"public/js/search.js","hash":"d559d402b4d4a0931821fe6e22a8831fc43a953d","modified":1602571742461},{"_id":"public/libs/aos/aos.js","hash":"02bfb40b0c4b6e9b0b4081218357145cbb327d74","modified":1602571742461},{"_id":"public/libs/aplayer/APlayer.min.css","hash":"07372a2ba507388d0fed166d761b1c2c2a659dce","modified":1602571742461},{"_id":"public/libs/codeBlock/codeBlockFuction.js","hash":"c7ab06d27a525b15b1eb69027135269e9b9132fb","modified":1602571742461},{"_id":"public/libs/codeBlock/codeCopy.js","hash":"6d39a766af62e625f177c4d5cf3adc35eed71e61","modified":1602571742461},{"_id":"public/libs/codeBlock/codeLang.js","hash":"bac88b4d4e3679732d29bd037c34f089cf27cf05","modified":1602571742461},{"_id":"public/libs/codeBlock/codeShrink.js","hash":"201e8cd761b4be557247bdaf1ebc7c11c83194f6","modified":1602571742461},{"_id":"public/libs/background/canvas-nest.js","hash":"65333d0dbb9c1173a1b13031b230161fc42c8b2f","modified":1602571742461},{"_id":"public/libs/background/ribbon-dynamic.js","hash":"052b80c29e6bc585aa28d4504b743bdbac220a88","modified":1602571742461},{"_id":"public/libs/background/ribbon-refresh.min.js","hash":"6d98692b2cad8c746a562db18b170b35c24402f4","modified":1602571742461},{"_id":"public/libs/background/ribbon.min.js","hash":"6a99d494c030388f96f6086a7aaa0f03f3fe532e","modified":1602571742461},{"_id":"public/libs/jqcloud/jqcloud-1.0.4.min.js","hash":"257eaae3020599e4939f50d5008a743827f25b8c","modified":1602571742461},{"_id":"public/libs/jqcloud/jqcloud.css","hash":"20d9f11a19d95c70e27cb922e0d6dccbec4eae89","modified":1602571742461},{"_id":"public/libs/instantpage/instantpage.js","hash":"83ce8919b1a69b2f1809ffaf99b52a8627e650e9","modified":1602571742461},{"_id":"public/libs/others/clicklove.js","hash":"6a39b8c683ba5dcd92f70c6ab45d1cfac3213e8e","modified":1602571742461},{"_id":"public/libs/others/busuanzi.pure.mini.js","hash":"6e41f31100ae7eb3a6f23f2c168f6dd56e7f7a9a","modified":1602571742461},{"_id":"public/libs/scrollprogress/scrollProgress.min.js","hash":"777ffe5d07e85a14fbe97d846f45ffc0087251cc","modified":1602571742461},{"_id":"public/libs/tocbot/tocbot.css","hash":"9ab8ef576c9a57115194152e79cca79b0a41dd70","modified":1602571742461},{"_id":"public/libs/tocbot/tocbot.min.js","hash":"5ec27317f0270b8cf6b884c6f12025700b9a565c","modified":1602571742461},{"_id":"public/libs/share/css/share.min.css","hash":"8a778a86f3ce9a042df6be63a9f1039631e351a5","modified":1602571742461},{"_id":"public/medias/banner/3.jpg","hash":"4ac047e92d0363b1a61ab756aca6dac13fb77494","modified":1602571742461},{"_id":"public/medias/banner/6.jpg","hash":"ed7282cc129c4ff9f322d2f2897fb4aac5c48589","modified":1602571742461},{"_id":"public/libs/awesome/webfonts/fa-brands-400.ttf","hash":"91cbeeaceb644a971241c08362898599d6d968ce","modified":1602571742461},{"_id":"public/libs/awesome/webfonts/fa-solid-900.ttf","hash":"9521ed12274c2cbc910cea77657116fcf6545da3","modified":1602571742461},{"_id":"public/libs/aos/aos.css","hash":"191a3705a8f63e589a50a0ff2f2c5559f1a1b6b2","modified":1602571742461},{"_id":"public/libs/gitalk/gitalk.css","hash":"940ded3ea12c2fe1ab0820d2831ec405f3f1fe9f","modified":1602571742461},{"_id":"public/libs/gitment/gitment-default.css","hash":"2903c59ee06b965bef32e937bd69f5b0b2190717","modified":1602571742461},{"_id":"public/libs/masonry/masonry.pkgd.min.js","hash":"ff940b4ea68368ca0e4d5560cbb79fb147dfc3c5","modified":1602571742461},{"_id":"public/libs/lightGallery/css/lightgallery.min.css","hash":"1b7227237f9785c66062a4811508916518e4132c","modified":1602571742461},{"_id":"public/libs/share/js/social-share.min.js","hash":"a3090a02786dcd4efc6355c1c1dc978add8d6827","modified":1602571742461},{"_id":"public/libs/share/js/jquery.share.min.js","hash":"41367dcb857e02e3c417ebe68a554ce1d4430806","modified":1602571742461},{"_id":"public/medias/banner/1.jpg","hash":"ab122a36998a4f62a61e61a4fc5e00248113413b","modified":1602571742461},{"_id":"public/css/matery.css","hash":"87bd1dacf48c9daab7ea43466368247f1e4107d1","modified":1602571742461},{"_id":"public/libs/cryptojs/crypto-js.min.js","hash":"5989527a378b55011a59522f41eeb3981518325c","modified":1602571742461},{"_id":"public/libs/dplayer/DPlayer.min.css","hash":"f7d19655f873b813ffba5d1a17145c91f82631b8","modified":1602571742461},{"_id":"public/libs/animate/animate.min.css","hash":"97afa151569f046b2e01f27c1871646e9cd87caf","modified":1602571742461},{"_id":"public/libs/aplayer/APlayer.min.js","hash":"22caa28ff6b41a16ff40f15d38f1739e22359478","modified":1602571742461},{"_id":"public/libs/lightGallery/js/lightgallery-all.min.js","hash":"9f5ef4bc8a0a3c746ca4f3c3e6d64493b1a977d8","modified":1602571742461},{"_id":"public/libs/awesome/webfonts/fa-solid-900.eot","hash":"cab8e84ae5682d1d556e234df9c790985888def8","modified":1602571742461},{"_id":"public/libs/gitment/gitment.js","hash":"28c02c45ce568e084cd1041dc493f83f9c6c88c6","modified":1602571742461},{"_id":"public/libs/valine/Valine.min.js","hash":"6cbdbf91e1f046dd41267a5ff0691a1fccba99df","modified":1602571742461},{"_id":"public/libs/awesome/css/all.css","hash":"ecc41e32ad2696877a1656749841f3b5543bbe3d","modified":1602571742461},{"_id":"public/medias/banner/4.jpg","hash":"e5ac5033678afa9d69edffe9a61004f836cb5734","modified":1602571742461},{"_id":"public/libs/jquery/jquery.min.js","hash":"2115753ca5fb7032aec498db7bb5dca624dbe6be","modified":1602571742461},{"_id":"public/libs/dplayer/DPlayer.min.js","hash":"c3bad7b265574fab0ae4d45867422ea1cb9d6599","modified":1602571742461},{"_id":"public/libs/materialize/materialize.min.css","hash":"a69d456e3345e7f59cd0d47d1b3e70fd4a496a05","modified":1602571742461},{"_id":"public/libs/gitalk/gitalk.min.js","hash":"8fefe38f28804f90116bdcb74a0875c9de9f3b7d","modified":1602571742461},{"_id":"public/libs/valine/av-min.js","hash":"541efb9edc1ce425cbe3897cfc25803211fe6a05","modified":1602571742461},{"_id":"public/libs/materialize/materialize.min.js","hash":"c8b4c65651921d888cf5f27430dfe2ad190d35bf","modified":1602571742461},{"_id":"public/libs/awesome/webfonts/fa-brands-400.svg","hash":"5e2d2a159294576bea69cc3360efb5ffe110ab2d","modified":1602571742461},{"_id":"public/libs/awesome/webfonts/fa-solid-900.svg","hash":"7da88b19e1486f8c968d3cf5ab3f194f01ea17fd","modified":1602571742461},{"_id":"public/libs/echarts/echarts.min.js","hash":"9496f386a0da4601cad22c479cc5543913a4d67f","modified":1602571742461},{"_id":"themes/hexo-theme-matery/source/medias/wisesky.jpg","hash":"ca0e4de76b63d2782d8618aeea148467258ae14f","modified":1602572521751},{"_id":"public/medias/wisesky.jpg","hash":"ca0e4de76b63d2782d8618aeea148467258ae14f","modified":1602574164658},{"_id":"themes/hexo-theme-matery/source/medias/reward/.DS_Store","hash":"fe9ec4436feaf1a9fedf0f2a2938c80df09fa8fa","modified":1602577812069},{"_id":"themes/hexo-theme-matery/source/medias/.DS_Store","hash":"49a8c2d15a0f57fe40bb502e337a296afdb1ef83","modified":1602577383050},{"_id":"themes/hexo-theme-matery/source/medias/reward/alipay.png","hash":"7c1cd3be7825da29c2aca0d8c0a77f6f791b6d3a","modified":1602577351418},{"_id":"public/uncategorized/hello-world/index.html","hash":"38d91d91a28d189bc1f36f490d64f1cab54bb5dd","modified":1602577909635},{"_id":"public/medias/reward/alipay.png","hash":"7c1cd3be7825da29c2aca0d8c0a77f6f791b6d3a","modified":1602577498584},{"_id":"public/tags/test/index.html","hash":"5613085029c80e1e0c0ea348cea0ee0e817fced3","modified":1621496966152},{"_id":"public/test/hello-world/index.html","hash":"258096a2581e401331d1f13925ab96d8154cfa38","modified":1607587332408},{"_id":"public/categories/test/index.html","hash":"805e2633d5f445b48c01cca8b39f87fc791e6bca","modified":1621496966152},{"_id":"source/_posts/my-first-blog.md","hash":"c7e5400935afb8289e78a08d62bfe907fba89d36","modified":1606285615417},{"_id":"source/.DS_Store","hash":"e99cc6920f98e5d694d97a1f601d60ebea90cc40","modified":1621495672290},{"_id":"themes/hexo-theme-matery/source/medias/ACG/9.jpg","hash":"10b2ddfbe7f03c4513ace7a2855a47f907478d55","modified":1602578209287},{"_id":"themes/hexo-theme-matery/source/medias/ACG/4.jpg","hash":"f06a264751553ff6b2e3b158c21154ce0aacda16","modified":1602578203288},{"_id":"themes/hexo-theme-matery/source/medias/ACG/3.jpg","hash":"f779883e34f277950961f5f1ab62a433dcd91567","modified":1602578201822},{"_id":"themes/hexo-theme-matery/source/medias/ACG/8.jpg","hash":"63c5ff3afa220b73031891a08cf56146f7fd9fee","modified":1602578208159},{"_id":"themes/hexo-theme-matery/source/medias/ACG/2.jpg","hash":"28792c2f8c55005db8c0e6aeae70b394c7dd0fff","modified":1602578200558},{"_id":"themes/hexo-theme-matery/source/medias/ACG/7.jpg","hash":"f80b51d620ca4fd2878295b00c68659c7990cfa0","modified":1602578206996},{"_id":"themes/hexo-theme-matery/source/medias/ACG/6.jpg","hash":"f82a96d6e74947be00c049d57d4e49a102344774","modified":1602578205731},{"_id":"themes/hexo-theme-matery/source/medias/ACG/5.jpg","hash":"5dfa664bb0bcf5ed1480e44bbeb92291a59b3326","modified":1602578204467},{"_id":"themes/hexo-theme-matery/source/medias/ACG/1.jpg","hash":"33c9e2585ba65798847eb7d10009db4089593350","modified":1602578198957},{"_id":"public/sui-bi/my-first-blog/index.html","hash":"f083da341fc1d909ef9996332c20945f036443cb","modified":1607587146319},{"_id":"public/categories//index.html","hash":"20d8e82df68a2e331b38e5e34a3f813de0b59c80","modified":1621496966152},{"_id":"public/tags//index.html","hash":"b1a7caaf45dcde02baa540bb137d055f9a3795bd","modified":1621496966152},{"_id":"public/css/prism-tomorrow.css","hash":"3b99487dfc9b4e51e9105a93743b92a761840e34","modified":1602665020148},{"_id":"public/medias/ACG/9.jpg","hash":"10b2ddfbe7f03c4513ace7a2855a47f907478d55","modified":1602665020148},{"_id":"public/medias/ACG/3.jpg","hash":"f779883e34f277950961f5f1ab62a433dcd91567","modified":1602665020148},{"_id":"public/medias/ACG/4.jpg","hash":"f06a264751553ff6b2e3b158c21154ce0aacda16","modified":1602665020148},{"_id":"public/medias/ACG/8.jpg","hash":"63c5ff3afa220b73031891a08cf56146f7fd9fee","modified":1602665020148},{"_id":"public/medias/ACG/2.jpg","hash":"28792c2f8c55005db8c0e6aeae70b394c7dd0fff","modified":1602665020148},{"_id":"public/medias/ACG/7.jpg","hash":"f80b51d620ca4fd2878295b00c68659c7990cfa0","modified":1602665020148},{"_id":"public/medias/ACG/6.jpg","hash":"f82a96d6e74947be00c049d57d4e49a102344774","modified":1602665020148},{"_id":"public/medias/ACG/5.jpg","hash":"5dfa664bb0bcf5ed1480e44bbeb92291a59b3326","modified":1602665020148},{"_id":"public/medias/ACG/1.jpg","hash":"33c9e2585ba65798847eb7d10009db4089593350","modified":1602665020148},{"_id":"source/_posts/.DS_Store","hash":"15e613ffb85d4c1c2580803f9a341ecb8eb340d1","modified":1607335687233},{"_id":"source/_posts/my-first-blog/Euphonium_Movie_2nd_KV.jpg","hash":"ca061b9e7f84622a9786b51979258304ed68f2ab","modified":1602665209583},{"_id":"source/_posts/my-first-blog/p2409965093.jpg","hash":"3e95adce661298a77553ffb74451bf8d8f94dbd3","modified":1602665506316},{"_id":"source/_posts/my-first-blog/p2382958621.png","hash":"8f905289010e20f1ec91485c06fefb9aa3969210","modified":1602665506289},{"_id":"source/_posts/my-first-blog/Euphonium_Movie_Finale_KV2.jpg","hash":"4bc062c352ba272482c27be24c373e3aa0dd99db","modified":1602665209643},{"_id":"public/sui-bi/my-first-blog/Euphonium_Movie_2nd_KV.jpg","hash":"ca061b9e7f84622a9786b51979258304ed68f2ab","modified":1602665561247},{"_id":"public/sui-bi/my-first-blog/p2409965093.jpg","hash":"3e95adce661298a77553ffb74451bf8d8f94dbd3","modified":1602665561247},{"_id":"public/sui-bi/my-first-blog/p2382958621.png","hash":"8f905289010e20f1ec91485c06fefb9aa3969210","modified":1602665561247},{"_id":"public/sui-bi/my-first-blog/Euphonium_Movie_Finale_KV2.jpg","hash":"4bc062c352ba272482c27be24c373e3aa0dd99db","modified":1602665561247},{"_id":"source/_posts/my-first-blog/relife-2.jpg","hash":"3e95adce661298a77553ffb74451bf8d8f94dbd3","modified":1602665691497},{"_id":"source/_posts/my-first-blog/relife-1.png","hash":"8f905289010e20f1ec91485c06fefb9aa3969210","modified":1602665687425},{"_id":"public/sui-bi/my-first-blog/relife-2.jpg","hash":"3e95adce661298a77553ffb74451bf8d8f94dbd3","modified":1602665761392},{"_id":"public/sui-bi/my-first-blog/relife-1.png","hash":"8f905289010e20f1ec91485c06fefb9aa3969210","modified":1602665761392},{"_id":"source/_posts/.md","hash":"a1309fc7ecd208af09188de98e92de9dd6fbe719","modified":1603879037910},{"_id":"source/_posts/sth-change-myself/2020-07-31.jpg","hash":"1e70ffa9161923f5a7b25c5f9da60f925ade49cf","modified":1602319160796},{"_id":"public/sui-bi/gai-bian-yu-lan-duo/index.html","hash":"21bb755d93994a7f7da145416bef2867cb72bd5c","modified":1607587146319},{"_id":"source/_posts//2020-07-31.jpg","hash":"1e70ffa9161923f5a7b25c5f9da60f925ade49cf","modified":1602319160796},{"_id":"public/sui-bi/gai-bian-yu-lan-duo/2020-07-31.jpg","hash":"1e70ffa9161923f5a7b25c5f9da60f925ade49cf","modified":1603877001247},{"_id":"source/_posts//IMG_9373.jpeg","hash":"3abf97bca9a9719e6c3797cb69fbaf3e3b82f183","modified":1603878562340},{"_id":"public/sui-bi/gai-bian-yu-lan-duo/IMG_9373.jpeg","hash":"3abf97bca9a9719e6c3797cb69fbaf3e3b82f183","modified":1603878590251},{"_id":"source/_posts/ubuntu.md","hash":"77ae20e01b2eda05026ae6c56d48638eb72e059c","modified":1607587287729},{"_id":"public/tags/ubuntu/index.html","hash":"c7366ebd33ccea8650bbb9220fe6edd7c42b4014","modified":1621496966152},{"_id":"public/tags//index.html","hash":"6d3d47ca2b42745691c75170983024d029728283","modified":1621496966152},{"_id":"public/yun-wei/ji-ubuntu-chong-qi-yin-qi-de-gu-zhang-pai-cha/index.html","hash":"e1258cbdaf70fb557e6b32d11f8facebfa0689b4","modified":1607587146319},{"_id":"public/archives/2020/11/index.html","hash":"e0c4cad604024564c5577422659205afe08606a4","modified":1621496966152},{"_id":"public/tags/grub/index.html","hash":"428089ccef3c83340eb2fffaf54ee91cc8e2596d","modified":1621496966152},{"_id":"public/tags/linux/index.html","hash":"c7d15206decf356780cceac59962c8a141723c31","modified":1621496966152},{"_id":"public/categories//index.html","hash":"9d4871d1c062f945c646470ea901a692ba7c8f83","modified":1621496966152},{"_id":"source/_posts/LeetCode-33-Search-in-Rotated-Sorted-Array.md","hash":"38c137779b3225cbe8640623089ecd5e7d8d2519","modified":1607587296687},{"_id":"source/_posts/LeetCode-33-Search-in-Rotated-Sorted-Array/img2.jpg","hash":"8839af294b39128cc5ebac6602b4432c78f1f702","modified":1605604665263},{"_id":"source/_posts/LeetCode-33-Search-in-Rotated-Sorted-Array/img3.jpg","hash":"91dc5aa98d0e31eea2c8a7e06aa02a93c2fed481","modified":1605604660564},{"_id":"source/_posts/LeetCode-33-Search-in-Rotated-Sorted-Array/img6.jpg","hash":"8839af294b39128cc5ebac6602b4432c78f1f702","modified":1605605676330},{"_id":"source/_posts/LeetCode-33-Search-in-Rotated-Sorted-Array/img7.jpg","hash":"99da6e3b4c7064128818cd54cf48f54464a4b379","modified":1605605679078},{"_id":"source/_posts/LeetCode-33-Search-in-Rotated-Sorted-Array/img8.jpg","hash":"02e2ce27e3ec791a9f78b746b321e90def906ca3","modified":1605605684311},{"_id":"source/_posts/LeetCode-33-Search-in-Rotated-Sorted-Array/img1.png","hash":"1561362bfc8b07eeca9e43b997431177a3b7601a","modified":1605601397721},{"_id":"public/algorithm-leetcode/leetcode-33-search-in-rotated-sorted-array/index.html","hash":"14e755a215967c9e99d9d29bd48df693b977acb3","modified":1605609271672},{"_id":"public/categories/Algorithm-LeetCode/index.html","hash":"9d46e00e60588a274764937e1e653a06083659f8","modified":1605609271672},{"_id":"public/tags/Algorithm/index.html","hash":"ff8c93ed596d4497fe4b335993915ef1fab4d541","modified":1621496966152},{"_id":"public/algorithm-leetcode/leetcode-33-search-in-rotated-sorted-array/img3.jpg","hash":"91dc5aa98d0e31eea2c8a7e06aa02a93c2fed481","modified":1605609207295},{"_id":"public/algorithm-leetcode/leetcode-33-search-in-rotated-sorted-array/img7.jpg","hash":"99da6e3b4c7064128818cd54cf48f54464a4b379","modified":1605609207295},{"_id":"public/algorithm-leetcode/leetcode-33-search-in-rotated-sorted-array/img6.jpg","hash":"8839af294b39128cc5ebac6602b4432c78f1f702","modified":1605609207295},{"_id":"public/algorithm-leetcode/leetcode-33-search-in-rotated-sorted-array/img8.jpg","hash":"02e2ce27e3ec791a9f78b746b321e90def906ca3","modified":1605609207295},{"_id":"public/algorithm-leetcode/leetcode-33-search-in-rotated-sorted-array/img2.jpg","hash":"8839af294b39128cc5ebac6602b4432c78f1f702","modified":1605609207295},{"_id":"public/algorithm-leetcode/leetcode-33-search-in-rotated-sorted-array/img1.png","hash":"1561362bfc8b07eeca9e43b997431177a3b7601a","modified":1605609207295},{"_id":"public/algorithm/leetcode/leetcode-33-search-in-rotated-sorted-array/index.html","hash":"d51f222777c9e812ba0f8b9aad05cf96023265f8","modified":1605609346756},{"_id":"public/categories/Algorithm/index.html","hash":"36e712a01279cae76b215053b176764bcc45c514","modified":1621496966152},{"_id":"public/categories/Algorithm/LeetCode/index.html","hash":"d46713a23432b4b6230b9a873316706befaf8bfd","modified":1605609346756},{"_id":"public/algorithm/leetcode/leetcode-33-search-in-rotated-sorted-array/img2.jpg","hash":"8839af294b39128cc5ebac6602b4432c78f1f702","modified":1605609346756},{"_id":"public/algorithm/leetcode/leetcode-33-search-in-rotated-sorted-array/img3.jpg","hash":"91dc5aa98d0e31eea2c8a7e06aa02a93c2fed481","modified":1605609346756},{"_id":"public/algorithm/leetcode/leetcode-33-search-in-rotated-sorted-array/img6.jpg","hash":"8839af294b39128cc5ebac6602b4432c78f1f702","modified":1605609346756},{"_id":"public/algorithm/leetcode/leetcode-33-search-in-rotated-sorted-array/img7.jpg","hash":"99da6e3b4c7064128818cd54cf48f54464a4b379","modified":1605609346756},{"_id":"public/algorithm/leetcode/leetcode-33-search-in-rotated-sorted-array/img8.jpg","hash":"02e2ce27e3ec791a9f78b746b321e90def906ca3","modified":1605609346756},{"_id":"public/algorithm/leetcode/leetcode-33-search-in-rotated-sorted-array/img1.png","hash":"1561362bfc8b07eeca9e43b997431177a3b7601a","modified":1605609346756},{"_id":"public/algorithm/leetcode-33-search-in-rotated-sorted-array/index.html","hash":"4e1c329df7da6db9e1cc8eaa15e2159986c681e7","modified":1607587146319},{"_id":"public/tags/LeetCode/index.html","hash":"e260b5ae0694008a845bb6b44fb6c311965d3511","modified":1621496966152},{"_id":"public/algorithm/leetcode-33-search-in-rotated-sorted-array/img2.jpg","hash":"8839af294b39128cc5ebac6602b4432c78f1f702","modified":1605609419212},{"_id":"public/algorithm/leetcode-33-search-in-rotated-sorted-array/img6.jpg","hash":"8839af294b39128cc5ebac6602b4432c78f1f702","modified":1605609419212},{"_id":"public/algorithm/leetcode-33-search-in-rotated-sorted-array/img3.jpg","hash":"91dc5aa98d0e31eea2c8a7e06aa02a93c2fed481","modified":1605609419212},{"_id":"public/algorithm/leetcode-33-search-in-rotated-sorted-array/img7.jpg","hash":"99da6e3b4c7064128818cd54cf48f54464a4b379","modified":1605609419212},{"_id":"public/algorithm/leetcode-33-search-in-rotated-sorted-array/img8.jpg","hash":"02e2ce27e3ec791a9f78b746b321e90def906ca3","modified":1605609419212},{"_id":"public/algorithm/leetcode-33-search-in-rotated-sorted-array/img1.png","hash":"1561362bfc8b07eeca9e43b997431177a3b7601a","modified":1605609419212},{"_id":"source/_posts/-.md","hash":"e8d482206efd10d16cc8d6dea31c43267e2427ab","modified":1609321383929},{"_id":"source/_posts/-/1.jpeg","hash":"7ab7e4f532a7ceca75c6b9dbeffe4512883483f6","modified":1606125898681},{"_id":"source/_posts/-/2.jpeg","hash":"e8afe7e8b17d1ee02551c2c6956f24fe802ad147","modified":1606125894245},{"_id":"public/algorithms/tong-bu-he-yi-bu-bian-cheng-ru-he-bing-xing-xie-tong-yi-ge-ri-zhi-wen-jian-shi-jian/index.html","hash":"cd978c6fe4afa24745ca8dfe9fac45b763a33604","modified":1609321386855},{"_id":"public/categories/Algorithms/index.html","hash":"ec6c175db47e3bf46eb7844922e630d6429cd5a2","modified":1621496966152},{"_id":"public/tags/Algorithms/index.html","hash":"1738b0d264adc8d59a70cc7733020947ecd53be7","modified":1621496966152},{"_id":"public/tags/OS/index.html","hash":"47607b88ea60c568cad10ded051f0ee45a121cec","modified":1621496966152},{"_id":"public/algorithms/tong-bu-he-yi-bu-bian-cheng-ru-he-bing-xing-xie-tong-yi-ge-ri-zhi-wen-jian-shi-jian/1.jpeg","hash":"7ab7e4f532a7ceca75c6b9dbeffe4512883483f6","modified":1606208305818},{"_id":"public/algorithms/tong-bu-he-yi-bu-bian-cheng-ru-he-bing-xing-xie-tong-yi-ge-ri-zhi-wen-jian-shi-jian/2.jpeg","hash":"e8afe7e8b17d1ee02551c2c6956f24fe802ad147","modified":1606208305818},{"_id":"source/_posts/GPU-in-Pytorch-.md","hash":"db5570eb8b4bd75b700b78aca156ae768433d4d7","modified":1610694623263},{"_id":"source/_posts/-in-Pytorch.md","hash":"359fac6de0a159566dfeb31a9200758eb18eb270","modified":1606287881380},{"_id":"public/pytorch/gpu-in-pytorch-bing-xing-he-fen-bu-shi-shi-jian/index.html","hash":"eebcf3beb5a8201f3f89177942daf58d29fd34e8","modified":1621496966152},{"_id":"public/pytorch/bing-xing-he-fen-bu-shi-xun-lian-in-pytorch/index.html","hash":"737e7305cf12eab004519847a2160137caa2ee0c","modified":1606386112132},{"_id":"public/categories/Pytorch/index.html","hash":"5ec3f29b8eba47e01bdd7d68937fb04e3abdfd28","modified":1621496966152},{"_id":"public/tags/Pytorch/index.html","hash":"bc125a8a3b996ea92c6419ef1e53592dc54c029b","modified":1621496966152},{"_id":"public/tags/CUDA/index.html","hash":"b65bd52debf3d1665137fece679a2392ed94614d","modified":1621496966152},{"_id":"public/tags/GPU/index.html","hash":"63aa4fa437426990ddbef402c91ee9781eb72d08","modified":1621496966152},{"_id":"public/tags/NLP/index.html","hash":"9602a400454f51e6ff0f75f0cd168ed803d5200b","modified":1607334899261},{"_id":"source/_posts/LeetCode-1-100-.md","hash":"77eea51910993543a022d21d671abebb38afe513","modified":1607587307037},{"_id":"public/sui-bi/leetcode-1-100-shua-ti-you-gan/index.html","hash":"d6b7c25ab9e014df1d395a5e167f0862531aaaae","modified":1607595087858},{"_id":"public/archives/2020/12/index.html","hash":"faf11c3dd956fe257fa51d0e9c0274610cd7321f","modified":1621496966152},{"_id":"source/_posts/LeetCode-115-Distinct-Subsequences.md","hash":"05a024d8dbfe1de678dd477ba116a32fe4225a9d","modified":1607595083217},{"_id":"source/_posts/GPU-in-Pytorch-/1.png","hash":"8a8b4c079a90aaa0773d0e98f8fdbfcc422ff4c8","modified":1607581522220},{"_id":"public/uncategorized/leetcode-115-distinct-subsequences/index.html","hash":"df6d923879f595b76f6fd49ca3876768866534d7","modified":1607594612520},{"_id":"public/pytorch/gpu-in-pytorch-bing-xing-he-fen-bu-shi-shi-jian/1.png","hash":"8a8b4c079a90aaa0773d0e98f8fdbfcc422ff4c8","modified":1607587146319},{"_id":"public/algorithms/leetcode-115-distinct-subsequences/index.html","hash":"4929a9aec73445f3e4a303fd28815be66b3912c3","modified":1608197436991},{"_id":"source/_posts/LeetCode-126-Word-Ladder-II.md","hash":"6f34292345a185b9f366321d21d3493999193250","modified":1608174426076},{"_id":"public/uncategorized/leetcode-126-word-ladder-ii/index.html","hash":"599cc916b1ae47809f51239228dde86bc7698722","modified":1608018948407},{"_id":"source/_posts/132-Palindrome-Partitioning-II.md","hash":"1ef8b00332737a661a80de88df2c339602cfc45c","modified":1608197580529},{"_id":"source/_posts/132-Palindrome-Partitioning-II/1.png","hash":"096aa5522771cf3aed36316ca0d12c74c72e134b","modified":1608195929481},{"_id":"source/_posts/132-Palindrome-Partitioning-II/2.png","hash":"422e51f2570ab261c5032d94209adbbd61332015","modified":1608195894436},{"_id":"source/_posts/132-Palindrome-Partitioning-II/3.png","hash":"f4e046c35a648f60fc4de379f7f968ec775fd084","modified":1608195909990},{"_id":"source/_posts/132-Palindrome-Partitioning-II/4.png","hash":"062fb6dd474e26028b6f1657ca562702cd823313","modified":1608195955378},{"_id":"public/algorithms/132-palindrome-partitioning-ii/index.html","hash":"6581cd78f71163263301c46ca5ffd4e930f746e0","modified":1609320899501},{"_id":"public/algorithms/leetcode-126-word-ladder-ii/index.html","hash":"dba2d6fa991c8a956e67d5867b5eca4c3c707d39","modified":1608197436991},{"_id":"public/archives/page/2/index.html","hash":"86293e4ead733d4d743bd495b3d7ea1a55f80199","modified":1621496966152},{"_id":"public/archives/2020/page/2/index.html","hash":"fcdf974c06d408a834ce336e2be58d23f6a55d3d","modified":1621496966152},{"_id":"public/algorithms/132-palindrome-partitioning-ii/4.png","hash":"062fb6dd474e26028b6f1657ca562702cd823313","modified":1608197436991},{"_id":"public/algorithms/132-palindrome-partitioning-ii/3.png","hash":"f4e046c35a648f60fc4de379f7f968ec775fd084","modified":1608197436991},{"_id":"public/algorithms/132-palindrome-partitioning-ii/1.png","hash":"096aa5522771cf3aed36316ca0d12c74c72e134b","modified":1608197436991},{"_id":"public/algorithms/132-palindrome-partitioning-ii/2.png","hash":"422e51f2570ab261c5032d94209adbbd61332015","modified":1608197436991},{"_id":"source/_posts/Python-.md","hash":"3512c57b605ca584beb714ba774c7575a6625c2a","modified":1609730880190},{"_id":"public/algorithms/python-xia-de-duo-jin-cheng-he-duo-xian-cheng-bian-cheng/index.html","hash":"aad2af0c0dd6ce9aeb5c3eb5a81a43919531cfd1","modified":1621496966152},{"_id":"source/_drafts/2020-.md","hash":"5db353c48c6dee1134a333413fc4505c1fed9702","modified":1609747693230},{"_id":"source/_drafts/.DS_Store","hash":"f885f7f1583a566ec7fd6082465d368806de6966","modified":1621495724038},{"_id":"source/_drafts/996-.md","hash":"1be2218bdfa1655dc0f471b5598caba92d5d7e75","modified":1616410779687},{"_id":"source/_drafts/.md","hash":"cc0fa1391388afaa03e496c6104e5211b25093c3","modified":1620615195929},{"_id":"source/_posts/146-LRU-Cache.md","hash":"3a938e11592d3de0ea23681c7ad9c24ccd56d71b","modified":1611213797970},{"_id":"source/_posts/135-Candy.md","hash":"f811acb7e23ef66471da618209d57c12a86e0e36","modified":1610532233128},{"_id":"source/_posts/139-Word-Break.md","hash":"27667764b5bd85290cb665fb503cf45861b09cc0","modified":1610612969193},{"_id":"source/_posts/147-148-merge-sort.md","hash":"3e47d6a2b33f225caa219e3abce26b67e4db3dd1","modified":1611217685905},{"_id":"source/_posts/.md","hash":"771db4bbf4bd1dffb0d9303dc0d12e48d8ae701b","modified":1621496893153},{"_id":"source/_posts/.md","hash":"c31f7492b2aeb105643539767d5677df1f4d6879","modified":1621495924510},{"_id":"source/_posts/.md","hash":"ef81f31a80934a63ca7e4098b4c6da249a3b1773","modified":1616123210320},{"_id":"source/_posts/-.md","hash":"ac04416c6d7430e77c3c6f96ed81c5ba3c780867","modified":1615345856692},{"_id":"source/_posts/.md","hash":"abc2af4d6c78e59e3b5826d4651aa67427444dc3","modified":1617332001397},{"_id":"public/sui-bi/shuang-chong-si-xiang-zhuan-zai/index.html","hash":"282a485b9bec738fe7183aca032c83a9b2a5b6da","modified":1621496966152},{"_id":"public/sui-bi/guan-yu-wei-lai-de-ji-hua/index.html","hash":"fa27048b79226f8f381691c6f5d0a9117ed0d798","modified":1621496966152},{"_id":"public/sui-bi/quan-li-de-yi-zhi-ru-he-ying-xiang-wo-de-sheng-huo/index.html","hash":"478e377d19012a94253114c5e84c8704096546cf","modified":1621496966152},{"_id":"public/algorithms/tiao-chu-shua-ti-de-zi-wo-huai-yi-zhuan-zai/index.html","hash":"b20e8ec99a19377db1dc2964273d6bcec4a529c9","modified":1621496966152},{"_id":"public/sui-bi/shi-duan-shi-xu-de-zhi-xing-li-fan-si/index.html","hash":"b28e3a24dd0f04b72e637f5f9a99fa5b98559ac8","modified":1621496966152},{"_id":"public/algorithms/147-148-merge-sort/index.html","hash":"a431f1c5f22a5cf764c14a95f5ee2d4571021e71","modified":1621496966152},{"_id":"public/uncategorized/146-lru-cache/index.html","hash":"f41c3366eb11fc4ec9c143e7be726f28991643ee","modified":1621496966152},{"_id":"public/algorithms/139-word-break/index.html","hash":"e8135dc3f579b7d0187570e5dcdc00a849183704","modified":1621496966152},{"_id":"public/algorithms/135-candy/index.html","hash":"3d31a9f2f573519433987de6e4c1ffd47b55091e","modified":1621496966152},{"_id":"public/page/2/index.html","hash":"3775d69cda9c402a7d7e3988e8f85c640659d115","modified":1621496966152},{"_id":"public/archives/page/3/index.html","hash":"d398f7e533fde2787eb450a7a485038c8f84c6c6","modified":1621496966152},{"_id":"public/archives/2021/index.html","hash":"1e825c45963d192b8b9a79d0361eaa5b835b1a26","modified":1621496966152},{"_id":"public/archives/2021/01/index.html","hash":"1c9bd05e56e0af7596463363595a8ae7cdaa4283","modified":1621496966152},{"_id":"public/archives/2021/03/index.html","hash":"97e0096b275b2723cdde04f1ab57a4c1656c1a09","modified":1621496966152},{"_id":"public/tags//index.html","hash":"24c86b626b8748f71be00cdd386714ecc06c4858","modified":1621496966152},{"_id":"public/tags//index.html","hash":"e10af5e7b0c4dcb5cd1be7019464a85f0270128d","modified":1621496966152},{"_id":"public/tags/1984/index.html","hash":"d0afe8567e103452db1ad1f29c48928396920593","modified":1621496966152},{"_id":"public/tags//index.html","hash":"f5c232ab4f4ae84eba0d45896c73766487762f41","modified":1621496966152},{"_id":"public/tags//index.html","hash":"a7f58e4ca2813fbe76620ae28aff058b74b57d1a","modified":1621496966152}],"Category":[{"name":"test","_id":"ckg7piwa500006a2813an1zrb"},{"name":"","_id":"ckg7qrrd000047j280hei7e4u"},{"name":"","_id":"ckh35zvby0001u72804px1qo7"},{"name":"-[Algorithm] -[LeetCode]","_id":"ckhlu9lvi0001w3289jga9zva"},{"name":"-Algorithm -LeetCode","_id":"ckhluawp60000x728ehjadxzq"},{"name":"Algorithm","_id":"ckhlubjrc0000y9282so58qf8"},{"name":"LeetCode","parent":"ckhlubjrc0000y9282so58qf8","_id":"ckhlubjrd0003y928345fh68r"},{"name":"Algorithms","_id":"ckhvqydbp00016z281mnxdhf3"},{"name":"Pytorch","_id":"ckhyotdje0002l928gyqa3gxs"}],"Data":[],"Page":[{"title":"about","date":"2020-10-13T06:35:21.000Z","type":"about","layout":"about","_content":"","source":"about/index.md","raw":"---\ntitle: about\ndate: 2020-10-13 14:35:21\ntype: 'about'\nlayout: 'about'\n---\n","updated":"2020-10-13T06:35:37.056Z","path":"about/index.html","comments":1,"_id":"ckg7lu78t0000bz288lkhb9ig","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"categories","date":"2020-10-13T06:33:52.000Z","type":"categories","layout":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2020-10-13 14:33:52\ntype: 'categories'\nlayout: 'categories'\n---","updated":"2020-10-13T08:12:35.198Z","path":"categories/index.html","_id":"ckg7lu78z0002bz281zevhen5","comments":1,"content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"tags","date":"2018-09-30T10:23:38.000Z","type":"tags","layout":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2018-09-30 18:23:38\ntype: \"tags\"\nlayout: \"tags\"\n---","updated":"2020-10-13T08:13:18.016Z","path":"tags/index.html","_id":"ckg7lu7900003bz282emkhkys","comments":1,"content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"Hello World","_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\ntags: test\ncategories: test\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","slug":"hello-world","published":1,"date":"2020-10-13T08:32:14.454Z","updated":"2020-10-13T08:32:14.454Z","_id":"ckg7lu78w0001bz2813ba5wh9","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><pre class=\" language-bash\"><code class=\"language-bash\">$ hexo new <span class=\"token string\">\"My New Post\"</span></code></pre>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><pre class=\" language-bash\"><code class=\"language-bash\">$ hexo server</code></pre>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><pre class=\" language-bash\"><code class=\"language-bash\">$ hexo generate</code></pre>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><pre class=\" language-bash\"><code class=\"language-bash\">$ hexo deploy</code></pre>\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\">Deployment</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><pre><code class=\"bash\">$ hexo new &quot;My New Post&quot;</code></pre>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><pre><code class=\"bash\">$ hexo server</code></pre>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><pre><code class=\"bash\">$ hexo generate</code></pre>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><pre><code class=\"bash\">$ hexo deploy</code></pre>\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\">Deployment</a></p>\n"},{"title":"","date":"2020-10-13T09:00:43.000Z","summary":"","toc":false,"mathjax":true,"top":true,"cover":true,"_content":"\nblogiOS\n\n<img src=\"Euphonium_Movie_2nd_KV.jpg\" width=\"50%\" height=\"50%\">\n\nblog[pluskid/freemind](http://freemind.pluskid.org) [](http://freemind.pluskid.org/misc/knowledge-accumulate/) \n\n7-8wordpressHexoBlogbloghexo\n\n![](relife-1.png)\n\nblogRelife  \n\n![](relife-2.jpg)","source":"_posts/my-first-blog.md","raw":"---\ntitle: \ndate: 2020-10-13 17:00:43\ncategories: \ntags: \nsummary: \ntoc: false\nmathjax: true\n#password: \n\ntop: true\ncover: true\n\n#img: #feature image\n#coverImg: # cover roll image\n---\n\nblogiOS\n\n<img src=\"Euphonium_Movie_2nd_KV.jpg\" width=\"50%\" height=\"50%\">\n\nblog[pluskid/freemind](http://freemind.pluskid.org) [](http://freemind.pluskid.org/misc/knowledge-accumulate/) \n\n7-8wordpressHexoBlogbloghexo\n\n![](relife-1.png)\n\nblogRelife  \n\n![](relife-2.jpg)","slug":"my-first-blog","published":1,"updated":"2020-11-25T06:26:55.417Z","_id":"ckg7qjivj00037j28eqt5h8o6","comments":1,"layout":"post","photos":[],"link":"","content":"<p>blogiOS</p>\n<img src=\"Euphonium_Movie_2nd_KV.jpg\" width=\"50%\" height=\"50%\">\n\n<p>blog<a href=\"http://freemind.pluskid.org/\">pluskid/freemind</a> <a href=\"http://freemind.pluskid.org/misc/knowledge-accumulate/\"></a> </p>\n<p>7-8wordpressHexoBlogbloghexo</p>\n<p><img src=\"relife-1.png\"></p>\n<p>blogRelife  </p>\n<p><img src=\"relife-2.jpg\"></p>\n","site":{"data":{}},"excerpt":"","more":"<p>blogiOS</p>\n<img src=\"Euphonium_Movie_2nd_KV.jpg\" width=\"50%\" height=\"50%\">\n\n<p>blog<a href=\"http://freemind.pluskid.org/\">pluskid/freemind</a> <a href=\"http://freemind.pluskid.org/misc/knowledge-accumulate/\"></a> </p>\n<p>7-8wordpressHexoBlogbloghexo</p>\n<p><img src=\"relife-1.png\"></p>\n<p>blogRelife  </p>\n<p><img src=\"relife-2.jpg\"></p>\n"},{"title":"","toc":true,"mathjax":true,"top":true,"cover":true,"date":"2020-10-27T06:52:29.000Z","_content":"\n\n\n![2020-07-31](IMG_9373.jpeg)\n\n731   **** \n\n  \n\n\t\n\n\t*** ***\n\n\n\n 10offerOJ   **** \n\n\n\n\n\n\n\n![](2020-07-31.jpg)","source":"_posts/.md","raw":"---\ntitle: \ntoc: true\nmathjax: true\ntop: true\ncover: true\ndate: 2020-10-27 14:52:29\ncategories: \ntags: \n---\n\n\n\n![2020-07-31](IMG_9373.jpeg)\n\n731   **** \n\n  \n\n\t\n\n\t*** ***\n\n\n\n 10offerOJ   **** \n\n\n\n\n\n\n\n![](2020-07-31.jpg)","slug":"","published":1,"updated":"2020-10-28T09:57:17.910Z","_id":"ckgt6w3by0000wx280fap2hbl","comments":1,"layout":"post","photos":[],"link":"","content":"<p></p>\n<p><img src=\"IMG_9373.jpeg\" alt=\"2020-07-31\"></p>\n<p>731   <strong></strong> </p>\n<p>  </p>\n<p>    </p>\n<p>    <strong><em> </em></strong></p>\n<p></p>\n<p> 10offerOJ   <strong></strong> </p>\n<p></p>\n<p></p>\n<p></p>\n<p><img src=\"2020-07-31.jpg\"></p>\n","site":{"data":{}},"excerpt":"","more":"<p></p>\n<p><img src=\"IMG_9373.jpeg\" alt=\"2020-07-31\"></p>\n<p>731   <strong></strong> </p>\n<p>  </p>\n<p>    </p>\n<p>    <strong><em> </em></strong></p>\n<p></p>\n<p> 10offerOJ   <strong></strong> </p>\n<p></p>\n<p></p>\n<p></p>\n<p><img src=\"2020-07-31.jpg\"></p>\n"},{"title":"ubuntu","toc":true,"mathjax":true,"top":false,"cover":true,"date":"2020-11-04T07:25:29.000Z","_content":"\nubuntu 18.04 LTSB \n\n### \n\nipv4ipv6\n\n```bash\nifconfig -a # ipifconfig \n# or\nip a\n```\n\n\n\nipv6ipB 3mins ipUI\n\n```bash\nvi /etc/network/interfaces\n# change\nauto enp1s0 # enp5s0 ifconfig \niface enp1s0 inet static\n\t\taddress x.x.x.x\n\t\tnetmask 255.255.255.0\n\t\tgateway x.x.x.x\n\t\tdns-nameservers 114.114.114.114 8.8.8.8\n\t\t\nsudo ip a flush enp1s0\nsudo systemctl restart networking.service\n```\n\n networking.service  Ubuntu 18.04 LTS  netplan netplanip\n\n```bash\nvi /etc/netplan/50-cloud-init.yaml # yaml   \\t\n# change\n# This file describes the network interfaces available on your system\n# For more information, see netplan(5).\nnetwork:\n  version: 2\n  renderer: networkd\n  ethernets:\n    enp1s0:\n     dhcp4: no\n     addresses: [192.168.1.222/24]\n     gateway4: 192.168.1.1\n     nameservers:\n       addresses: [8.8.8.8,8.8.4.4]\n       \nsudo netplan apply\n# or\nsudo netplan --dubug apply\n```\n\n netplan /etc/netplan/50-cloud-init.yaml StackOverFlow  StackExchange  Ubuntu 16.04  Upgrade Ubuntu 18.04  netplan  /etc/network/interfaces ip\n\n```bash\n# netplan  \nsudo apt install netplan.io # \n```\n\n\n\nipUbuntu 18.04 Upgrade ip24h\n\n```bash\n#  ip  dns \n#  \nifconfig enp1s0 x.x.x.x netmask 255.255.255.0\nroute add default gw x.x.x.x\nvi /etc/resolf.conf\n\n```\n\n\n\n### nvidia-smi  docker \n\nnvidia-smidocker\n\n```bash\nnvidia-smi\nNVIDIA-SMI has failed because it couldnt communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n```\n\n### \n\n Ubuntu ubuntunvidia Ubuntu 18.04 linux\n\n\n\n### \n\n grub ,Advanced options for Ubuntu -> Ubuntu , with linux x.x.x-x-generic  4.15.0-60-generic 4.15.0-122-generic\n\n \n\n```bash\n# \ndpkg --get-selections |grep linux-image\nlinux-image-4.15.0-122-generic\t\t\tdeinstall\nlinux-image-4.15.0-60-generic\t\t\tinstall\nlinux-image-4.15.0-62-generic\t\t\tdeinstall\n\n#  grub  \ngrep menuentry /boot/grub/grub.cfg\nmenuentry 'Ubuntu, with Linux 4.15.0-60-generic' \n...\n```\n\n#### Solution 1: grub\n\n```bash\nvi /etc/default/grub\n# change\nGRUB_DEFAULT=Advanced options for Ubuntu > Ubuntu, with Linux 4.15.0-60-generic\n#   0\nGRUB_DEFAULT = \"1> 4\" #\n\nGRUB_TIMEOUT_STYLE=menu # default: hidden\nGRUB_TIMEOUT=3 # default: 0\n\nsudo update-grub\nsudo reboot\n```\n\n#### Solution 2: \n\n```bash\n#  \nsudo apt remove linux-image-xxx-xx-generic\n# or\nsudo dpkg --purge linux-image-x.x.x-xx-generic\n# \nsudo apt install linux-headers-x.x.x-x-generic linux-image-x.x.x-x-generic\n# \nsudo apt-mark hold linux-image-generic linux-headers-generic\n# \nsudo apt-mark unhold linux-image-generic linux-headers-generic\n```\n\n### Conclusion\n\nnvidiadocker netplan \n\n\n\nReferences:\n\n[How to configure static IP address on Ubuntu 18.04 ](https://linuxconfig.org/how-to-configure-static-ip-address-on-ubuntu-18-04-bionic-beaver-linux)\n\n[How to enable netplan on ubuntu server upgraded from 16.04 to 18.04](https://askubuntu.com/questions/1034711/how-to-enable-netplan-on-ubuntu-server-upgraded-from-16-04-to-18-04)\n\n[ubuntu18.04 ](https://blog.csdn.net/qq_43222384/article/details/90314297)","source":"_posts/ubuntu.md","raw":"---\ntitle: ubuntu\ntoc: true\nmathjax: true\ntop: false\ncover: true\ndate: 2020-11-04 15:25:29\ncategories: \ntags:\n- ubuntu\n- \n- linux\n- grub\n---\n\nubuntu 18.04 LTSB \n\n### \n\nipv4ipv6\n\n```bash\nifconfig -a # ipifconfig \n# or\nip a\n```\n\n\n\nipv6ipB 3mins ipUI\n\n```bash\nvi /etc/network/interfaces\n# change\nauto enp1s0 # enp5s0 ifconfig \niface enp1s0 inet static\n\t\taddress x.x.x.x\n\t\tnetmask 255.255.255.0\n\t\tgateway x.x.x.x\n\t\tdns-nameservers 114.114.114.114 8.8.8.8\n\t\t\nsudo ip a flush enp1s0\nsudo systemctl restart networking.service\n```\n\n networking.service  Ubuntu 18.04 LTS  netplan netplanip\n\n```bash\nvi /etc/netplan/50-cloud-init.yaml # yaml   \\t\n# change\n# This file describes the network interfaces available on your system\n# For more information, see netplan(5).\nnetwork:\n  version: 2\n  renderer: networkd\n  ethernets:\n    enp1s0:\n     dhcp4: no\n     addresses: [192.168.1.222/24]\n     gateway4: 192.168.1.1\n     nameservers:\n       addresses: [8.8.8.8,8.8.4.4]\n       \nsudo netplan apply\n# or\nsudo netplan --dubug apply\n```\n\n netplan /etc/netplan/50-cloud-init.yaml StackOverFlow  StackExchange  Ubuntu 16.04  Upgrade Ubuntu 18.04  netplan  /etc/network/interfaces ip\n\n```bash\n# netplan  \nsudo apt install netplan.io # \n```\n\n\n\nipUbuntu 18.04 Upgrade ip24h\n\n```bash\n#  ip  dns \n#  \nifconfig enp1s0 x.x.x.x netmask 255.255.255.0\nroute add default gw x.x.x.x\nvi /etc/resolf.conf\n\n```\n\n\n\n### nvidia-smi  docker \n\nnvidia-smidocker\n\n```bash\nnvidia-smi\nNVIDIA-SMI has failed because it couldnt communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n```\n\n### \n\n Ubuntu ubuntunvidia Ubuntu 18.04 linux\n\n\n\n### \n\n grub ,Advanced options for Ubuntu -> Ubuntu , with linux x.x.x-x-generic  4.15.0-60-generic 4.15.0-122-generic\n\n \n\n```bash\n# \ndpkg --get-selections |grep linux-image\nlinux-image-4.15.0-122-generic\t\t\tdeinstall\nlinux-image-4.15.0-60-generic\t\t\tinstall\nlinux-image-4.15.0-62-generic\t\t\tdeinstall\n\n#  grub  \ngrep menuentry /boot/grub/grub.cfg\nmenuentry 'Ubuntu, with Linux 4.15.0-60-generic' \n...\n```\n\n#### Solution 1: grub\n\n```bash\nvi /etc/default/grub\n# change\nGRUB_DEFAULT=Advanced options for Ubuntu > Ubuntu, with Linux 4.15.0-60-generic\n#   0\nGRUB_DEFAULT = \"1> 4\" #\n\nGRUB_TIMEOUT_STYLE=menu # default: hidden\nGRUB_TIMEOUT=3 # default: 0\n\nsudo update-grub\nsudo reboot\n```\n\n#### Solution 2: \n\n```bash\n#  \nsudo apt remove linux-image-xxx-xx-generic\n# or\nsudo dpkg --purge linux-image-x.x.x-xx-generic\n# \nsudo apt install linux-headers-x.x.x-x-generic linux-image-x.x.x-x-generic\n# \nsudo apt-mark hold linux-image-generic linux-headers-generic\n# \nsudo apt-mark unhold linux-image-generic linux-headers-generic\n```\n\n### Conclusion\n\nnvidiadocker netplan \n\n\n\nReferences:\n\n[How to configure static IP address on Ubuntu 18.04 ](https://linuxconfig.org/how-to-configure-static-ip-address-on-ubuntu-18-04-bionic-beaver-linux)\n\n[How to enable netplan on ubuntu server upgraded from 16.04 to 18.04](https://askubuntu.com/questions/1034711/how-to-enable-netplan-on-ubuntu-server-upgraded-from-16-04-to-18-04)\n\n[ubuntu18.04 ](https://blog.csdn.net/qq_43222384/article/details/90314297)","slug":"ubuntu","published":1,"updated":"2020-12-10T08:01:27.729Z","_id":"ckh35zvbu0000u7282nma27nl","comments":1,"layout":"post","photos":[],"link":"","content":"<p>ubuntu 18.04 LTSB </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>ipv4ipv6</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">ifconfig</span> -a <span class=\"token comment\" spellcheck=\"true\"># ipifconfig </span>\n<span class=\"token comment\" spellcheck=\"true\"># or</span>\nip a</code></pre>\n<p>ipv6ipB 3mins ipUI</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">vi</span> /etc/network/interfaces\n<span class=\"token comment\" spellcheck=\"true\"># change</span>\nauto enp1s0 <span class=\"token comment\" spellcheck=\"true\"># enp5s0 ifconfig </span>\niface enp1s0 inet static\n        address x.x.x.x\n        netmask 255.255.255.0\n        gateway x.x.x.x\n        dns-nameservers 114.114.114.114 8.8.8.8\n\n<span class=\"token function\">sudo</span> ip a flush enp1s0\n<span class=\"token function\">sudo</span> systemctl restart networking.service</code></pre>\n<p> networking.service  Ubuntu 18.04 LTS  netplan netplanip</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">vi</span> /etc/netplan/50-cloud-init.yaml <span class=\"token comment\" spellcheck=\"true\"># yaml   \\t</span>\n<span class=\"token comment\" spellcheck=\"true\"># change</span>\n<span class=\"token comment\" spellcheck=\"true\"># This file describes the network interfaces available on your system</span>\n<span class=\"token comment\" spellcheck=\"true\"># For more information, see netplan(5).</span>\nnetwork:\n  version: 2\n  renderer: networkd\n  ethernets:\n    enp1s0:\n     dhcp4: no\n     addresses: <span class=\"token punctuation\">[</span>192.168.1.222/24<span class=\"token punctuation\">]</span>\n     gateway4: 192.168.1.1\n     nameservers:\n       addresses: <span class=\"token punctuation\">[</span>8.8.8.8,8.8.4.4<span class=\"token punctuation\">]</span>\n\n<span class=\"token function\">sudo</span> netplan apply\n<span class=\"token comment\" spellcheck=\"true\"># or</span>\n<span class=\"token function\">sudo</span> netplan --dubug apply</code></pre>\n<p> netplan /etc/netplan/50-cloud-init.yaml StackOverFlow  StackExchange  Ubuntu 16.04  Upgrade Ubuntu 18.04  netplan  /etc/network/interfaces ip</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token comment\" spellcheck=\"true\"># netplan  </span>\n<span class=\"token function\">sudo</span> apt <span class=\"token function\">install</span> netplan.io <span class=\"token comment\" spellcheck=\"true\"># </span></code></pre>\n<p>ipUbuntu 18.04 Upgrade ip24h</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token comment\" spellcheck=\"true\">#  ip  dns </span>\n<span class=\"token comment\" spellcheck=\"true\">#  </span>\n<span class=\"token function\">ifconfig</span> enp1s0 x.x.x.x netmask 255.255.255.0\nroute add default gw x.x.x.x\n<span class=\"token function\">vi</span> /etc/resolf.conf\n</code></pre>\n<h3 id=\"nvidia-smi--docker-\"><a href=\"#nvidia-smi--docker-\" class=\"headerlink\" title=\"nvidia-smi  docker \"></a>nvidia-smi  docker </h3><p>nvidia-smidocker</p>\n<pre class=\" language-bash\"><code class=\"language-bash\">nvidia-smi\nNVIDIA-SMI has failed because it couldnt communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.</code></pre>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> Ubuntu ubuntunvidia Ubuntu 18.04 linux</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> grub ,Advanced options for Ubuntu -&gt; Ubuntu , with linux x.x.x-x-generic  4.15.0-60-generic 4.15.0-122-generic</p>\n<p> </p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token comment\" spellcheck=\"true\"># </span>\ndpkg --get-selections <span class=\"token operator\">|</span><span class=\"token function\">grep</span> linux-image\nlinux-image-4.15.0-122-generic            deinstall\nlinux-image-4.15.0-60-generic            <span class=\"token function\">install</span>\nlinux-image-4.15.0-62-generic            deinstall\n\n<span class=\"token comment\" spellcheck=\"true\">#  grub  </span>\n<span class=\"token function\">grep</span> menuentry /boot/grub/grub.cfg\nmenuentry <span class=\"token string\">'Ubuntu, with Linux 4.15.0-60-generic'</span> \n<span class=\"token punctuation\">..</span>.</code></pre>\n<h4 id=\"Solution-1-grub\"><a href=\"#Solution-1-grub\" class=\"headerlink\" title=\"Solution 1: grub\"></a>Solution 1: grub</h4><pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token function\">vi</span> /etc/default/grub\n<span class=\"token comment\" spellcheck=\"true\"># change</span>\nGRUB_DEFAULT<span class=\"token operator\">=</span>Advanced options <span class=\"token keyword\">for</span> Ubuntu <span class=\"token operator\">></span> Ubuntu, with Linux 4.15.0-60-generic\n<span class=\"token comment\" spellcheck=\"true\">#   0</span>\nGRUB_DEFAULT <span class=\"token operator\">=</span> <span class=\"token string\">\"1> 4\"</span> <span class=\"token comment\" spellcheck=\"true\">#</span>\n\nGRUB_TIMEOUT_STYLE<span class=\"token operator\">=</span>menu <span class=\"token comment\" spellcheck=\"true\"># default: hidden</span>\nGRUB_TIMEOUT<span class=\"token operator\">=</span>3 <span class=\"token comment\" spellcheck=\"true\"># default: 0</span>\n\n<span class=\"token function\">sudo</span> update-grub\n<span class=\"token function\">sudo</span> <span class=\"token function\">reboot</span></code></pre>\n<h4 id=\"Solution-2-\"><a href=\"#Solution-2-\" class=\"headerlink\" title=\"Solution 2: \"></a>Solution 2: </h4><pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token comment\" spellcheck=\"true\">#  </span>\n<span class=\"token function\">sudo</span> apt remove linux-image-xxx-xx-generic\n<span class=\"token comment\" spellcheck=\"true\"># or</span>\n<span class=\"token function\">sudo</span> dpkg --purge linux-image-x.x.x-xx-generic\n<span class=\"token comment\" spellcheck=\"true\"># </span>\n<span class=\"token function\">sudo</span> apt <span class=\"token function\">install</span> linux-headers-x.x.x-x-generic linux-image-x.x.x-x-generic\n<span class=\"token comment\" spellcheck=\"true\"># </span>\n<span class=\"token function\">sudo</span> apt-mark hold linux-image-generic linux-headers-generic\n<span class=\"token comment\" spellcheck=\"true\"># </span>\n<span class=\"token function\">sudo</span> apt-mark unhold linux-image-generic linux-headers-generic</code></pre>\n<h3 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h3><p>nvidiadocker netplan </p>\n<p>References:</p>\n<p><a href=\"https://linuxconfig.org/how-to-configure-static-ip-address-on-ubuntu-18-04-bionic-beaver-linux\">How to configure static IP address on Ubuntu 18.04 </a></p>\n<p><a href=\"https://askubuntu.com/questions/1034711/how-to-enable-netplan-on-ubuntu-server-upgraded-from-16-04-to-18-04\">How to enable netplan on ubuntu server upgraded from 16.04 to 18.04</a></p>\n<p><a href=\"https://blog.csdn.net/qq_43222384/article/details/90314297\">ubuntu18.04 </a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>ubuntu 18.04 LTSB </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>ipv4ipv6</p>\n<pre><code class=\"bash\">ifconfig -a # ipifconfig \n# or\nip a</code></pre>\n<p>ipv6ipB 3mins ipUI</p>\n<pre><code class=\"bash\">vi /etc/network/interfaces\n# change\nauto enp1s0 # enp5s0 ifconfig \niface enp1s0 inet static\n        address x.x.x.x\n        netmask 255.255.255.0\n        gateway x.x.x.x\n        dns-nameservers 114.114.114.114 8.8.8.8\n\nsudo ip a flush enp1s0\nsudo systemctl restart networking.service</code></pre>\n<p> networking.service  Ubuntu 18.04 LTS  netplan netplanip</p>\n<pre><code class=\"bash\">vi /etc/netplan/50-cloud-init.yaml # yaml   \\t\n# change\n# This file describes the network interfaces available on your system\n# For more information, see netplan(5).\nnetwork:\n  version: 2\n  renderer: networkd\n  ethernets:\n    enp1s0:\n     dhcp4: no\n     addresses: [192.168.1.222/24]\n     gateway4: 192.168.1.1\n     nameservers:\n       addresses: [8.8.8.8,8.8.4.4]\n\nsudo netplan apply\n# or\nsudo netplan --dubug apply</code></pre>\n<p> netplan /etc/netplan/50-cloud-init.yaml StackOverFlow  StackExchange  Ubuntu 16.04  Upgrade Ubuntu 18.04  netplan  /etc/network/interfaces ip</p>\n<pre><code class=\"bash\"># netplan  \nsudo apt install netplan.io # </code></pre>\n<p>ipUbuntu 18.04 Upgrade ip24h</p>\n<pre><code class=\"bash\">#  ip  dns \n#  \nifconfig enp1s0 x.x.x.x netmask 255.255.255.0\nroute add default gw x.x.x.x\nvi /etc/resolf.conf\n</code></pre>\n<h3 id=\"nvidia-smi--docker-\"><a href=\"#nvidia-smi--docker-\" class=\"headerlink\" title=\"nvidia-smi  docker \"></a>nvidia-smi  docker </h3><p>nvidia-smidocker</p>\n<pre><code class=\"bash\">nvidia-smi\nNVIDIA-SMI has failed because it couldnt communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.</code></pre>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> Ubuntu ubuntunvidia Ubuntu 18.04 linux</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> grub ,Advanced options for Ubuntu -&gt; Ubuntu , with linux x.x.x-x-generic  4.15.0-60-generic 4.15.0-122-generic</p>\n<p> </p>\n<pre><code class=\"bash\"># \ndpkg --get-selections |grep linux-image\nlinux-image-4.15.0-122-generic            deinstall\nlinux-image-4.15.0-60-generic            install\nlinux-image-4.15.0-62-generic            deinstall\n\n#  grub  \ngrep menuentry /boot/grub/grub.cfg\nmenuentry &#39;Ubuntu, with Linux 4.15.0-60-generic&#39; \n...</code></pre>\n<h4 id=\"Solution-1-grub\"><a href=\"#Solution-1-grub\" class=\"headerlink\" title=\"Solution 1: grub\"></a>Solution 1: grub</h4><pre><code class=\"bash\">vi /etc/default/grub\n# change\nGRUB_DEFAULT=Advanced options for Ubuntu &gt; Ubuntu, with Linux 4.15.0-60-generic\n#   0\nGRUB_DEFAULT = &quot;1&gt; 4&quot; #\n\nGRUB_TIMEOUT_STYLE=menu # default: hidden\nGRUB_TIMEOUT=3 # default: 0\n\nsudo update-grub\nsudo reboot</code></pre>\n<h4 id=\"Solution-2-\"><a href=\"#Solution-2-\" class=\"headerlink\" title=\"Solution 2: \"></a>Solution 2: </h4><pre><code class=\"bash\">#  \nsudo apt remove linux-image-xxx-xx-generic\n# or\nsudo dpkg --purge linux-image-x.x.x-xx-generic\n# \nsudo apt install linux-headers-x.x.x-x-generic linux-image-x.x.x-x-generic\n# \nsudo apt-mark hold linux-image-generic linux-headers-generic\n# \nsudo apt-mark unhold linux-image-generic linux-headers-generic</code></pre>\n<h3 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h3><p>nvidiadocker netplan </p>\n<p>References:</p>\n<p><a href=\"https://linuxconfig.org/how-to-configure-static-ip-address-on-ubuntu-18-04-bionic-beaver-linux\">How to configure static IP address on Ubuntu 18.04 </a></p>\n<p><a href=\"https://askubuntu.com/questions/1034711/how-to-enable-netplan-on-ubuntu-server-upgraded-from-16-04-to-18-04\">How to enable netplan on ubuntu server upgraded from 16.04 to 18.04</a></p>\n<p><a href=\"https://blog.csdn.net/qq_43222384/article/details/90314297\">ubuntu18.04 </a></p>\n"},{"title":"LeetCode 33. Search in Rotated Sorted Array","toc":true,"mathjax":true,"top":false,"cover":true,"date":"2020-11-17T08:19:58.000Z","updated":"2020-12-10T08:01:36.687Z","_content":"\n### LeetCode 33. Search in Rotated Sorted Array\n\n![](img1.png)\n\nif\n\n#### \n\ntarget $O(log(n))$$O(log(n))$start, mid, end \n\n- start  mid:\n\nmid > start :  in left\n\n![](img3.jpg)\n\nmid < start :  in left:\n\n![](img2.jpg)\n\n- mid  end\n\nmid < end:  in leftend = mid\n\n![](img6.jpg)\n\nmid > end :  in right, start = mid\n\n![](img7.jpg)\n\nmid  end\n\n![](img8.jpg)\n\nin right mid in right midvalue start = mid + 1 \n\n```python\nwhile start < end:\n\tmid = (start + end ) //2\n\tif nums[start] > nums[end]:\n\t\tstart = mid + 1\n\telse:\n\t\tend = mid\nbias = start\n```\n\nmid  midtarget\n\n```python\nstart = 0\nend = len(nums) - 1\nwhile start <= end:\n\tmid = (start+end) // 2\n\tmid_pos = (mid + bias) \t% len(nums)\n\tval = nums[mid_pos]\n\tif target == value:\n\t\treturn mid_pos\n\tif target < value:\n\t\tend = mid - 1\n\telse:\n\t\tstart = mid + 1\n    \nreturn -1\n```\n\n\n\nTime Complexity: $O(log(n))$\n\nSpace Complexity: $O(1)$\n\n#### \n\n22,[4 5 6 7 1 2 3 ] [4 5 6 7 ][1 2 3 ]target-inf or inf\n\n[ 4 5 6 7 1 2 3]  target = 5 [ 4 5 6 7 inf inf inf ]\n\n[ 4 5 6 7 1 2 3]  target = 2 [ -inf -inf - inf -inf 1 2 3]\n\nnums[mid]valvaltargetvalvaltarget-inf or inf\n\n- nums[mid]  target : \n\n```python\nnums[mid] > nums[0] and target > nums[0]\nor\nnums[mid] < nums[0] and target < nums[0]\n```\n\n\n\n- nums[mid]  target \n\n```python\nnums[mid] > nums[0] and target < nums[0]\nor\nnums[mid] < nums[0] and target > nums[0]\n```\n\nnums[mid]valnumstarget-inf or inf\n\n```python\nlo = 0\nhi = len(nums) - 1\n\nwhile lo <= hi:\n\tmid = (lo+hi) // 2\n\tval = nums[mid]\n\tif (val > nums[0] ) == (target > nums[0]):\n\t\tpass\n\telse:\n\t\tval =  float('-inf') if target < nums[0] else float('inf')\n   \n\tif val < target:\n\t\tlo = mid + 1\n\telif val > target:\n\t\thi = mid - 1\n\telse:\n\t\treturn mid\n      \n  return -1\n```\n\nTime Complexity: $O(log(n))$\n\nSpace Complexity: $O(1)$\n\n#### \n\n\n\n target\n\n```python\nlo = 0\nhi = len(nums) - 1\n\nwhile lo <= hi:\n\tmid = (lo+hi) // 2\n\tval = nums[mid]\n\tif target == val:\n\t\treturn mid\n\t\t# lo-mid \n\tif nums[lo] <= val:\n\t\tif target >= nums[lo] and target < nums[mid]:\n\t\t\thi = mid - 1\n\t\telse:\n\t\t\tlo = mid + 1\n\telse: # mid-hi \n\t\tif target > nums[mid] and target <= nums[hi]:\n\t\t\tlo = mid + 1\n\t\telse:\n\t\t\thi = mid - 1\n```\n\nTime Complexity: $O(log(n))$\n\nSpace Complexity: $O(1)$\n\n\n\n### Conclusion\n\n$log(n)$target  nums[mid]nums[mid]iftargettarget\n\n\n\nReference:\n\n[LeetCode 33. Search in Rotated Sorted Array](https://leetcode.wang/leetCode-33-Search-in-Rotated-Sorted-Array.html)\n\n","source":"_posts/LeetCode-33-Search-in-Rotated-Sorted-Array.md","raw":"---\ntitle: LeetCode 33. Search in Rotated Sorted Array\ntoc: true\nmathjax: true\ntop: false\ncover: true\ndate: 2020-11-17 16:19:58\nupdated:\ncategories: Algorithm\ntags:\n\t- Algorithm\n\t- LeetCode\n---\n\n### LeetCode 33. Search in Rotated Sorted Array\n\n![](img1.png)\n\nif\n\n#### \n\ntarget $O(log(n))$$O(log(n))$start, mid, end \n\n- start  mid:\n\nmid > start :  in left\n\n![](img3.jpg)\n\nmid < start :  in left:\n\n![](img2.jpg)\n\n- mid  end\n\nmid < end:  in leftend = mid\n\n![](img6.jpg)\n\nmid > end :  in right, start = mid\n\n![](img7.jpg)\n\nmid  end\n\n![](img8.jpg)\n\nin right mid in right midvalue start = mid + 1 \n\n```python\nwhile start < end:\n\tmid = (start + end ) //2\n\tif nums[start] > nums[end]:\n\t\tstart = mid + 1\n\telse:\n\t\tend = mid\nbias = start\n```\n\nmid  midtarget\n\n```python\nstart = 0\nend = len(nums) - 1\nwhile start <= end:\n\tmid = (start+end) // 2\n\tmid_pos = (mid + bias) \t% len(nums)\n\tval = nums[mid_pos]\n\tif target == value:\n\t\treturn mid_pos\n\tif target < value:\n\t\tend = mid - 1\n\telse:\n\t\tstart = mid + 1\n    \nreturn -1\n```\n\n\n\nTime Complexity: $O(log(n))$\n\nSpace Complexity: $O(1)$\n\n#### \n\n22,[4 5 6 7 1 2 3 ] [4 5 6 7 ][1 2 3 ]target-inf or inf\n\n[ 4 5 6 7 1 2 3]  target = 5 [ 4 5 6 7 inf inf inf ]\n\n[ 4 5 6 7 1 2 3]  target = 2 [ -inf -inf - inf -inf 1 2 3]\n\nnums[mid]valvaltargetvalvaltarget-inf or inf\n\n- nums[mid]  target : \n\n```python\nnums[mid] > nums[0] and target > nums[0]\nor\nnums[mid] < nums[0] and target < nums[0]\n```\n\n\n\n- nums[mid]  target \n\n```python\nnums[mid] > nums[0] and target < nums[0]\nor\nnums[mid] < nums[0] and target > nums[0]\n```\n\nnums[mid]valnumstarget-inf or inf\n\n```python\nlo = 0\nhi = len(nums) - 1\n\nwhile lo <= hi:\n\tmid = (lo+hi) // 2\n\tval = nums[mid]\n\tif (val > nums[0] ) == (target > nums[0]):\n\t\tpass\n\telse:\n\t\tval =  float('-inf') if target < nums[0] else float('inf')\n   \n\tif val < target:\n\t\tlo = mid + 1\n\telif val > target:\n\t\thi = mid - 1\n\telse:\n\t\treturn mid\n      \n  return -1\n```\n\nTime Complexity: $O(log(n))$\n\nSpace Complexity: $O(1)$\n\n#### \n\n\n\n target\n\n```python\nlo = 0\nhi = len(nums) - 1\n\nwhile lo <= hi:\n\tmid = (lo+hi) // 2\n\tval = nums[mid]\n\tif target == val:\n\t\treturn mid\n\t\t# lo-mid \n\tif nums[lo] <= val:\n\t\tif target >= nums[lo] and target < nums[mid]:\n\t\t\thi = mid - 1\n\t\telse:\n\t\t\tlo = mid + 1\n\telse: # mid-hi \n\t\tif target > nums[mid] and target <= nums[hi]:\n\t\t\tlo = mid + 1\n\t\telse:\n\t\t\thi = mid - 1\n```\n\nTime Complexity: $O(log(n))$\n\nSpace Complexity: $O(1)$\n\n\n\n### Conclusion\n\n$log(n)$target  nums[mid]nums[mid]iftargettarget\n\n\n\nReference:\n\n[LeetCode 33. Search in Rotated Sorted Array](https://leetcode.wang/leetCode-33-Search-in-Rotated-Sorted-Array.html)\n\n","slug":"LeetCode-33-Search-in-Rotated-Sorted-Array","published":1,"_id":"ckhlu9lv60000w328appuchpc","comments":1,"layout":"post","photos":[],"link":"","content":"<h3 id=\"LeetCode-33-Search-in-Rotated-Sorted-Array\"><a href=\"#LeetCode-33-Search-in-Rotated-Sorted-Array\" class=\"headerlink\" title=\"LeetCode 33. Search in Rotated Sorted Array\"></a>LeetCode 33. Search in Rotated Sorted Array</h3><p><img src=\"img1.png\"></p>\n<p>if</p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p>target $O(log(n))$$O(log(n))$start, mid, end </p>\n<ul>\n<li>start  mid:</li>\n</ul>\n<p>mid &gt; start :  in left</p>\n<p><img src=\"img3.jpg\"></p>\n<p>mid &lt; start :  in left:</p>\n<p><img src=\"img2.jpg\"></p>\n<ul>\n<li>mid  end</li>\n</ul>\n<p>mid &lt; end:  in leftend = mid</p>\n<p><img src=\"img6.jpg\"></p>\n<p>mid &gt; end :  in right, start = mid</p>\n<p><img src=\"img7.jpg\"></p>\n<p>mid  end</p>\n<p><img src=\"img8.jpg\"></p>\n<p>in right mid in right midvalue start = mid + 1 </p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token keyword\">while</span> start <span class=\"token operator\">&lt;</span> end<span class=\"token punctuation\">:</span>\n    mid <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>start <span class=\"token operator\">+</span> end <span class=\"token punctuation\">)</span> <span class=\"token operator\">//</span><span class=\"token number\">2</span>\n    <span class=\"token keyword\">if</span> nums<span class=\"token punctuation\">[</span>start<span class=\"token punctuation\">]</span> <span class=\"token operator\">></span> nums<span class=\"token punctuation\">[</span>end<span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n        start <span class=\"token operator\">=</span> mid <span class=\"token operator\">+</span> <span class=\"token number\">1</span>\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n        end <span class=\"token operator\">=</span> mid\nbias <span class=\"token operator\">=</span> start</code></pre>\n<p>mid  midtarget</p>\n<pre class=\" language-python\"><code class=\"language-python\">start <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\nend <span class=\"token operator\">=</span> len<span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> <span class=\"token number\">1</span>\n<span class=\"token keyword\">while</span> start <span class=\"token operator\">&lt;=</span> end<span class=\"token punctuation\">:</span>\n    mid <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>start<span class=\"token operator\">+</span>end<span class=\"token punctuation\">)</span> <span class=\"token operator\">//</span> <span class=\"token number\">2</span>\n    mid_pos <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>mid <span class=\"token operator\">+</span> bias<span class=\"token punctuation\">)</span>     <span class=\"token operator\">%</span> len<span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">)</span>\n    val <span class=\"token operator\">=</span> nums<span class=\"token punctuation\">[</span>mid_pos<span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">if</span> target <span class=\"token operator\">==</span> value<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> mid_pos\n    <span class=\"token keyword\">if</span> target <span class=\"token operator\">&lt;</span> value<span class=\"token punctuation\">:</span>\n        end <span class=\"token operator\">=</span> mid <span class=\"token operator\">-</span> <span class=\"token number\">1</span>\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n        start <span class=\"token operator\">=</span> mid <span class=\"token operator\">+</span> <span class=\"token number\">1</span>\n\n<span class=\"token keyword\">return</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span></code></pre>\n<p>Time Complexity: $O(log(n))$</p>\n<p>Space Complexity: $O(1)$</p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p>22,[4 5 6 7 1 2 3 ] [4 5 6 7 ][1 2 3 ]target-inf or inf</p>\n<p>[ 4 5 6 7 1 2 3]  target = 5 [ 4 5 6 7 inf inf inf ]</p>\n<p>[ 4 5 6 7 1 2 3]  target = 2 [ -inf -inf - inf -inf 1 2 3]</p>\n<p>nums[mid]valvaltargetvalvaltarget-inf or inf</p>\n<ul>\n<li>nums[mid]  target : </li>\n</ul>\n<pre class=\" language-python\"><code class=\"language-python\">nums<span class=\"token punctuation\">[</span>mid<span class=\"token punctuation\">]</span> <span class=\"token operator\">></span> nums<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">and</span> target <span class=\"token operator\">></span> nums<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n<span class=\"token operator\">or</span>\nnums<span class=\"token punctuation\">[</span>mid<span class=\"token punctuation\">]</span> <span class=\"token operator\">&lt;</span> nums<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">and</span> target <span class=\"token operator\">&lt;</span> nums<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span></code></pre>\n<ul>\n<li>nums[mid]  target </li>\n</ul>\n<pre class=\" language-python\"><code class=\"language-python\">nums<span class=\"token punctuation\">[</span>mid<span class=\"token punctuation\">]</span> <span class=\"token operator\">></span> nums<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">and</span> target <span class=\"token operator\">&lt;</span> nums<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n<span class=\"token operator\">or</span>\nnums<span class=\"token punctuation\">[</span>mid<span class=\"token punctuation\">]</span> <span class=\"token operator\">&lt;</span> nums<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">and</span> target <span class=\"token operator\">></span> nums<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span></code></pre>\n<p>nums[mid]valnumstarget-inf or inf</p>\n<pre class=\" language-python\"><code class=\"language-python\">lo <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\nhi <span class=\"token operator\">=</span> len<span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> <span class=\"token number\">1</span>\n\n<span class=\"token keyword\">while</span> lo <span class=\"token operator\">&lt;=</span> hi<span class=\"token punctuation\">:</span>\n    mid <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>lo<span class=\"token operator\">+</span>hi<span class=\"token punctuation\">)</span> <span class=\"token operator\">//</span> <span class=\"token number\">2</span>\n    val <span class=\"token operator\">=</span> nums<span class=\"token punctuation\">[</span>mid<span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>val <span class=\"token operator\">></span> nums<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> <span class=\"token punctuation\">(</span>target <span class=\"token operator\">></span> nums<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">pass</span>\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n        val <span class=\"token operator\">=</span>  float<span class=\"token punctuation\">(</span><span class=\"token string\">'-inf'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">if</span> target <span class=\"token operator\">&lt;</span> nums<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">else</span> float<span class=\"token punctuation\">(</span><span class=\"token string\">'inf'</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">if</span> val <span class=\"token operator\">&lt;</span> target<span class=\"token punctuation\">:</span>\n        lo <span class=\"token operator\">=</span> mid <span class=\"token operator\">+</span> <span class=\"token number\">1</span>\n    <span class=\"token keyword\">elif</span> val <span class=\"token operator\">></span> target<span class=\"token punctuation\">:</span>\n        hi <span class=\"token operator\">=</span> mid <span class=\"token operator\">-</span> <span class=\"token number\">1</span>\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> mid\n\n  <span class=\"token keyword\">return</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span></code></pre>\n<p>Time Complexity: $O(log(n))$</p>\n<p>Space Complexity: $O(1)$</p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p></p>\n<p> target</p>\n<pre class=\" language-python\"><code class=\"language-python\">lo <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\nhi <span class=\"token operator\">=</span> len<span class=\"token punctuation\">(</span>nums<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> <span class=\"token number\">1</span>\n\n<span class=\"token keyword\">while</span> lo <span class=\"token operator\">&lt;=</span> hi<span class=\"token punctuation\">:</span>\n    mid <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>lo<span class=\"token operator\">+</span>hi<span class=\"token punctuation\">)</span> <span class=\"token operator\">//</span> <span class=\"token number\">2</span>\n    val <span class=\"token operator\">=</span> nums<span class=\"token punctuation\">[</span>mid<span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">if</span> target <span class=\"token operator\">==</span> val<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> mid\n        <span class=\"token comment\" spellcheck=\"true\"># lo-mid </span>\n    <span class=\"token keyword\">if</span> nums<span class=\"token punctuation\">[</span>lo<span class=\"token punctuation\">]</span> <span class=\"token operator\">&lt;=</span> val<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> target <span class=\"token operator\">>=</span> nums<span class=\"token punctuation\">[</span>lo<span class=\"token punctuation\">]</span> <span class=\"token operator\">and</span> target <span class=\"token operator\">&lt;</span> nums<span class=\"token punctuation\">[</span>mid<span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n            hi <span class=\"token operator\">=</span> mid <span class=\"token operator\">-</span> <span class=\"token number\">1</span>\n        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n            lo <span class=\"token operator\">=</span> mid <span class=\"token operator\">+</span> <span class=\"token number\">1</span>\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span> <span class=\"token comment\" spellcheck=\"true\"># mid-hi </span>\n        <span class=\"token keyword\">if</span> target <span class=\"token operator\">></span> nums<span class=\"token punctuation\">[</span>mid<span class=\"token punctuation\">]</span> <span class=\"token operator\">and</span> target <span class=\"token operator\">&lt;=</span> nums<span class=\"token punctuation\">[</span>hi<span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n            lo <span class=\"token operator\">=</span> mid <span class=\"token operator\">+</span> <span class=\"token number\">1</span>\n        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n            hi <span class=\"token operator\">=</span> mid <span class=\"token operator\">-</span> <span class=\"token number\">1</span></code></pre>\n<p>Time Complexity: $O(log(n))$</p>\n<p>Space Complexity: $O(1)$</p>\n<h3 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h3><p>$log(n)$target  nums[mid]nums[mid]iftargettarget</p>\n<p>Reference:</p>\n<p><a href=\"https://leetcode.wang/leetCode-33-Search-in-Rotated-Sorted-Array.html\">LeetCode 33. Search in Rotated Sorted Array</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"LeetCode-33-Search-in-Rotated-Sorted-Array\"><a href=\"#LeetCode-33-Search-in-Rotated-Sorted-Array\" class=\"headerlink\" title=\"LeetCode 33. Search in Rotated Sorted Array\"></a>LeetCode 33. Search in Rotated Sorted Array</h3><p><img src=\"img1.png\"></p>\n<p>if</p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p>target $O(log(n))$$O(log(n))$start, mid, end </p>\n<ul>\n<li>start  mid:</li>\n</ul>\n<p>mid &gt; start :  in left</p>\n<p><img src=\"img3.jpg\"></p>\n<p>mid &lt; start :  in left:</p>\n<p><img src=\"img2.jpg\"></p>\n<ul>\n<li>mid  end</li>\n</ul>\n<p>mid &lt; end:  in leftend = mid</p>\n<p><img src=\"img6.jpg\"></p>\n<p>mid &gt; end :  in right, start = mid</p>\n<p><img src=\"img7.jpg\"></p>\n<p>mid  end</p>\n<p><img src=\"img8.jpg\"></p>\n<p>in right mid in right midvalue start = mid + 1 </p>\n<pre><code class=\"python\">while start &lt; end:\n    mid = (start + end ) //2\n    if nums[start] &gt; nums[end]:\n        start = mid + 1\n    else:\n        end = mid\nbias = start</code></pre>\n<p>mid  midtarget</p>\n<pre><code class=\"python\">start = 0\nend = len(nums) - 1\nwhile start &lt;= end:\n    mid = (start+end) // 2\n    mid_pos = (mid + bias)     % len(nums)\n    val = nums[mid_pos]\n    if target == value:\n        return mid_pos\n    if target &lt; value:\n        end = mid - 1\n    else:\n        start = mid + 1\n\nreturn -1</code></pre>\n<p>Time Complexity: $O(log(n))$</p>\n<p>Space Complexity: $O(1)$</p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p>22,[4 5 6 7 1 2 3 ] [4 5 6 7 ][1 2 3 ]target-inf or inf</p>\n<p>[ 4 5 6 7 1 2 3]  target = 5 [ 4 5 6 7 inf inf inf ]</p>\n<p>[ 4 5 6 7 1 2 3]  target = 2 [ -inf -inf - inf -inf 1 2 3]</p>\n<p>nums[mid]valvaltargetvalvaltarget-inf or inf</p>\n<ul>\n<li>nums[mid]  target : </li>\n</ul>\n<pre><code class=\"python\">nums[mid] &gt; nums[0] and target &gt; nums[0]\nor\nnums[mid] &lt; nums[0] and target &lt; nums[0]</code></pre>\n<ul>\n<li>nums[mid]  target </li>\n</ul>\n<pre><code class=\"python\">nums[mid] &gt; nums[0] and target &lt; nums[0]\nor\nnums[mid] &lt; nums[0] and target &gt; nums[0]</code></pre>\n<p>nums[mid]valnumstarget-inf or inf</p>\n<pre><code class=\"python\">lo = 0\nhi = len(nums) - 1\n\nwhile lo &lt;= hi:\n    mid = (lo+hi) // 2\n    val = nums[mid]\n    if (val &gt; nums[0] ) == (target &gt; nums[0]):\n        pass\n    else:\n        val =  float(&#39;-inf&#39;) if target &lt; nums[0] else float(&#39;inf&#39;)\n\n    if val &lt; target:\n        lo = mid + 1\n    elif val &gt; target:\n        hi = mid - 1\n    else:\n        return mid\n\n  return -1</code></pre>\n<p>Time Complexity: $O(log(n))$</p>\n<p>Space Complexity: $O(1)$</p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p></p>\n<p> target</p>\n<pre><code class=\"python\">lo = 0\nhi = len(nums) - 1\n\nwhile lo &lt;= hi:\n    mid = (lo+hi) // 2\n    val = nums[mid]\n    if target == val:\n        return mid\n        # lo-mid \n    if nums[lo] &lt;= val:\n        if target &gt;= nums[lo] and target &lt; nums[mid]:\n            hi = mid - 1\n        else:\n            lo = mid + 1\n    else: # mid-hi \n        if target &gt; nums[mid] and target &lt;= nums[hi]:\n            lo = mid + 1\n        else:\n            hi = mid - 1</code></pre>\n<p>Time Complexity: $O(log(n))$</p>\n<p>Space Complexity: $O(1)$</p>\n<h3 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h3><p>$log(n)$target  nums[mid]nums[mid]iftargettarget</p>\n<p>Reference:</p>\n<p><a href=\"https://leetcode.wang/leetCode-33-Search-in-Rotated-Sorted-Array.html\">LeetCode 33. Search in Rotated Sorted Array</a></p>\n"},{"title":"()","toc":true,"mathjax":true,"top":false,"cover":true,"date":"2020-11-23T08:27:20.000Z","updated":"2020-12-30T09:43:03.929Z","_content":"\nRabbitMQ HTTP  Rabbit-Consumer I/ORabbitMQ Producer-Consumerprint\n\nOS\n\n#### \n\nOS/ //CPUOSIOIO/OS//\n\n> \n>\n> \n\n socket  recv() recv()  recv()  recv() \n\nsocket  send()TCP send() \n\n#### \n\n\n\n> CPU\n>\n> CPU \n\n![](1.jpeg)\n\n![](2.jpeg)\n\n#### \n\n\n\n> \n>\n> \n\n 2\n\n/OS\n\nOS/OSOS\n\n> \n\n\n\n\n\n cuda GPUcudaCPUCPUcuda\n\nPythonGIL, Global Interpreter LockPython GILPython\n\n```python\nimport threading, multiprocessing\n\ndef loop():\n    x = 0\n    while True:\n        x = x^1\n\t\t\nfor i in range(multiprocessing.cpu_count()):\n    t = threading.Thread(target = loop)\n    t.start()\n```\n\nCPU100%C++/Java4400%\n\nGIL100cudapythonGIL\n\nPythonGILHTTPproducer-consumer \n\n queue.Queue Queueproducer-consumer\n\n```python\nfrom queue import Queue\nfrom threading import Thread\n\ndef producer(out_q):\n\twhile True:\n\t\tout_q.put(data)\n        \ndef consumer(in_q):\n\twhile True:\n\t\tdata = in_q.get()\n\t\t\t...\n    \t# q \n      in_q.task_done()\n        \nq = Queue()\nt1 = Thread(target=consumer, args=(q,))\nt2 = Thread(taget=producer, args=(q,))\nt1.start()\nt2.start()\n\n# wait for all produced items to be consumed\nq.join()\n```\n\n\n\nqQueue\n\n```python\nq = Queue(100)\n\ntry:\n    data = q.get(block=False)\nexcept queue.Empty:\n    pass\n    \ntry:\n    q.put(item, timeout=5.0)\nexcept queue.Full:\n    log.warning('queued item %r discarded!', item)\n```\n\n\n\n### \n\ntornadohttprequest_bodyq.put()tornado producerconsumer\n\n```python\nfrom eliot import log_call, start_action, to_file\nclass LogHandler(tornado.web.RequestHandler):\n\t# eliot input, output\n\t@log_call\n\tdef post(self, *args, **kwargs):\n\t\ttry:\n\t\t\tself.timestamp = time.ctime()\n\t\t\tself.recv_json = json.loads(self.request.body, strict=False)\n\t\t\tq.put((self.timestamp, self.recv_json ))\n\t\t\toutput_dic = {\n                'status': '1',\n                'result': 'success'\n      }\n\t\texcept Exception as e:\n\t\t\tprint('LogHandler Error: ', e)\n\t\t\treturn\n          \n\n# eliot.start_action  with \ndef consume_msg(queue):\n\twhile True:\n\t\twith start_action(action_type='consume_msg', lenghth = queue.qsize()):\n\t\t\ttry:\n\t\t\t\ttimestamp, msg= q.get()\n\t\t\t\tstart_time = time.time()\n\t\t\t\twith start_action(action_type='save_request_body', timestamp=timestamp,msg=msg):\n\t\t\t\t\tsave_body(msg)\n\t\t\texcept Exception as e:\n\t\t\t\twith start_action(action_type='consume_msg exceptiosn', timestamp=timestamp,e=e, msg=msg):\n\t\t\t\t\tprint('consume_mgs exception : '  , e)\n                    \nconsumer = Process(target=consume_msg, args=(q, ))\nconsumer.daemon = True # \nconsumer.start()\n```\n\n\n\neliot\n\n### RabbiMQ\n\nRabbiMQ \n\n```python\n# rabbitmq init\ncredentials = pika.PlainCredentials(RabbitMQ.USERNAME, RabbitMQ.USERPWD)\nconnection = pika.BlockingConnection(\n                pika.ConnectionParameters(RabbitMQ.HOST, RabbitMQ.PORT,\n                                          credentials=credentials)\n    )\n# channel init and declare\nchannel = connection.channel()\nchannel.exchange_declare(exchange=RabbitMQ.EXCHANGE,\n                             exchange_type=RabbitMQ.EXCHANGE_TYPE,\n                             durable=True)\nchannel.queue_declare(queue=RabbitMQ.QUEUE_NAME_ALG, durable=True)\nchannel.queue_bind(exchange=RabbitMQ.EXCHANGE,\n                       queue=RabbitMQ.QUEUE_NAME_ALG,\n                       routing_key=RabbitMQ.ROUTING_KEY)\nchannel.basic_qos(prefetch_count=1)    # \nchannel.basic_consume(on_message_callback=consumer,\n                          queue=RabbitMQ.QUEUE_NAME_ALG, auto_ack=False)\nprint(' [*] Waiting for messages...')\nchannel.start_consuming()\n\ndef consumer(ch, method, properties, body):\n\tbody = json.loads(body, strict=False)\n\tflag = body['flag']\n\t# process body\n  \n\t# Ack manually\n\tch.basic_ack(delivery_tag=method.delivery_tag)\n  \n\n  \n# producer.py\ntry:\n\tcredentials = pika.PlainCredentials(\n                RabbitMQ.USERNAME, RabbitMQ.USERPWD)\n\tconnection = pika.BlockingConnection(\n                pika.ConnectionParameters(RabbitMQ.HOST, RabbitMQ.PORT,\n                                          credentials=credentials)\n            )\n\tchannel = self.connection.channel()\n\tchannel.exchange_declare(exchange=RabbitMQ.EXCHANGE,                                      \t\t\t\t\t\t\t\t\t\t\t\t\t\texchange_type=RabbitMQ.EXCHANGE_TYPE,\n                                          durable=True)\nexcept Exception as e:\n\tpass\n        \nsent_msg = {...}\nbody = json.dumps(sent_msg)\nchannel.basic_publish(exchange=RabbitMQ.EXCHANGE, \t\t\t\t\n                      routing_key=RabbitMQ.ROUTING_KEY,\n                      body=body, \n                      properties=pika.BasicProperties(delivery_mode=2))\n\nchannel.close()\nconnection.close()\n```\n\n\n\n###   IO\n\nIO\n\n> CPUPythonC++/Java\n>\n> IOIOC++/JavaPython\n\nPythonC++/Java\n\n### \n\nPython\n\nPythonasyncioIOasyncioEventLoopEventLoopIO,producer-consumer\n\n```python\nimport asyncio\nimport random\n\nasync def producer(queue, n):\n\tfor x in range(1, n+1):\n\t\tprint('producing : ', x)    \n\t\t# simulate io job\n\t\tawait asyncio.sleep(random.random())\n\t\titem = str(x)\n\t\tawait queue.put(item)\n        \nasync def consume(queue):\n\twhile True:\n\t\titem = await queue.get()\n    # process item\n    print('consuming : ', item)\n    # simulate io \n    await asyncio.sleep(random.random())\n    # notify queue that the item has been processed\n    queue.task_done()\n        \nasync def run(n):\n    queue = asyncio.Queue()\n    # schedule consumer\n    consumer= asyncio.ensure_future(consume(queue))\n    await producer(queue, n)\n    # wait until consumer processed all items\n    await queue.join()\n    # consumer is still awaiting item, cancel it\n    consumer.cancel()\n    \nloop = asyncio.get_event_loop()\nloop.run_until_complete(run(10))\nloop.close()\n```\n\n\n\n### Conclusion\n\n\n\n\n\nReferences:\n\n[Producer/consumer-examlpe_asyncio](https://asyncio.readthedocs.io/en/latest/producer_consumer.html)\n\n[-](https://www.liaoxuefeng.com/wiki/1016959663602400/1017968846697824)\n\n[--](https://www.liaoxuefeng.com/wiki/1016959663602400/1017631469467456)\n\n[-Python_CookBook](https://python3-cookbook.readthedocs.io/zh_CN/latest/c12/p03_communicating_between_threads.html)\n\n[Python](https://juejin.cn/post/6844904039210024967#heading-3)\n\n","source":"_posts/-.md","raw":"---\ntitle: ()\ntoc: true\nmathjax: true\ntop: false\ncover: true\ndate: 2020-11-23 16:27:20\nupdated:\ncategories: Algorithms\ntags: \n\t- Algorithms\n\t- OS\n---\n\nRabbitMQ HTTP  Rabbit-Consumer I/ORabbitMQ Producer-Consumerprint\n\nOS\n\n#### \n\nOS/ //CPUOSIOIO/OS//\n\n> \n>\n> \n\n socket  recv() recv()  recv()  recv() \n\nsocket  send()TCP send() \n\n#### \n\n\n\n> CPU\n>\n> CPU \n\n![](1.jpeg)\n\n![](2.jpeg)\n\n#### \n\n\n\n> \n>\n> \n\n 2\n\n/OS\n\nOS/OSOS\n\n> \n\n\n\n\n\n cuda GPUcudaCPUCPUcuda\n\nPythonGIL, Global Interpreter LockPython GILPython\n\n```python\nimport threading, multiprocessing\n\ndef loop():\n    x = 0\n    while True:\n        x = x^1\n\t\t\nfor i in range(multiprocessing.cpu_count()):\n    t = threading.Thread(target = loop)\n    t.start()\n```\n\nCPU100%C++/Java4400%\n\nGIL100cudapythonGIL\n\nPythonGILHTTPproducer-consumer \n\n queue.Queue Queueproducer-consumer\n\n```python\nfrom queue import Queue\nfrom threading import Thread\n\ndef producer(out_q):\n\twhile True:\n\t\tout_q.put(data)\n        \ndef consumer(in_q):\n\twhile True:\n\t\tdata = in_q.get()\n\t\t\t...\n    \t# q \n      in_q.task_done()\n        \nq = Queue()\nt1 = Thread(target=consumer, args=(q,))\nt2 = Thread(taget=producer, args=(q,))\nt1.start()\nt2.start()\n\n# wait for all produced items to be consumed\nq.join()\n```\n\n\n\nqQueue\n\n```python\nq = Queue(100)\n\ntry:\n    data = q.get(block=False)\nexcept queue.Empty:\n    pass\n    \ntry:\n    q.put(item, timeout=5.0)\nexcept queue.Full:\n    log.warning('queued item %r discarded!', item)\n```\n\n\n\n### \n\ntornadohttprequest_bodyq.put()tornado producerconsumer\n\n```python\nfrom eliot import log_call, start_action, to_file\nclass LogHandler(tornado.web.RequestHandler):\n\t# eliot input, output\n\t@log_call\n\tdef post(self, *args, **kwargs):\n\t\ttry:\n\t\t\tself.timestamp = time.ctime()\n\t\t\tself.recv_json = json.loads(self.request.body, strict=False)\n\t\t\tq.put((self.timestamp, self.recv_json ))\n\t\t\toutput_dic = {\n                'status': '1',\n                'result': 'success'\n      }\n\t\texcept Exception as e:\n\t\t\tprint('LogHandler Error: ', e)\n\t\t\treturn\n          \n\n# eliot.start_action  with \ndef consume_msg(queue):\n\twhile True:\n\t\twith start_action(action_type='consume_msg', lenghth = queue.qsize()):\n\t\t\ttry:\n\t\t\t\ttimestamp, msg= q.get()\n\t\t\t\tstart_time = time.time()\n\t\t\t\twith start_action(action_type='save_request_body', timestamp=timestamp,msg=msg):\n\t\t\t\t\tsave_body(msg)\n\t\t\texcept Exception as e:\n\t\t\t\twith start_action(action_type='consume_msg exceptiosn', timestamp=timestamp,e=e, msg=msg):\n\t\t\t\t\tprint('consume_mgs exception : '  , e)\n                    \nconsumer = Process(target=consume_msg, args=(q, ))\nconsumer.daemon = True # \nconsumer.start()\n```\n\n\n\neliot\n\n### RabbiMQ\n\nRabbiMQ \n\n```python\n# rabbitmq init\ncredentials = pika.PlainCredentials(RabbitMQ.USERNAME, RabbitMQ.USERPWD)\nconnection = pika.BlockingConnection(\n                pika.ConnectionParameters(RabbitMQ.HOST, RabbitMQ.PORT,\n                                          credentials=credentials)\n    )\n# channel init and declare\nchannel = connection.channel()\nchannel.exchange_declare(exchange=RabbitMQ.EXCHANGE,\n                             exchange_type=RabbitMQ.EXCHANGE_TYPE,\n                             durable=True)\nchannel.queue_declare(queue=RabbitMQ.QUEUE_NAME_ALG, durable=True)\nchannel.queue_bind(exchange=RabbitMQ.EXCHANGE,\n                       queue=RabbitMQ.QUEUE_NAME_ALG,\n                       routing_key=RabbitMQ.ROUTING_KEY)\nchannel.basic_qos(prefetch_count=1)    # \nchannel.basic_consume(on_message_callback=consumer,\n                          queue=RabbitMQ.QUEUE_NAME_ALG, auto_ack=False)\nprint(' [*] Waiting for messages...')\nchannel.start_consuming()\n\ndef consumer(ch, method, properties, body):\n\tbody = json.loads(body, strict=False)\n\tflag = body['flag']\n\t# process body\n  \n\t# Ack manually\n\tch.basic_ack(delivery_tag=method.delivery_tag)\n  \n\n  \n# producer.py\ntry:\n\tcredentials = pika.PlainCredentials(\n                RabbitMQ.USERNAME, RabbitMQ.USERPWD)\n\tconnection = pika.BlockingConnection(\n                pika.ConnectionParameters(RabbitMQ.HOST, RabbitMQ.PORT,\n                                          credentials=credentials)\n            )\n\tchannel = self.connection.channel()\n\tchannel.exchange_declare(exchange=RabbitMQ.EXCHANGE,                                      \t\t\t\t\t\t\t\t\t\t\t\t\t\texchange_type=RabbitMQ.EXCHANGE_TYPE,\n                                          durable=True)\nexcept Exception as e:\n\tpass\n        \nsent_msg = {...}\nbody = json.dumps(sent_msg)\nchannel.basic_publish(exchange=RabbitMQ.EXCHANGE, \t\t\t\t\n                      routing_key=RabbitMQ.ROUTING_KEY,\n                      body=body, \n                      properties=pika.BasicProperties(delivery_mode=2))\n\nchannel.close()\nconnection.close()\n```\n\n\n\n###   IO\n\nIO\n\n> CPUPythonC++/Java\n>\n> IOIOC++/JavaPython\n\nPythonC++/Java\n\n### \n\nPython\n\nPythonasyncioIOasyncioEventLoopEventLoopIO,producer-consumer\n\n```python\nimport asyncio\nimport random\n\nasync def producer(queue, n):\n\tfor x in range(1, n+1):\n\t\tprint('producing : ', x)    \n\t\t# simulate io job\n\t\tawait asyncio.sleep(random.random())\n\t\titem = str(x)\n\t\tawait queue.put(item)\n        \nasync def consume(queue):\n\twhile True:\n\t\titem = await queue.get()\n    # process item\n    print('consuming : ', item)\n    # simulate io \n    await asyncio.sleep(random.random())\n    # notify queue that the item has been processed\n    queue.task_done()\n        \nasync def run(n):\n    queue = asyncio.Queue()\n    # schedule consumer\n    consumer= asyncio.ensure_future(consume(queue))\n    await producer(queue, n)\n    # wait until consumer processed all items\n    await queue.join()\n    # consumer is still awaiting item, cancel it\n    consumer.cancel()\n    \nloop = asyncio.get_event_loop()\nloop.run_until_complete(run(10))\nloop.close()\n```\n\n\n\n### Conclusion\n\n\n\n\n\nReferences:\n\n[Producer/consumer-examlpe_asyncio](https://asyncio.readthedocs.io/en/latest/producer_consumer.html)\n\n[-](https://www.liaoxuefeng.com/wiki/1016959663602400/1017968846697824)\n\n[--](https://www.liaoxuefeng.com/wiki/1016959663602400/1017631469467456)\n\n[-Python_CookBook](https://python3-cookbook.readthedocs.io/zh_CN/latest/c12/p03_communicating_between_threads.html)\n\n[Python](https://juejin.cn/post/6844904039210024967#heading-3)\n\n","slug":"-","published":1,"_id":"ckhvqydbn00006z28dot614mu","comments":1,"layout":"post","photos":[],"link":"","content":"<p>RabbitMQ HTTP  Rabbit-Consumer I/ORabbitMQ Producer-Consumerprint</p>\n<p>OS</p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p>OS/ //CPUOSIOIO/OS//</p>\n<blockquote>\n<p></p>\n<p></p>\n</blockquote>\n<p> socket  recv() recv()  recv()  recv() </p>\n<p>socket  send()TCP send() </p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p></p>\n<blockquote>\n<p>CPU</p>\n<p>CPU </p>\n</blockquote>\n<p><img src=\"1.jpeg\"></p>\n<p><img src=\"2.jpeg\"></p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p></p>\n<blockquote>\n<p></p>\n<p></p>\n</blockquote>\n<p> 2</p>\n<p>/OS</p>\n<p>OS/OSOS</p>\n<blockquote>\n<p></p>\n</blockquote>\n<p></p>\n<p></p>\n<p> cuda GPUcudaCPUCPUcuda</p>\n<p>PythonGIL, Global Interpreter LockPython GILPython</p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> threading<span class=\"token punctuation\">,</span> multiprocessing\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">loop</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    x <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n    <span class=\"token keyword\">while</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">:</span>\n        x <span class=\"token operator\">=</span> x<span class=\"token operator\">^</span><span class=\"token number\">1</span>\n\n<span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span>multiprocessing<span class=\"token punctuation\">.</span>cpu_count<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    t <span class=\"token operator\">=</span> threading<span class=\"token punctuation\">.</span>Thread<span class=\"token punctuation\">(</span>target <span class=\"token operator\">=</span> loop<span class=\"token punctuation\">)</span>\n    t<span class=\"token punctuation\">.</span>start<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre>\n<p>CPU100%C++/Java4400%</p>\n<p>GIL100cudapythonGIL</p>\n<p>PythonGILHTTPproducer-consumer </p>\n<p> queue.Queue Queueproducer-consumer</p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> queue <span class=\"token keyword\">import</span> Queue\n<span class=\"token keyword\">from</span> threading <span class=\"token keyword\">import</span> Thread\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">producer</span><span class=\"token punctuation\">(</span>out_q<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">while</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">:</span>\n        out_q<span class=\"token punctuation\">.</span>put<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">consumer</span><span class=\"token punctuation\">(</span>in_q<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">while</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">:</span>\n        data <span class=\"token operator\">=</span> in_q<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n            <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\n        <span class=\"token comment\" spellcheck=\"true\"># q </span>\n      in_q<span class=\"token punctuation\">.</span>task_done<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\nq <span class=\"token operator\">=</span> Queue<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nt1 <span class=\"token operator\">=</span> Thread<span class=\"token punctuation\">(</span>target<span class=\"token operator\">=</span>consumer<span class=\"token punctuation\">,</span> args<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>q<span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nt2 <span class=\"token operator\">=</span> Thread<span class=\"token punctuation\">(</span>taget<span class=\"token operator\">=</span>producer<span class=\"token punctuation\">,</span> args<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>q<span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nt1<span class=\"token punctuation\">.</span>start<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nt2<span class=\"token punctuation\">.</span>start<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># wait for all produced items to be consumed</span>\nq<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre>\n<p>qQueue</p>\n<pre class=\" language-python\"><code class=\"language-python\">q <span class=\"token operator\">=</span> Queue<span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span>\n    data <span class=\"token operator\">=</span> q<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span>block<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">except</span> queue<span class=\"token punctuation\">.</span>Empty<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">pass</span>\n\n<span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span>\n    q<span class=\"token punctuation\">.</span>put<span class=\"token punctuation\">(</span>item<span class=\"token punctuation\">,</span> timeout<span class=\"token operator\">=</span><span class=\"token number\">5.0</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">except</span> queue<span class=\"token punctuation\">.</span>Full<span class=\"token punctuation\">:</span>\n    log<span class=\"token punctuation\">.</span>warning<span class=\"token punctuation\">(</span><span class=\"token string\">'queued item %r discarded!'</span><span class=\"token punctuation\">,</span> item<span class=\"token punctuation\">)</span></code></pre>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>tornadohttprequest_bodyq.put()tornado producerconsumer</p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> eliot <span class=\"token keyword\">import</span> log_call<span class=\"token punctuation\">,</span> start_action<span class=\"token punctuation\">,</span> to_file\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">LogHandler</span><span class=\"token punctuation\">(</span>tornado<span class=\"token punctuation\">.</span>web<span class=\"token punctuation\">.</span>RequestHandler<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\" spellcheck=\"true\"># eliot input, output</span>\n    @log_call\n    <span class=\"token keyword\">def</span> <span class=\"token function\">post</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> <span class=\"token operator\">*</span>args<span class=\"token punctuation\">,</span> <span class=\"token operator\">**</span>kwargs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span>\n            self<span class=\"token punctuation\">.</span>timestamp <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>ctime<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n            self<span class=\"token punctuation\">.</span>recv_json <span class=\"token operator\">=</span> json<span class=\"token punctuation\">.</span>loads<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>request<span class=\"token punctuation\">.</span>body<span class=\"token punctuation\">,</span> strict<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\n            q<span class=\"token punctuation\">.</span>put<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>timestamp<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>recv_json <span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n            output_dic <span class=\"token operator\">=</span> <span class=\"token operator\">&amp;</span><span class=\"token comment\" spellcheck=\"true\">#123;</span>\n                <span class=\"token string\">'status'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'1'</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">'result'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'success'</span>\n      <span class=\"token operator\">&amp;</span><span class=\"token comment\" spellcheck=\"true\">#125;</span>\n        <span class=\"token keyword\">except</span> Exception <span class=\"token keyword\">as</span> e<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'LogHandler Error: '</span><span class=\"token punctuation\">,</span> e<span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">return</span>\n\n\n<span class=\"token comment\" spellcheck=\"true\"># eliot.start_action  with </span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">consume_msg</span><span class=\"token punctuation\">(</span>queue<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">while</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">with</span> start_action<span class=\"token punctuation\">(</span>action_type<span class=\"token operator\">=</span><span class=\"token string\">'consume_msg'</span><span class=\"token punctuation\">,</span> lenghth <span class=\"token operator\">=</span> queue<span class=\"token punctuation\">.</span>qsize<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span>\n                timestamp<span class=\"token punctuation\">,</span> msg<span class=\"token operator\">=</span> q<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n                start_time <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n                <span class=\"token keyword\">with</span> start_action<span class=\"token punctuation\">(</span>action_type<span class=\"token operator\">=</span><span class=\"token string\">'save_request_body'</span><span class=\"token punctuation\">,</span> timestamp<span class=\"token operator\">=</span>timestamp<span class=\"token punctuation\">,</span>msg<span class=\"token operator\">=</span>msg<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                    save_body<span class=\"token punctuation\">(</span>msg<span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">except</span> Exception <span class=\"token keyword\">as</span> e<span class=\"token punctuation\">:</span>\n                <span class=\"token keyword\">with</span> start_action<span class=\"token punctuation\">(</span>action_type<span class=\"token operator\">=</span><span class=\"token string\">'consume_msg exceptiosn'</span><span class=\"token punctuation\">,</span> timestamp<span class=\"token operator\">=</span>timestamp<span class=\"token punctuation\">,</span>e<span class=\"token operator\">=</span>e<span class=\"token punctuation\">,</span> msg<span class=\"token operator\">=</span>msg<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'consume_mgs exception : '</span>  <span class=\"token punctuation\">,</span> e<span class=\"token punctuation\">)</span>\n\nconsumer <span class=\"token operator\">=</span> Process<span class=\"token punctuation\">(</span>target<span class=\"token operator\">=</span>consume_msg<span class=\"token punctuation\">,</span> args<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>q<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nconsumer<span class=\"token punctuation\">.</span>daemon <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span> <span class=\"token comment\" spellcheck=\"true\"># </span>\nconsumer<span class=\"token punctuation\">.</span>start<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre>\n<p>eliot</p>\n<h3 id=\"RabbiMQ\"><a href=\"#RabbiMQ\" class=\"headerlink\" title=\"RabbiMQ\"></a>RabbiMQ</h3><p>RabbiMQ </p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token comment\" spellcheck=\"true\"># rabbitmq init</span>\ncredentials <span class=\"token operator\">=</span> pika<span class=\"token punctuation\">.</span>PlainCredentials<span class=\"token punctuation\">(</span>RabbitMQ<span class=\"token punctuation\">.</span>USERNAME<span class=\"token punctuation\">,</span> RabbitMQ<span class=\"token punctuation\">.</span>USERPWD<span class=\"token punctuation\">)</span>\nconnection <span class=\"token operator\">=</span> pika<span class=\"token punctuation\">.</span>BlockingConnection<span class=\"token punctuation\">(</span>\n                pika<span class=\"token punctuation\">.</span>ConnectionParameters<span class=\"token punctuation\">(</span>RabbitMQ<span class=\"token punctuation\">.</span>HOST<span class=\"token punctuation\">,</span> RabbitMQ<span class=\"token punctuation\">.</span>PORT<span class=\"token punctuation\">,</span>\n                                          credentials<span class=\"token operator\">=</span>credentials<span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">)</span>\n<span class=\"token comment\" spellcheck=\"true\"># channel init and declare</span>\nchannel <span class=\"token operator\">=</span> connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nchannel<span class=\"token punctuation\">.</span>exchange_declare<span class=\"token punctuation\">(</span>exchange<span class=\"token operator\">=</span>RabbitMQ<span class=\"token punctuation\">.</span>EXCHANGE<span class=\"token punctuation\">,</span>\n                             exchange_type<span class=\"token operator\">=</span>RabbitMQ<span class=\"token punctuation\">.</span>EXCHANGE_TYPE<span class=\"token punctuation\">,</span>\n                             durable<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\nchannel<span class=\"token punctuation\">.</span>queue_declare<span class=\"token punctuation\">(</span>queue<span class=\"token operator\">=</span>RabbitMQ<span class=\"token punctuation\">.</span>QUEUE_NAME_ALG<span class=\"token punctuation\">,</span> durable<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\nchannel<span class=\"token punctuation\">.</span>queue_bind<span class=\"token punctuation\">(</span>exchange<span class=\"token operator\">=</span>RabbitMQ<span class=\"token punctuation\">.</span>EXCHANGE<span class=\"token punctuation\">,</span>\n                       queue<span class=\"token operator\">=</span>RabbitMQ<span class=\"token punctuation\">.</span>QUEUE_NAME_ALG<span class=\"token punctuation\">,</span>\n                       routing_key<span class=\"token operator\">=</span>RabbitMQ<span class=\"token punctuation\">.</span>ROUTING_KEY<span class=\"token punctuation\">)</span>\nchannel<span class=\"token punctuation\">.</span>basic_qos<span class=\"token punctuation\">(</span>prefetch_count<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>    <span class=\"token comment\" spellcheck=\"true\"># </span>\nchannel<span class=\"token punctuation\">.</span>basic_consume<span class=\"token punctuation\">(</span>on_message_callback<span class=\"token operator\">=</span>consumer<span class=\"token punctuation\">,</span>\n                          queue<span class=\"token operator\">=</span>RabbitMQ<span class=\"token punctuation\">.</span>QUEUE_NAME_ALG<span class=\"token punctuation\">,</span> auto_ack<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">' [*] Waiting for messages...'</span><span class=\"token punctuation\">)</span>\nchannel<span class=\"token punctuation\">.</span>start_consuming<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">consumer</span><span class=\"token punctuation\">(</span>ch<span class=\"token punctuation\">,</span> method<span class=\"token punctuation\">,</span> properties<span class=\"token punctuation\">,</span> body<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    body <span class=\"token operator\">=</span> json<span class=\"token punctuation\">.</span>loads<span class=\"token punctuation\">(</span>body<span class=\"token punctuation\">,</span> strict<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>\n    flag <span class=\"token operator\">=</span> body<span class=\"token punctuation\">[</span><span class=\"token string\">'flag'</span><span class=\"token punctuation\">]</span>\n    <span class=\"token comment\" spellcheck=\"true\"># process body</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Ack manually</span>\n    ch<span class=\"token punctuation\">.</span>basic_ack<span class=\"token punctuation\">(</span>delivery_tag<span class=\"token operator\">=</span>method<span class=\"token punctuation\">.</span>delivery_tag<span class=\"token punctuation\">)</span>\n\n\n\n<span class=\"token comment\" spellcheck=\"true\"># producer.py</span>\n<span class=\"token keyword\">try</span><span class=\"token punctuation\">:</span>\n    credentials <span class=\"token operator\">=</span> pika<span class=\"token punctuation\">.</span>PlainCredentials<span class=\"token punctuation\">(</span>\n                RabbitMQ<span class=\"token punctuation\">.</span>USERNAME<span class=\"token punctuation\">,</span> RabbitMQ<span class=\"token punctuation\">.</span>USERPWD<span class=\"token punctuation\">)</span>\n    connection <span class=\"token operator\">=</span> pika<span class=\"token punctuation\">.</span>BlockingConnection<span class=\"token punctuation\">(</span>\n                pika<span class=\"token punctuation\">.</span>ConnectionParameters<span class=\"token punctuation\">(</span>RabbitMQ<span class=\"token punctuation\">.</span>HOST<span class=\"token punctuation\">,</span> RabbitMQ<span class=\"token punctuation\">.</span>PORT<span class=\"token punctuation\">,</span>\n                                          credentials<span class=\"token operator\">=</span>credentials<span class=\"token punctuation\">)</span>\n            <span class=\"token punctuation\">)</span>\n    channel <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>connection<span class=\"token punctuation\">.</span>channel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    channel<span class=\"token punctuation\">.</span>exchange_declare<span class=\"token punctuation\">(</span>exchange<span class=\"token operator\">=</span>RabbitMQ<span class=\"token punctuation\">.</span>EXCHANGE<span class=\"token punctuation\">,</span>                                                                                              exchange_type<span class=\"token operator\">=</span>RabbitMQ<span class=\"token punctuation\">.</span>EXCHANGE_TYPE<span class=\"token punctuation\">,</span>\n                                          durable<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">except</span> Exception <span class=\"token keyword\">as</span> e<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">pass</span>\n\nsent_msg <span class=\"token operator\">=</span> <span class=\"token operator\">&amp;</span><span class=\"token comment\" spellcheck=\"true\">#123;...&amp;#125;</span>\nbody <span class=\"token operator\">=</span> json<span class=\"token punctuation\">.</span>dumps<span class=\"token punctuation\">(</span>sent_msg<span class=\"token punctuation\">)</span>\nchannel<span class=\"token punctuation\">.</span>basic_publish<span class=\"token punctuation\">(</span>exchange<span class=\"token operator\">=</span>RabbitMQ<span class=\"token punctuation\">.</span>EXCHANGE<span class=\"token punctuation\">,</span>                 \n                      routing_key<span class=\"token operator\">=</span>RabbitMQ<span class=\"token punctuation\">.</span>ROUTING_KEY<span class=\"token punctuation\">,</span>\n                      body<span class=\"token operator\">=</span>body<span class=\"token punctuation\">,</span> \n                      properties<span class=\"token operator\">=</span>pika<span class=\"token punctuation\">.</span>BasicProperties<span class=\"token punctuation\">(</span>delivery_mode<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nchannel<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nconnection<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre>\n<h3 id=\"--IO\"><a href=\"#--IO\" class=\"headerlink\" title=\"  IO\"></a>  IO</h3><p>IO</p>\n<blockquote>\n<p>CPUPythonC++/Java</p>\n<p>IOIOC++/JavaPython</p>\n</blockquote>\n<p>PythonC++/Java</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>Python</p>\n<p>PythonasyncioIOasyncioEventLoopEventLoopIO,producer-consumer</p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> asyncio\n<span class=\"token keyword\">import</span> random\n\n<span class=\"token keyword\">async</span> <span class=\"token keyword\">def</span> <span class=\"token function\">producer</span><span class=\"token punctuation\">(</span>queue<span class=\"token punctuation\">,</span> n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">for</span> x <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> n<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'producing : '</span><span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span>    \n        <span class=\"token comment\" spellcheck=\"true\"># simulate io job</span>\n        <span class=\"token keyword\">await</span> asyncio<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span>random<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        item <span class=\"token operator\">=</span> str<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">await</span> queue<span class=\"token punctuation\">.</span>put<span class=\"token punctuation\">(</span>item<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">async</span> <span class=\"token keyword\">def</span> <span class=\"token function\">consume</span><span class=\"token punctuation\">(</span>queue<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">while</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">:</span>\n        item <span class=\"token operator\">=</span> <span class=\"token keyword\">await</span> queue<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\" spellcheck=\"true\"># process item</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'consuming : '</span><span class=\"token punctuation\">,</span> item<span class=\"token punctuation\">)</span>\n    <span class=\"token comment\" spellcheck=\"true\"># simulate io </span>\n    <span class=\"token keyword\">await</span> asyncio<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span>random<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\" spellcheck=\"true\"># notify queue that the item has been processed</span>\n    queue<span class=\"token punctuation\">.</span>task_done<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">async</span> <span class=\"token keyword\">def</span> <span class=\"token function\">run</span><span class=\"token punctuation\">(</span>n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    queue <span class=\"token operator\">=</span> asyncio<span class=\"token punctuation\">.</span>Queue<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\" spellcheck=\"true\"># schedule consumer</span>\n    consumer<span class=\"token operator\">=</span> asyncio<span class=\"token punctuation\">.</span>ensure_future<span class=\"token punctuation\">(</span>consume<span class=\"token punctuation\">(</span>queue<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">await</span> producer<span class=\"token punctuation\">(</span>queue<span class=\"token punctuation\">,</span> n<span class=\"token punctuation\">)</span>\n    <span class=\"token comment\" spellcheck=\"true\"># wait until consumer processed all items</span>\n    <span class=\"token keyword\">await</span> queue<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\" spellcheck=\"true\"># consumer is still awaiting item, cancel it</span>\n    consumer<span class=\"token punctuation\">.</span>cancel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\nloop <span class=\"token operator\">=</span> asyncio<span class=\"token punctuation\">.</span>get_event_loop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nloop<span class=\"token punctuation\">.</span>run_until_complete<span class=\"token punctuation\">(</span>run<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nloop<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre>\n<h3 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h3><p></p>\n<p>References:</p>\n<p><a href=\"https://asyncio.readthedocs.io/en/latest/producer_consumer.html\">Producer/consumer-examlpe_asyncio</a></p>\n<p><a href=\"https://www.liaoxuefeng.com/wiki/1016959663602400/1017968846697824\">-</a></p>\n<p><a href=\"https://www.liaoxuefeng.com/wiki/1016959663602400/1017631469467456\">--</a></p>\n<p><a href=\"https://python3-cookbook.readthedocs.io/zh_CN/latest/c12/p03_communicating_between_threads.html\">-Python_CookBook</a></p>\n<p><a href=\"https://juejin.cn/post/6844904039210024967#heading-3\">Python</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>RabbitMQ HTTP  Rabbit-Consumer I/ORabbitMQ Producer-Consumerprint</p>\n<p>OS</p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p>OS/ //CPUOSIOIO/OS//</p>\n<blockquote>\n<p></p>\n<p></p>\n</blockquote>\n<p> socket  recv() recv()  recv()  recv() </p>\n<p>socket  send()TCP send() </p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p></p>\n<blockquote>\n<p>CPU</p>\n<p>CPU </p>\n</blockquote>\n<p><img src=\"1.jpeg\"></p>\n<p><img src=\"2.jpeg\"></p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p></p>\n<blockquote>\n<p></p>\n<p></p>\n</blockquote>\n<p> 2</p>\n<p>/OS</p>\n<p>OS/OSOS</p>\n<blockquote>\n<p></p>\n</blockquote>\n<p></p>\n<p></p>\n<p> cuda GPUcudaCPUCPUcuda</p>\n<p>PythonGIL, Global Interpreter LockPython GILPython</p>\n<pre><code class=\"python\">import threading, multiprocessing\n\ndef loop():\n    x = 0\n    while True:\n        x = x^1\n\nfor i in range(multiprocessing.cpu_count()):\n    t = threading.Thread(target = loop)\n    t.start()</code></pre>\n<p>CPU100%C++/Java4400%</p>\n<p>GIL100cudapythonGIL</p>\n<p>PythonGILHTTPproducer-consumer </p>\n<p> queue.Queue Queueproducer-consumer</p>\n<pre><code class=\"python\">from queue import Queue\nfrom threading import Thread\n\ndef producer(out_q):\n    while True:\n        out_q.put(data)\n\ndef consumer(in_q):\n    while True:\n        data = in_q.get()\n            ...\n        # q \n      in_q.task_done()\n\nq = Queue()\nt1 = Thread(target=consumer, args=(q,))\nt2 = Thread(taget=producer, args=(q,))\nt1.start()\nt2.start()\n\n# wait for all produced items to be consumed\nq.join()</code></pre>\n<p>qQueue</p>\n<pre><code class=\"python\">q = Queue(100)\n\ntry:\n    data = q.get(block=False)\nexcept queue.Empty:\n    pass\n\ntry:\n    q.put(item, timeout=5.0)\nexcept queue.Full:\n    log.warning(&#39;queued item %r discarded!&#39;, item)</code></pre>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>tornadohttprequest_bodyq.put()tornado producerconsumer</p>\n<pre><code class=\"python\">from eliot import log_call, start_action, to_file\nclass LogHandler(tornado.web.RequestHandler):\n    # eliot input, output\n    @log_call\n    def post(self, *args, **kwargs):\n        try:\n            self.timestamp = time.ctime()\n            self.recv_json = json.loads(self.request.body, strict=False)\n            q.put((self.timestamp, self.recv_json ))\n            output_dic = &#123;\n                &#39;status&#39;: &#39;1&#39;,\n                &#39;result&#39;: &#39;success&#39;\n      &#125;\n        except Exception as e:\n            print(&#39;LogHandler Error: &#39;, e)\n            return\n\n\n# eliot.start_action  with \ndef consume_msg(queue):\n    while True:\n        with start_action(action_type=&#39;consume_msg&#39;, lenghth = queue.qsize()):\n            try:\n                timestamp, msg= q.get()\n                start_time = time.time()\n                with start_action(action_type=&#39;save_request_body&#39;, timestamp=timestamp,msg=msg):\n                    save_body(msg)\n            except Exception as e:\n                with start_action(action_type=&#39;consume_msg exceptiosn&#39;, timestamp=timestamp,e=e, msg=msg):\n                    print(&#39;consume_mgs exception : &#39;  , e)\n\nconsumer = Process(target=consume_msg, args=(q, ))\nconsumer.daemon = True # \nconsumer.start()</code></pre>\n<p>eliot</p>\n<h3 id=\"RabbiMQ\"><a href=\"#RabbiMQ\" class=\"headerlink\" title=\"RabbiMQ\"></a>RabbiMQ</h3><p>RabbiMQ </p>\n<pre><code class=\"python\"># rabbitmq init\ncredentials = pika.PlainCredentials(RabbitMQ.USERNAME, RabbitMQ.USERPWD)\nconnection = pika.BlockingConnection(\n                pika.ConnectionParameters(RabbitMQ.HOST, RabbitMQ.PORT,\n                                          credentials=credentials)\n    )\n# channel init and declare\nchannel = connection.channel()\nchannel.exchange_declare(exchange=RabbitMQ.EXCHANGE,\n                             exchange_type=RabbitMQ.EXCHANGE_TYPE,\n                             durable=True)\nchannel.queue_declare(queue=RabbitMQ.QUEUE_NAME_ALG, durable=True)\nchannel.queue_bind(exchange=RabbitMQ.EXCHANGE,\n                       queue=RabbitMQ.QUEUE_NAME_ALG,\n                       routing_key=RabbitMQ.ROUTING_KEY)\nchannel.basic_qos(prefetch_count=1)    # \nchannel.basic_consume(on_message_callback=consumer,\n                          queue=RabbitMQ.QUEUE_NAME_ALG, auto_ack=False)\nprint(&#39; [*] Waiting for messages...&#39;)\nchannel.start_consuming()\n\ndef consumer(ch, method, properties, body):\n    body = json.loads(body, strict=False)\n    flag = body[&#39;flag&#39;]\n    # process body\n\n    # Ack manually\n    ch.basic_ack(delivery_tag=method.delivery_tag)\n\n\n\n# producer.py\ntry:\n    credentials = pika.PlainCredentials(\n                RabbitMQ.USERNAME, RabbitMQ.USERPWD)\n    connection = pika.BlockingConnection(\n                pika.ConnectionParameters(RabbitMQ.HOST, RabbitMQ.PORT,\n                                          credentials=credentials)\n            )\n    channel = self.connection.channel()\n    channel.exchange_declare(exchange=RabbitMQ.EXCHANGE,                                                                                              exchange_type=RabbitMQ.EXCHANGE_TYPE,\n                                          durable=True)\nexcept Exception as e:\n    pass\n\nsent_msg = &#123;...&#125;\nbody = json.dumps(sent_msg)\nchannel.basic_publish(exchange=RabbitMQ.EXCHANGE,                 \n                      routing_key=RabbitMQ.ROUTING_KEY,\n                      body=body, \n                      properties=pika.BasicProperties(delivery_mode=2))\n\nchannel.close()\nconnection.close()</code></pre>\n<h3 id=\"--IO\"><a href=\"#--IO\" class=\"headerlink\" title=\"  IO\"></a>  IO</h3><p>IO</p>\n<blockquote>\n<p>CPUPythonC++/Java</p>\n<p>IOIOC++/JavaPython</p>\n</blockquote>\n<p>PythonC++/Java</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>Python</p>\n<p>PythonasyncioIOasyncioEventLoopEventLoopIO,producer-consumer</p>\n<pre><code class=\"python\">import asyncio\nimport random\n\nasync def producer(queue, n):\n    for x in range(1, n+1):\n        print(&#39;producing : &#39;, x)    \n        # simulate io job\n        await asyncio.sleep(random.random())\n        item = str(x)\n        await queue.put(item)\n\nasync def consume(queue):\n    while True:\n        item = await queue.get()\n    # process item\n    print(&#39;consuming : &#39;, item)\n    # simulate io \n    await asyncio.sleep(random.random())\n    # notify queue that the item has been processed\n    queue.task_done()\n\nasync def run(n):\n    queue = asyncio.Queue()\n    # schedule consumer\n    consumer= asyncio.ensure_future(consume(queue))\n    await producer(queue, n)\n    # wait until consumer processed all items\n    await queue.join()\n    # consumer is still awaiting item, cancel it\n    consumer.cancel()\n\nloop = asyncio.get_event_loop()\nloop.run_until_complete(run(10))\nloop.close()</code></pre>\n<h3 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h3><p></p>\n<p>References:</p>\n<p><a href=\"https://asyncio.readthedocs.io/en/latest/producer_consumer.html\">Producer/consumer-examlpe_asyncio</a></p>\n<p><a href=\"https://www.liaoxuefeng.com/wiki/1016959663602400/1017968846697824\">-</a></p>\n<p><a href=\"https://www.liaoxuefeng.com/wiki/1016959663602400/1017631469467456\">--</a></p>\n<p><a href=\"https://python3-cookbook.readthedocs.io/zh_CN/latest/c12/p03_communicating_between_threads.html\">-Python_CookBook</a></p>\n<p><a href=\"https://juejin.cn/post/6844904039210024967#heading-3\">Python</a></p>\n"},{"title":"GPU in Pytorch  ","toc":true,"mathjax":true,"top":false,"cover":true,"date":"2020-11-25T07:07:07.000Z","updated":"2021-01-15T07:10:23.263Z","_content":"\nCUDAGPUPytorch\n\nPytorch 3torch.multiprocessing, nn.DataParallel, nn.parallel.DistributedDataParallelGPU nn.parallle.DistributedDataParallel, [CUDA SEMANTIC](https://pytorch.org/docs/stable/notes/cuda.html#cuda-nn-ddp-instead) \n\n> **Use nn.parallel.DistributedDataParallel instead of multiprocessing or nn.DataParallel**\n>\n> Most use cases involving batched inputs and multiple GPUs should default to using [`DistributedDataParallel`](https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel) to utilize more than one GPU.\n>\n> There are significant caveats to using CUDA models with [`multiprocessing`](https://pytorch.org/docs/stable/multiprocessing.html#module-torch.multiprocessing); unless care is taken to meet the data handling requirements exactly, it is likely that your program will have incorrect or undefined behavior.\n>\n> It is recommended to use [`DistributedDataParallel`](https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel), instead of [`DataParallel`](https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html#torch.nn.DataParallel) to do multi-GPU training, even if there is only a single node.\n>\n> The difference between [`DistributedDataParallel`](https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel) and [`DataParallel`](https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html#torch.nn.DataParallel) is: [`DistributedDataParallel`](https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel) uses multiprocessing where a process is created for each GPU, while [`DataParallel`](https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html#torch.nn.DataParallel) uses multithreading. By using multiprocessing, each GPU has its dedicated process, this avoids the performance overhead caused by GIL of Python interpreter.\n>\n> If you use [`DistributedDataParallel`](https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel), you could use torch.distributed.launch utility to launch your program, see [Third-party backends](https://pytorch.org/docs/stable/distributed.html#distributed-launch).\n\n\n\n### torch.multiprocessing\n\ntorch.multiprocessing  Python multiprocessing  python: multiprocessing.Queue Pytorch [MULTIPROCESSING BEST PRACTICES](https://pytorch.org/docs/stable/notes/multiprocessing.html), [](https://pytorch.apachecn.org/docs/1.4/64.html)\n\n```python\nimport torch.multiprocessing as mp\nfrom model import MyModel\n\ndef train(model):\n    # Construct data_loader, optimizer, etc.\n    for data, labels in data_loader:\n        optimizer.zero_grad()\n        loss_fn(model(data), labels).backward()\n        optimizer.step()  # This will update the shared parameters\n\nif __name__ == '__main__':\n    num_processes = 4\n    model = MyModel()\n    # NOTE: this is required for the ``fork`` method to work\n    model.share_memory()\n    processes = []\n    for rank in range(num_processes):\n        p = mp.Process(target=train, args=(model,))\n        p.start()\n        processes.append(p)\n    for p in processes:\n        p.join()\n```\n\n\n\n### DataParallel\n\nDataParallelmodel copyGPUGPUSIMDGPU\n\n#### DataParallel\n\n```python\nmodel = nn.DataParallel(model)\n```\n\n outside model    inside model \n\n```python\nclass Model(nn.Module):\n    # Our model\n\n    def __init__(self, input_size, output_size):\n        super(Model, self).__init__()\n        self.fc = nn.Linear(input_size, output_size)\n\n    def forward(self, input):\n        output = self.fc(input)\n        print(\"\\tIn Model: input size\", input.size(),\n              \"output size\", output.size())\n\n        return output\n        \n\nmodel = Model(input_size, output_size)\nif torch.cuda.device_count() > 1:\n  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n  model = nn.DataParallel(model)\n\nmodel.to(device)\n\nfor data in rand_loader:\n    input = data.to(device)\n    output = model(input)\n    print(\"Outside: input size\", input.size(),\n          \"output_size\", output.size())\n    \n# 2 GPUs\n# on 2 GPUs\nLet's use 2 GPUs!\n    In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\n    In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\nOutside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])\n    In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\n    In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\nOutside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])\n    In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\n    In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\nOutside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])\n    In Model: input size torch.Size([5, 5]) output size torch.Size([5, 2])\n    In Model: input size torch.Size([5, 5]) output size torch.Size([5, 2])\nOutside: input size torch.Size([10, 5]) output_size torch.Size([10, 2])\n```\n\nGPUTrickGPU GPU  GPU ( `m` 10 `DataParallel` GPU  10  GPU  GPU  5 \n\n#### \n\n```python\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nclass ToyModel(nn.Module):\n    def __init__(self):\n        super(ToyModel, self).__init__()\n        self.net1 = torch.nn.Linear(10, 10).to('cuda:0')\n        self.relu = torch.nn.ReLU()\n        self.net2 = torch.nn.Linear(10, 5).to('cuda:1')\n\n    def forward(self, x):\n        x = self.relu(self.net1(x.to('cuda:0')))\n        return self.net2(x.to('cuda:1'))\n```\n\n GPU  GPU GPU   GPU  `layer2``layer3``cuda:0``cuda:1`\n\nTrick\n\n#### Pipeline \n\n```python\nclass PipelineParallelResNet50(ModelParallelResNet50):\n    def __init__(self, split_size=20, *args, **kwargs):\n        super(PipelineParallelResNet50, self).__init__(*args, **kwargs)\n        self.split_size = split_size\n\n    def forward(self, x):\n        splits = iter(x.split(self.split_size, dim=0))\n        s_next = next(splits)\n        s_prev = self.seq1(s_next).to('cuda:1')\n        ret = []\n\n        for s_next in splits:\n            # A. s_prev runs on cuda:1\n            s_prev = self.seq2(s_prev)\n            ret.append(self.fc(s_prev.view(s_prev.size(0), -1)))\n\n            # B. s_next runs on cuda:0, which can run concurrently with A\n            s_prev = self.seq1(s_next).to('cuda:1')\n\n        s_prev = self.seq2(s_prev)\n        ret.append(self.fc(s_prev.view(s_prev.size(0), -1)))\n\n        return torch.cat(ret)\n\nsetup = \"model = PipelineParallelResNet50()\"\npp_run_times = timeit.repeat(\n    stmt, setup, number=1, repeat=num_repeat, globals=globals())\npp_mean, pp_std = np.mean(pp_run_times), np.std(pp_run_times)\n\nplot([mp_mean, rn_mean, pp_mean],\n     [mp_std, rn_std, pp_std],\n     ['Model Parallel', 'Single GPU', 'Pipelining Model Parallel'],\n     'mp_vs_rn_vs_pp.png')\n```\n\n2 GPUs50%100%\n\n###![1](1.png) \n\n### \n\n 2-GPU 1-GPU 2-GPU Pipelining  \n\n\n\n### nn.parallel.DistributedDataParallel\n\ntorch.distributed DataParallel \n\n`DistributedDataParallel`\n\n#### GPU\n\n```python\ntorch.distributed.init_process_group(backend=\"nccl\")\n# device_ids will include all GPU devices by default\nmodel = DistributedDataParallel(model) \n\n```\n\n#### GPU\n\nGPUGILDDP(DistributedDataParallel)GPUtorch.nn.DataParallelPytorch\n\n\n\n1. NGPUNtorch.distributed.launch\n\n```bash\npython -m torch.distributed.launch --nproc_per_node=n distributed_data_parallel.py\n```\n\n2. GPU model\n\n```python\nparser = argparse.ArgumentParser()\n# FOR DISTRIBUTED:  Parse for the local_rank argument, which will be supplied\n# automatically by torch.distributed.launch.\nparser.add_argument(\"--local_rank\", default=0, type=int)\nargs = parser.parse_args()\n\n#  GPU rank id\ntorch.cuda.set_device(args.local_rank)\n# model\ntorch.distributed.init_process_group(backend='nccl', world_size=n, init_method='env://')\nmodel = torch.nn.parallel.DistributedDataParallel(\n  \t\t\t\t\t\t\t\t\tmodel,\n\t\t\t\t\t\t\t\t\t\tdevice_ids=[args.local_rank],\n\t\t\t\t\t\t\t\t\t\toutput_device=args.local_rank)\n```\n\nNote:\n\n1. nccl \n2. nccl\n3. no_sync DDPForward-Backward\n\n```python\nddp = torch.nn.DistributedDataParallel(model, pg)\nwith ddp.no_sync():\nfor input in inputs:\n\tddp(input).backward()  # no synchronization, accumulate grads\nddp(another_input).backward()  # synchronize grads\n```\n\n\n\n### apex.parallel.DistributedDataParallel\n\ntorch.nn.parallel.DistributedDataParallelwrapperNCCL\n\n``` bash\n#  n <= GPU  1GPU1\ntorch.distributed.launch --nproc_per_node=n distributed_data_parallel.py\n# :\n# args.local_rank\n# os.environ['WORLD_SIZE']\n\n```\n\n\n\n1. model = DDP(model)  devices_ids output_device\n\n2. init_process_group  init_method='env://'\n\n   ``` python\n   torch.distributed.init_process_group(backend='nccl',init_method='env://')\n   ```\n\n\n\n```python\n# distributed_data_parallel.py\nimport torch\nimport argparse\nimport os\nfrom apex import amp\n# FOR DISTRIBUTED: (can also use torch.nn.parallel.DistributedDataParallel instead)\nfrom apex.parallel import DistributedDataParallel\n\nparser = argparse.ArgumentParser()\n# FOR DISTRIBUTED:  Parse for the local_rank argument, which will be supplied\n# automatically by torch.distributed.launch.\nparser.add_argument(\"--local_rank\", default=0, type=int)\nargs = parser.parse_args()\n\n# FOR DISTRIBUTED:  If we are running under torch.distributed.launch,\n# the 'WORLD_SIZE' environment variable will also be set automatically.\nargs.distributed = False\nif 'WORLD_SIZE' in os.environ:\n    args.distributed = int(os.environ['WORLD_SIZE']) > 1\n\nif args.distributed:\n    # FOR DISTRIBUTED:  Set the device according to local_rank.\n    torch.cuda.set_device(args.local_rank)\n\n    # FOR DISTRIBUTED:  Initialize the backend.  torch.distributed.launch will provide\n    # environment variables, and requires that you use init_method=`env://`.\n    torch.distributed.init_process_group(backend='nccl',\n                                         init_method='env://')\n\ntorch.backends.cudnn.benchmark = True\n\nN, D_in, D_out = 64, 1024, 16\n\n# Each process receives its own batch of \"fake input data\" and \"fake target data.\"\n# The \"training loop\" in each process just uses this fake batch over and over.\n# https://github.com/NVIDIA/apex/tree/master/examples/imagenet provides a more realistic\n# example of distributed data sampling for both training and validation.\nx = torch.randn(N, D_in, device='cuda')\ny = torch.randn(N, D_out, device='cuda')\n\nmodel = torch.nn.Linear(D_in, D_out).cuda()\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n\nmodel, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\")\n\nif args.distributed:\n    # FOR DISTRIBUTED:  After amp.initialize, wrap the model with\n    # apex.parallel.DistributedDataParallel.\n    model = DistributedDataParallel(model)\n    # torch.nn.parallel.DistributedDataParallel is also fine, with some added args:\n    # model = torch.nn.parallel.DistributedDataParallel(model,\n    #                                                   device_ids=[args.local_rank],\n    #                                                   output_device=args.local_rank)\n\nloss_fn = torch.nn.MSELoss()\n\nfor t in range(500):\n    optimizer.zero_grad()\n    y_pred = model(x)\n    loss = loss_fn(y_pred, y)\n    with amp.scale_loss(loss, optimizer) as scaled_loss:\n        scaled_loss.backward()\n    optimizer.step()\n\nif args.local_rank == 0:\n    print(\"final loss = \", loss)\n```\n\n [mixed precision training with DDP](https://github.com/NVIDIA/apex/tree/master/examples/imagenet)\n\n\n\n### DDP \n\ntorch.save  torch.load \n\n``` python\nimport os\nimport tempfile\nimport torch\nimport torch.distributed as dist\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.multiprocessing as mp\n\nfrom torch.nn.parallel import DistributedDataParallel as DDP\n\ndef demo_checkpoint(rank, world_size):\n    setup(rank, world_size)\n\n    # setup devices for this process, rank 1 uses GPUs [0, 1, 2, 3] and\n    # rank 2 uses GPUs [4, 5, 6, 7].\n    n = torch.cuda.device_count() // world_size\n    device_ids = list(range(rank * n, (rank + 1) * n))\n\n    model = ToyModel().to(device_ids[0])\n    # output_device defaults to device_ids[0]\n    ddp_model = DDP(model, device_ids=device_ids)\n\n    loss_fn = nn.MSELoss()\n    optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)\n\n    CHECKPOINT_PATH = tempfile.gettempdir() + \"/model.checkpoint\"\n    if rank == 0:\n        # All processes should see same parameters as they all start from same\n        # random parameters and gradients are synchronized in backward passes.\n        # Therefore, saving it in one process is sufficient.\n        torch.save(ddp_model.state_dict(), CHECKPOINT_PATH)\n\n    # Use a barrier() to make sure that process 1 loads the model after process\n    # 0 saves it.\n    dist.barrier()\n    # configure map_location properly\n    rank0_devices = [x - rank * len(device_ids) for x in device_ids]\n    device_pairs = zip(rank0_devices, device_ids)\n    map_location = {'cuda:%d' % x: 'cuda:%d' % y for x, y in device_pairs}\n    ddp_model.load_state_dict(\n        torch.load(CHECKPOINT_PATH, map_location=map_location))\n\n    optimizer.zero_grad()\n    outputs = ddp_model(torch.randn(20, 10))\n    labels = torch.randn(20, 5).to(device_ids[0])\n    loss_fn = nn.MSELoss()\n    loss_fn(outputs, labels).backward()\n    optimizer.step()\n\n    # Use a barrier() to make sure that all processes have finished reading the\n    # checkpoint\n    dist.barrier()\n\n    if rank == 0:\n        os.remove(CHECKPOINT_PATH)\n\n    cleanup()\n```\n\n\n\n### DDP \n\nDDP  GPU   DDP  GPU   GPU \n\n``` python\nclass ToyMpModel(nn.Module):\n    def __init__(self, dev0, dev1):\n        super(ToyMpModel, self).__init__()\n        self.dev0 = dev0\n        self.dev1 = dev1\n        self.net1 = torch.nn.Linear(10, 10).to(dev0)\n        self.relu = torch.nn.ReLU()\n        self.net2 = torch.nn.Linear(10, 5).to(dev1)\n\n    def forward(self, x):\n        x = x.to(self.dev0)\n        x = self.relu(self.net1(x))\n        x = x.to(self.dev1)\n        return self.net2(x)\n```\n\n GPU  DDP `device_ids``output_device` `forward()`\n\n``` python\ndef demo_model_parallel(rank, world_size):\n    setup(rank, world_size)\n\n    # setup mp_model and devices for this process\n    dev0 = rank * 2\n    dev1 = rank * 2 + 1\n    mp_model = ToyMpModel(dev0, dev1)\n    ddp_mp_model = DDP(mp_model)\n\n    loss_fn = nn.MSELoss()\n    optimizer = optim.SGD(ddp_mp_model.parameters(), lr=0.001)\n\n    optimizer.zero_grad()\n    # outputs will be on dev1\n    outputs = ddp_mp_model(torch.randn(20, 10))\n    labels = torch.randn(20, 5).to(dev1)\n    loss_fn(outputs, labels).backward()\n    optimizer.step()\n\n    cleanup()\n\nif __name__ == \"__main__\":\n    run_demo(demo_basic, 2)\n    run_demo(demo_checkpoint, 2)\n\n    if torch.cuda.device_count() >= 8:\n        run_demo(demo_model_parallel, 4)\n```\n\nsetup  torch.multiprocessing.spawn setup\n\n```python\nimport os\nimport tempfile\nimport torch\nimport torch.distributed as dist\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.multiprocessing as mp\n\nfrom torch.nn.parallel import DistributedDataParallel as DDP\n\ndef setup(rank, world_size):\n    os.environ['MASTER_ADDR'] = 'localhost'\n    os.environ['MASTER_PORT'] = '12355'\n\n    # initialize the process group\n    dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)\n\n    # Explicitly setting seed to make sure that models created in two processes\n    # start from same random weights and biases.\n    torch.manual_seed(42)\n\ndef cleanup():\n    dist.destroy_process_group()\n    \nclass ToyModel(nn.Module):\n    def __init__(self):\n        super(ToyModel, self).__init__()\n        self.net1 = nn.Linear(10, 10)\n        self.relu = nn.ReLU()\n        self.net2 = nn.Linear(10, 5)\n\n    def forward(self, x):\n        return self.net2(self.relu(self.net1(x)))\n\ndef demo_basic(rank, world_size):\n    setup(rank, world_size)\n\n    # setup devices for this process, rank 1 uses GPUs [0, 1, 2, 3] and\n    # rank 2 uses GPUs [4, 5, 6, 7].\n    n = torch.cuda.device_count() // world_size\n    device_ids = list(range(rank * n, (rank + 1) * n))\n\n    # create model and move it to device_ids[0]\n    model = ToyModel().to(device_ids[0])\n    # output_device defaults to device_ids[0]\n    ddp_model = DDP(model, device_ids=device_ids)\n\n    loss_fn = nn.MSELoss()\n    optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)\n\n    optimizer.zero_grad()\n    outputs = ddp_model(torch.randn(20, 10))\n    labels = torch.randn(20, 5).to(device_ids[0])\n    loss_fn(outputs, labels).backward()\n    optimizer.step()\n\n    cleanup()\n\ndef run_demo(demo_fn, world_size):\n    mp.spawn(demo_fn,\n             args=(world_size,),\n             nprocs=world_size,\n             join=True)\n```\n\n\n\n### Conclusion\n\nPytorchGPUGILDDP model \n\n\n\nReferences:\n\n[torch.nn](https://pytorch.apachecn.org/docs/1.4/75.html)\n\n[DistributedDataParallel API](https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html?highlight=distributeddataparallel#torch.nn.parallel.DistributedDataParallel)\n\n[CUDA Semantics](https://pytorch.org/docs/stable/notes/cuda.html#cuda-nn-ddp-instead)\n\n[](https://pytorch.apachecn.org/docs/1.4/34.html)\n\n[Pytorch](https://pytorch.apachecn.org/docs/1.4/35.html)\n\n[apex.parallel](https://nvidia.github.io/apex/parallel.html)\n\n","source":"_posts/GPU-in-Pytorch-.md","raw":"---\ntitle: GPU in Pytorch  \ntoc: true\nmathjax: true\ntop: false\ncover: true\ndate: 2020-11-25 15:07:07\nupdated:\ncategories: Pytorch\ntags:\n\t- Pytorch\n\t- CUDA\n\t- GPU\n---\n\nCUDAGPUPytorch\n\nPytorch 3torch.multiprocessing, nn.DataParallel, nn.parallel.DistributedDataParallelGPU nn.parallle.DistributedDataParallel, [CUDA SEMANTIC](https://pytorch.org/docs/stable/notes/cuda.html#cuda-nn-ddp-instead) \n\n> **Use nn.parallel.DistributedDataParallel instead of multiprocessing or nn.DataParallel**\n>\n> Most use cases involving batched inputs and multiple GPUs should default to using [`DistributedDataParallel`](https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel) to utilize more than one GPU.\n>\n> There are significant caveats to using CUDA models with [`multiprocessing`](https://pytorch.org/docs/stable/multiprocessing.html#module-torch.multiprocessing); unless care is taken to meet the data handling requirements exactly, it is likely that your program will have incorrect or undefined behavior.\n>\n> It is recommended to use [`DistributedDataParallel`](https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel), instead of [`DataParallel`](https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html#torch.nn.DataParallel) to do multi-GPU training, even if there is only a single node.\n>\n> The difference between [`DistributedDataParallel`](https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel) and [`DataParallel`](https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html#torch.nn.DataParallel) is: [`DistributedDataParallel`](https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel) uses multiprocessing where a process is created for each GPU, while [`DataParallel`](https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html#torch.nn.DataParallel) uses multithreading. By using multiprocessing, each GPU has its dedicated process, this avoids the performance overhead caused by GIL of Python interpreter.\n>\n> If you use [`DistributedDataParallel`](https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel), you could use torch.distributed.launch utility to launch your program, see [Third-party backends](https://pytorch.org/docs/stable/distributed.html#distributed-launch).\n\n\n\n### torch.multiprocessing\n\ntorch.multiprocessing  Python multiprocessing  python: multiprocessing.Queue Pytorch [MULTIPROCESSING BEST PRACTICES](https://pytorch.org/docs/stable/notes/multiprocessing.html), [](https://pytorch.apachecn.org/docs/1.4/64.html)\n\n```python\nimport torch.multiprocessing as mp\nfrom model import MyModel\n\ndef train(model):\n    # Construct data_loader, optimizer, etc.\n    for data, labels in data_loader:\n        optimizer.zero_grad()\n        loss_fn(model(data), labels).backward()\n        optimizer.step()  # This will update the shared parameters\n\nif __name__ == '__main__':\n    num_processes = 4\n    model = MyModel()\n    # NOTE: this is required for the ``fork`` method to work\n    model.share_memory()\n    processes = []\n    for rank in range(num_processes):\n        p = mp.Process(target=train, args=(model,))\n        p.start()\n        processes.append(p)\n    for p in processes:\n        p.join()\n```\n\n\n\n### DataParallel\n\nDataParallelmodel copyGPUGPUSIMDGPU\n\n#### DataParallel\n\n```python\nmodel = nn.DataParallel(model)\n```\n\n outside model    inside model \n\n```python\nclass Model(nn.Module):\n    # Our model\n\n    def __init__(self, input_size, output_size):\n        super(Model, self).__init__()\n        self.fc = nn.Linear(input_size, output_size)\n\n    def forward(self, input):\n        output = self.fc(input)\n        print(\"\\tIn Model: input size\", input.size(),\n              \"output size\", output.size())\n\n        return output\n        \n\nmodel = Model(input_size, output_size)\nif torch.cuda.device_count() > 1:\n  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n  model = nn.DataParallel(model)\n\nmodel.to(device)\n\nfor data in rand_loader:\n    input = data.to(device)\n    output = model(input)\n    print(\"Outside: input size\", input.size(),\n          \"output_size\", output.size())\n    \n# 2 GPUs\n# on 2 GPUs\nLet's use 2 GPUs!\n    In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\n    In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\nOutside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])\n    In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\n    In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\nOutside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])\n    In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\n    In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\nOutside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])\n    In Model: input size torch.Size([5, 5]) output size torch.Size([5, 2])\n    In Model: input size torch.Size([5, 5]) output size torch.Size([5, 2])\nOutside: input size torch.Size([10, 5]) output_size torch.Size([10, 2])\n```\n\nGPUTrickGPU GPU  GPU ( `m` 10 `DataParallel` GPU  10  GPU  GPU  5 \n\n#### \n\n```python\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nclass ToyModel(nn.Module):\n    def __init__(self):\n        super(ToyModel, self).__init__()\n        self.net1 = torch.nn.Linear(10, 10).to('cuda:0')\n        self.relu = torch.nn.ReLU()\n        self.net2 = torch.nn.Linear(10, 5).to('cuda:1')\n\n    def forward(self, x):\n        x = self.relu(self.net1(x.to('cuda:0')))\n        return self.net2(x.to('cuda:1'))\n```\n\n GPU  GPU GPU   GPU  `layer2``layer3``cuda:0``cuda:1`\n\nTrick\n\n#### Pipeline \n\n```python\nclass PipelineParallelResNet50(ModelParallelResNet50):\n    def __init__(self, split_size=20, *args, **kwargs):\n        super(PipelineParallelResNet50, self).__init__(*args, **kwargs)\n        self.split_size = split_size\n\n    def forward(self, x):\n        splits = iter(x.split(self.split_size, dim=0))\n        s_next = next(splits)\n        s_prev = self.seq1(s_next).to('cuda:1')\n        ret = []\n\n        for s_next in splits:\n            # A. s_prev runs on cuda:1\n            s_prev = self.seq2(s_prev)\n            ret.append(self.fc(s_prev.view(s_prev.size(0), -1)))\n\n            # B. s_next runs on cuda:0, which can run concurrently with A\n            s_prev = self.seq1(s_next).to('cuda:1')\n\n        s_prev = self.seq2(s_prev)\n        ret.append(self.fc(s_prev.view(s_prev.size(0), -1)))\n\n        return torch.cat(ret)\n\nsetup = \"model = PipelineParallelResNet50()\"\npp_run_times = timeit.repeat(\n    stmt, setup, number=1, repeat=num_repeat, globals=globals())\npp_mean, pp_std = np.mean(pp_run_times), np.std(pp_run_times)\n\nplot([mp_mean, rn_mean, pp_mean],\n     [mp_std, rn_std, pp_std],\n     ['Model Parallel', 'Single GPU', 'Pipelining Model Parallel'],\n     'mp_vs_rn_vs_pp.png')\n```\n\n2 GPUs50%100%\n\n###![1](1.png) \n\n### \n\n 2-GPU 1-GPU 2-GPU Pipelining  \n\n\n\n### nn.parallel.DistributedDataParallel\n\ntorch.distributed DataParallel \n\n`DistributedDataParallel`\n\n#### GPU\n\n```python\ntorch.distributed.init_process_group(backend=\"nccl\")\n# device_ids will include all GPU devices by default\nmodel = DistributedDataParallel(model) \n\n```\n\n#### GPU\n\nGPUGILDDP(DistributedDataParallel)GPUtorch.nn.DataParallelPytorch\n\n\n\n1. NGPUNtorch.distributed.launch\n\n```bash\npython -m torch.distributed.launch --nproc_per_node=n distributed_data_parallel.py\n```\n\n2. GPU model\n\n```python\nparser = argparse.ArgumentParser()\n# FOR DISTRIBUTED:  Parse for the local_rank argument, which will be supplied\n# automatically by torch.distributed.launch.\nparser.add_argument(\"--local_rank\", default=0, type=int)\nargs = parser.parse_args()\n\n#  GPU rank id\ntorch.cuda.set_device(args.local_rank)\n# model\ntorch.distributed.init_process_group(backend='nccl', world_size=n, init_method='env://')\nmodel = torch.nn.parallel.DistributedDataParallel(\n  \t\t\t\t\t\t\t\t\tmodel,\n\t\t\t\t\t\t\t\t\t\tdevice_ids=[args.local_rank],\n\t\t\t\t\t\t\t\t\t\toutput_device=args.local_rank)\n```\n\nNote:\n\n1. nccl \n2. nccl\n3. no_sync DDPForward-Backward\n\n```python\nddp = torch.nn.DistributedDataParallel(model, pg)\nwith ddp.no_sync():\nfor input in inputs:\n\tddp(input).backward()  # no synchronization, accumulate grads\nddp(another_input).backward()  # synchronize grads\n```\n\n\n\n### apex.parallel.DistributedDataParallel\n\ntorch.nn.parallel.DistributedDataParallelwrapperNCCL\n\n``` bash\n#  n <= GPU  1GPU1\ntorch.distributed.launch --nproc_per_node=n distributed_data_parallel.py\n# :\n# args.local_rank\n# os.environ['WORLD_SIZE']\n\n```\n\n\n\n1. model = DDP(model)  devices_ids output_device\n\n2. init_process_group  init_method='env://'\n\n   ``` python\n   torch.distributed.init_process_group(backend='nccl',init_method='env://')\n   ```\n\n\n\n```python\n# distributed_data_parallel.py\nimport torch\nimport argparse\nimport os\nfrom apex import amp\n# FOR DISTRIBUTED: (can also use torch.nn.parallel.DistributedDataParallel instead)\nfrom apex.parallel import DistributedDataParallel\n\nparser = argparse.ArgumentParser()\n# FOR DISTRIBUTED:  Parse for the local_rank argument, which will be supplied\n# automatically by torch.distributed.launch.\nparser.add_argument(\"--local_rank\", default=0, type=int)\nargs = parser.parse_args()\n\n# FOR DISTRIBUTED:  If we are running under torch.distributed.launch,\n# the 'WORLD_SIZE' environment variable will also be set automatically.\nargs.distributed = False\nif 'WORLD_SIZE' in os.environ:\n    args.distributed = int(os.environ['WORLD_SIZE']) > 1\n\nif args.distributed:\n    # FOR DISTRIBUTED:  Set the device according to local_rank.\n    torch.cuda.set_device(args.local_rank)\n\n    # FOR DISTRIBUTED:  Initialize the backend.  torch.distributed.launch will provide\n    # environment variables, and requires that you use init_method=`env://`.\n    torch.distributed.init_process_group(backend='nccl',\n                                         init_method='env://')\n\ntorch.backends.cudnn.benchmark = True\n\nN, D_in, D_out = 64, 1024, 16\n\n# Each process receives its own batch of \"fake input data\" and \"fake target data.\"\n# The \"training loop\" in each process just uses this fake batch over and over.\n# https://github.com/NVIDIA/apex/tree/master/examples/imagenet provides a more realistic\n# example of distributed data sampling for both training and validation.\nx = torch.randn(N, D_in, device='cuda')\ny = torch.randn(N, D_out, device='cuda')\n\nmodel = torch.nn.Linear(D_in, D_out).cuda()\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n\nmodel, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\")\n\nif args.distributed:\n    # FOR DISTRIBUTED:  After amp.initialize, wrap the model with\n    # apex.parallel.DistributedDataParallel.\n    model = DistributedDataParallel(model)\n    # torch.nn.parallel.DistributedDataParallel is also fine, with some added args:\n    # model = torch.nn.parallel.DistributedDataParallel(model,\n    #                                                   device_ids=[args.local_rank],\n    #                                                   output_device=args.local_rank)\n\nloss_fn = torch.nn.MSELoss()\n\nfor t in range(500):\n    optimizer.zero_grad()\n    y_pred = model(x)\n    loss = loss_fn(y_pred, y)\n    with amp.scale_loss(loss, optimizer) as scaled_loss:\n        scaled_loss.backward()\n    optimizer.step()\n\nif args.local_rank == 0:\n    print(\"final loss = \", loss)\n```\n\n [mixed precision training with DDP](https://github.com/NVIDIA/apex/tree/master/examples/imagenet)\n\n\n\n### DDP \n\ntorch.save  torch.load \n\n``` python\nimport os\nimport tempfile\nimport torch\nimport torch.distributed as dist\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.multiprocessing as mp\n\nfrom torch.nn.parallel import DistributedDataParallel as DDP\n\ndef demo_checkpoint(rank, world_size):\n    setup(rank, world_size)\n\n    # setup devices for this process, rank 1 uses GPUs [0, 1, 2, 3] and\n    # rank 2 uses GPUs [4, 5, 6, 7].\n    n = torch.cuda.device_count() // world_size\n    device_ids = list(range(rank * n, (rank + 1) * n))\n\n    model = ToyModel().to(device_ids[0])\n    # output_device defaults to device_ids[0]\n    ddp_model = DDP(model, device_ids=device_ids)\n\n    loss_fn = nn.MSELoss()\n    optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)\n\n    CHECKPOINT_PATH = tempfile.gettempdir() + \"/model.checkpoint\"\n    if rank == 0:\n        # All processes should see same parameters as they all start from same\n        # random parameters and gradients are synchronized in backward passes.\n        # Therefore, saving it in one process is sufficient.\n        torch.save(ddp_model.state_dict(), CHECKPOINT_PATH)\n\n    # Use a barrier() to make sure that process 1 loads the model after process\n    # 0 saves it.\n    dist.barrier()\n    # configure map_location properly\n    rank0_devices = [x - rank * len(device_ids) for x in device_ids]\n    device_pairs = zip(rank0_devices, device_ids)\n    map_location = {'cuda:%d' % x: 'cuda:%d' % y for x, y in device_pairs}\n    ddp_model.load_state_dict(\n        torch.load(CHECKPOINT_PATH, map_location=map_location))\n\n    optimizer.zero_grad()\n    outputs = ddp_model(torch.randn(20, 10))\n    labels = torch.randn(20, 5).to(device_ids[0])\n    loss_fn = nn.MSELoss()\n    loss_fn(outputs, labels).backward()\n    optimizer.step()\n\n    # Use a barrier() to make sure that all processes have finished reading the\n    # checkpoint\n    dist.barrier()\n\n    if rank == 0:\n        os.remove(CHECKPOINT_PATH)\n\n    cleanup()\n```\n\n\n\n### DDP \n\nDDP  GPU   DDP  GPU   GPU \n\n``` python\nclass ToyMpModel(nn.Module):\n    def __init__(self, dev0, dev1):\n        super(ToyMpModel, self).__init__()\n        self.dev0 = dev0\n        self.dev1 = dev1\n        self.net1 = torch.nn.Linear(10, 10).to(dev0)\n        self.relu = torch.nn.ReLU()\n        self.net2 = torch.nn.Linear(10, 5).to(dev1)\n\n    def forward(self, x):\n        x = x.to(self.dev0)\n        x = self.relu(self.net1(x))\n        x = x.to(self.dev1)\n        return self.net2(x)\n```\n\n GPU  DDP `device_ids``output_device` `forward()`\n\n``` python\ndef demo_model_parallel(rank, world_size):\n    setup(rank, world_size)\n\n    # setup mp_model and devices for this process\n    dev0 = rank * 2\n    dev1 = rank * 2 + 1\n    mp_model = ToyMpModel(dev0, dev1)\n    ddp_mp_model = DDP(mp_model)\n\n    loss_fn = nn.MSELoss()\n    optimizer = optim.SGD(ddp_mp_model.parameters(), lr=0.001)\n\n    optimizer.zero_grad()\n    # outputs will be on dev1\n    outputs = ddp_mp_model(torch.randn(20, 10))\n    labels = torch.randn(20, 5).to(dev1)\n    loss_fn(outputs, labels).backward()\n    optimizer.step()\n\n    cleanup()\n\nif __name__ == \"__main__\":\n    run_demo(demo_basic, 2)\n    run_demo(demo_checkpoint, 2)\n\n    if torch.cuda.device_count() >= 8:\n        run_demo(demo_model_parallel, 4)\n```\n\nsetup  torch.multiprocessing.spawn setup\n\n```python\nimport os\nimport tempfile\nimport torch\nimport torch.distributed as dist\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.multiprocessing as mp\n\nfrom torch.nn.parallel import DistributedDataParallel as DDP\n\ndef setup(rank, world_size):\n    os.environ['MASTER_ADDR'] = 'localhost'\n    os.environ['MASTER_PORT'] = '12355'\n\n    # initialize the process group\n    dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)\n\n    # Explicitly setting seed to make sure that models created in two processes\n    # start from same random weights and biases.\n    torch.manual_seed(42)\n\ndef cleanup():\n    dist.destroy_process_group()\n    \nclass ToyModel(nn.Module):\n    def __init__(self):\n        super(ToyModel, self).__init__()\n        self.net1 = nn.Linear(10, 10)\n        self.relu = nn.ReLU()\n        self.net2 = nn.Linear(10, 5)\n\n    def forward(self, x):\n        return self.net2(self.relu(self.net1(x)))\n\ndef demo_basic(rank, world_size):\n    setup(rank, world_size)\n\n    # setup devices for this process, rank 1 uses GPUs [0, 1, 2, 3] and\n    # rank 2 uses GPUs [4, 5, 6, 7].\n    n = torch.cuda.device_count() // world_size\n    device_ids = list(range(rank * n, (rank + 1) * n))\n\n    # create model and move it to device_ids[0]\n    model = ToyModel().to(device_ids[0])\n    # output_device defaults to device_ids[0]\n    ddp_model = DDP(model, device_ids=device_ids)\n\n    loss_fn = nn.MSELoss()\n    optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)\n\n    optimizer.zero_grad()\n    outputs = ddp_model(torch.randn(20, 10))\n    labels = torch.randn(20, 5).to(device_ids[0])\n    loss_fn(outputs, labels).backward()\n    optimizer.step()\n\n    cleanup()\n\ndef run_demo(demo_fn, world_size):\n    mp.spawn(demo_fn,\n             args=(world_size,),\n             nprocs=world_size,\n             join=True)\n```\n\n\n\n### Conclusion\n\nPytorchGPUGILDDP model \n\n\n\nReferences:\n\n[torch.nn](https://pytorch.apachecn.org/docs/1.4/75.html)\n\n[DistributedDataParallel API](https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html?highlight=distributeddataparallel#torch.nn.parallel.DistributedDataParallel)\n\n[CUDA Semantics](https://pytorch.org/docs/stable/notes/cuda.html#cuda-nn-ddp-instead)\n\n[](https://pytorch.apachecn.org/docs/1.4/34.html)\n\n[Pytorch](https://pytorch.apachecn.org/docs/1.4/35.html)\n\n[apex.parallel](https://nvidia.github.io/apex/parallel.html)\n\n","slug":"GPU-in-Pytorch-","published":1,"_id":"ckhyotdja0000l9289pxq20m8","comments":1,"layout":"post","photos":[],"link":"","content":"<p>CUDAGPUPytorch</p>\n<p>Pytorch 3torch.multiprocessing, nn.DataParallel, nn.parallel.DistributedDataParallelGPU nn.parallle.DistributedDataParallel, <a href=\"https://pytorch.org/docs/stable/notes/cuda.html#cuda-nn-ddp-instead\">CUDA SEMANTIC</a> </p>\n<blockquote>\n<p><strong>Use nn.parallel.DistributedDataParallel instead of multiprocessing or nn.DataParallel</strong></p>\n<p>Most use cases involving batched inputs and multiple GPUs should default to using <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel\"><code>DistributedDataParallel</code></a> to utilize more than one GPU.</p>\n<p>There are significant caveats to using CUDA models with <a href=\"https://pytorch.org/docs/stable/multiprocessing.html#module-torch.multiprocessing\"><code>multiprocessing</code></a>; unless care is taken to meet the data handling requirements exactly, it is likely that your program will have incorrect or undefined behavior.</p>\n<p>It is recommended to use <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel\"><code>DistributedDataParallel</code></a>, instead of <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html#torch.nn.DataParallel\"><code>DataParallel</code></a> to do multi-GPU training, even if there is only a single node.</p>\n<p>The difference between <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel\"><code>DistributedDataParallel</code></a> and <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html#torch.nn.DataParallel\"><code>DataParallel</code></a> is: <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel\"><code>DistributedDataParallel</code></a> uses multiprocessing where a process is created for each GPU, while <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html#torch.nn.DataParallel\"><code>DataParallel</code></a> uses multithreading. By using multiprocessing, each GPU has its dedicated process, this avoids the performance overhead caused by GIL of Python interpreter.</p>\n<p>If you use <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel\"><code>DistributedDataParallel</code></a>, you could use torch.distributed.launch utility to launch your program, see <a href=\"https://pytorch.org/docs/stable/distributed.html#distributed-launch\">Third-party backends</a>.</p>\n</blockquote>\n<h3 id=\"torch-multiprocessing\"><a href=\"#torch-multiprocessing\" class=\"headerlink\" title=\"torch.multiprocessing\"></a>torch.multiprocessing</h3><p>torch.multiprocessing  Python multiprocessing  python: multiprocessing.Queue Pytorch <a href=\"https://pytorch.org/docs/stable/notes/multiprocessing.html\">MULTIPROCESSING BEST PRACTICES</a>, <a href=\"https://pytorch.apachecn.org/docs/1.4/64.html\"></a></p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>multiprocessing <span class=\"token keyword\">as</span> mp\n<span class=\"token keyword\">from</span> model <span class=\"token keyword\">import</span> MyModel\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">train</span><span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\" spellcheck=\"true\"># Construct data_loader, optimizer, etc.</span>\n    <span class=\"token keyword\">for</span> data<span class=\"token punctuation\">,</span> labels <span class=\"token keyword\">in</span> data_loader<span class=\"token punctuation\">:</span>\n        optimizer<span class=\"token punctuation\">.</span>zero_grad<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        loss_fn<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>backward<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        optimizer<span class=\"token punctuation\">.</span>step<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\" spellcheck=\"true\"># This will update the shared parameters</span>\n\n<span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">'__main__'</span><span class=\"token punctuation\">:</span>\n    num_processes <span class=\"token operator\">=</span> <span class=\"token number\">4</span>\n    model <span class=\"token operator\">=</span> MyModel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\" spellcheck=\"true\"># NOTE: this is required for the ``fork`` method to work</span>\n    model<span class=\"token punctuation\">.</span>share_memory<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    processes <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">for</span> rank <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span>num_processes<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        p <span class=\"token operator\">=</span> mp<span class=\"token punctuation\">.</span>Process<span class=\"token punctuation\">(</span>target<span class=\"token operator\">=</span>train<span class=\"token punctuation\">,</span> args<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        p<span class=\"token punctuation\">.</span>start<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        processes<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>p<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span> p <span class=\"token keyword\">in</span> processes<span class=\"token punctuation\">:</span>\n        p<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre>\n<h3 id=\"DataParallel\"><a href=\"#DataParallel\" class=\"headerlink\" title=\"DataParallel\"></a>DataParallel</h3><p>DataParallelmodel copyGPUGPUSIMDGPU</p>\n<h4 id=\"DataParallel\"><a href=\"#DataParallel\" class=\"headerlink\" title=\"DataParallel\"></a>DataParallel</h4><pre class=\" language-python\"><code class=\"language-python\">model <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>DataParallel<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">)</span></code></pre>\n<p> outside model    inside model </p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">Model</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\" spellcheck=\"true\"># Our model</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> input_size<span class=\"token punctuation\">,</span> output_size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        super<span class=\"token punctuation\">(</span>Model<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>fc <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>input_size<span class=\"token punctuation\">,</span> output_size<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> input<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        output <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>fc<span class=\"token punctuation\">(</span>input<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"\\tIn Model: input size\"</span><span class=\"token punctuation\">,</span> input<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n              <span class=\"token string\">\"output size\"</span><span class=\"token punctuation\">,</span> output<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">return</span> output\n\n\nmodel <span class=\"token operator\">=</span> Model<span class=\"token punctuation\">(</span>input_size<span class=\"token punctuation\">,</span> output_size<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">if</span> torch<span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">.</span>device_count<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">></span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Let's use\"</span><span class=\"token punctuation\">,</span> torch<span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">.</span>device_count<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"GPUs!\"</span><span class=\"token punctuation\">)</span>\n  <span class=\"token comment\" spellcheck=\"true\"># dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs</span>\n  model <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>DataParallel<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">for</span> data <span class=\"token keyword\">in</span> rand_loader<span class=\"token punctuation\">:</span>\n    input <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device<span class=\"token punctuation\">)</span>\n    output <span class=\"token operator\">=</span> model<span class=\"token punctuation\">(</span>input<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Outside: input size\"</span><span class=\"token punctuation\">,</span> input<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n          <span class=\"token string\">\"output_size\"</span><span class=\"token punctuation\">,</span> output<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># 2 GPUs</span>\n<span class=\"token comment\" spellcheck=\"true\"># on 2 GPUs</span>\nLet's use <span class=\"token number\">2</span> GPUs!\n    In Model<span class=\"token punctuation\">:</span> input size torch<span class=\"token punctuation\">.</span>Size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">15</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> output size torch<span class=\"token punctuation\">.</span>Size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">15</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    In Model<span class=\"token punctuation\">:</span> input size torch<span class=\"token punctuation\">.</span>Size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">15</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> output size torch<span class=\"token punctuation\">.</span>Size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">15</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nOutside<span class=\"token punctuation\">:</span> input size torch<span class=\"token punctuation\">.</span>Size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">30</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> output_size torch<span class=\"token punctuation\">.</span>Size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">30</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    In Model<span class=\"token punctuation\">:</span> input size torch<span class=\"token punctuation\">.</span>Size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">15</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> output size torch<span class=\"token punctuation\">.</span>Size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">15</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    In Model<span class=\"token punctuation\">:</span> input size torch<span class=\"token punctuation\">.</span>Size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">15</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> output size torch<span class=\"token punctuation\">.</span>Size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">15</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nOutside<span class=\"token punctuation\">:</span> input size torch<span class=\"token punctuation\">.</span>Size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">30</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> output_size torch<span class=\"token punctuation\">.</span>Size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">30</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    In Model<span class=\"token punctuation\">:</span> input size torch<span class=\"token punctuation\">.</span>Size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">15</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> output size torch<span class=\"token punctuation\">.</span>Size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">15</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    In Model<span class=\"token punctuation\">:</span> input size torch<span class=\"token punctuation\">.</span>Size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">15</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> output size torch<span class=\"token punctuation\">.</span>Size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">15</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nOutside<span class=\"token punctuation\">:</span> input size torch<span class=\"token punctuation\">.</span>Size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">30</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> output_size torch<span class=\"token punctuation\">.</span>Size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">30</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    In Model<span class=\"token punctuation\">:</span> input size torch<span class=\"token punctuation\">.</span>Size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> output size torch<span class=\"token punctuation\">.</span>Size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    In Model<span class=\"token punctuation\">:</span> input size torch<span class=\"token punctuation\">.</span>Size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> output size torch<span class=\"token punctuation\">.</span>Size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nOutside<span class=\"token punctuation\">:</span> input size torch<span class=\"token punctuation\">.</span>Size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> output_size torch<span class=\"token punctuation\">.</span>Size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre>\n<p>GPUTrickGPU GPU  GPU ( <code>m</code> 10 <code>DataParallel</code> GPU  10  GPU  GPU  5 </p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><pre class=\" language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> torch\n<span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>nn <span class=\"token keyword\">as</span> nn\n<span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>optim <span class=\"token keyword\">as</span> optim\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">ToyModel</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        super<span class=\"token punctuation\">(</span>ToyModel<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>net1 <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span><span class=\"token string\">'cuda:0'</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>relu <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>net2 <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span><span class=\"token string\">'cuda:1'</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>relu<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>net1<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span><span class=\"token string\">'cuda:0'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>net2<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span><span class=\"token string\">'cuda:1'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre>\n<p> GPU  GPU GPU   GPU  <code>layer2</code><code>layer3</code><code>cuda:0</code><code>cuda:1</code></p>\n<p>Trick</p>\n<h4 id=\"Pipeline-\"><a href=\"#Pipeline-\" class=\"headerlink\" title=\"Pipeline \"></a>Pipeline </h4><pre class=\" language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">PipelineParallelResNet50</span><span class=\"token punctuation\">(</span>ModelParallelResNet50<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> split_size<span class=\"token operator\">=</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">*</span>args<span class=\"token punctuation\">,</span> <span class=\"token operator\">**</span>kwargs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        super<span class=\"token punctuation\">(</span>PipelineParallelResNet50<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token operator\">*</span>args<span class=\"token punctuation\">,</span> <span class=\"token operator\">**</span>kwargs<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>split_size <span class=\"token operator\">=</span> split_size\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        splits <span class=\"token operator\">=</span> iter<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>split_size<span class=\"token punctuation\">,</span> dim<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        s_next <span class=\"token operator\">=</span> next<span class=\"token punctuation\">(</span>splits<span class=\"token punctuation\">)</span>\n        s_prev <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>seq1<span class=\"token punctuation\">(</span>s_next<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span><span class=\"token string\">'cuda:1'</span><span class=\"token punctuation\">)</span>\n        ret <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n\n        <span class=\"token keyword\">for</span> s_next <span class=\"token keyword\">in</span> splits<span class=\"token punctuation\">:</span>\n            <span class=\"token comment\" spellcheck=\"true\"># A. s_prev runs on cuda:1</span>\n            s_prev <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>seq2<span class=\"token punctuation\">(</span>s_prev<span class=\"token punctuation\">)</span>\n            ret<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>fc<span class=\"token punctuation\">(</span>s_prev<span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span>s_prev<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n            <span class=\"token comment\" spellcheck=\"true\"># B. s_next runs on cuda:0, which can run concurrently with A</span>\n            s_prev <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>seq1<span class=\"token punctuation\">(</span>s_next<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span><span class=\"token string\">'cuda:1'</span><span class=\"token punctuation\">)</span>\n\n        s_prev <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>seq2<span class=\"token punctuation\">(</span>s_prev<span class=\"token punctuation\">)</span>\n        ret<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>fc<span class=\"token punctuation\">(</span>s_prev<span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span>s_prev<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">return</span> torch<span class=\"token punctuation\">.</span>cat<span class=\"token punctuation\">(</span>ret<span class=\"token punctuation\">)</span>\n\nsetup <span class=\"token operator\">=</span> <span class=\"token string\">\"model = PipelineParallelResNet50()\"</span>\npp_run_times <span class=\"token operator\">=</span> timeit<span class=\"token punctuation\">.</span>repeat<span class=\"token punctuation\">(</span>\n    stmt<span class=\"token punctuation\">,</span> setup<span class=\"token punctuation\">,</span> number<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> repeat<span class=\"token operator\">=</span>num_repeat<span class=\"token punctuation\">,</span> globals<span class=\"token operator\">=</span>globals<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\npp_mean<span class=\"token punctuation\">,</span> pp_std <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span>pp_run_times<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> np<span class=\"token punctuation\">.</span>std<span class=\"token punctuation\">(</span>pp_run_times<span class=\"token punctuation\">)</span>\n\nplot<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>mp_mean<span class=\"token punctuation\">,</span> rn_mean<span class=\"token punctuation\">,</span> pp_mean<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n     <span class=\"token punctuation\">[</span>mp_std<span class=\"token punctuation\">,</span> rn_std<span class=\"token punctuation\">,</span> pp_std<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n     <span class=\"token punctuation\">[</span><span class=\"token string\">'Model Parallel'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Single GPU'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'Pipelining Model Parallel'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n     <span class=\"token string\">'mp_vs_rn_vs_pp.png'</span><span class=\"token punctuation\">)</span></code></pre>\n<p>2 GPUs50%100%</p>\n<p>###<img src=\"1.png\" alt=\"1\"> </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> 2-GPU 1-GPU 2-GPU Pipelining  </p>\n<h3 id=\"nn-parallel-DistributedDataParallel\"><a href=\"#nn-parallel-DistributedDataParallel\" class=\"headerlink\" title=\"nn.parallel.DistributedDataParallel\"></a>nn.parallel.DistributedDataParallel</h3><p>torch.distributed DataParallel </p>\n<p><code>DistributedDataParallel</code></p>\n<h4 id=\"GPU\"><a href=\"#GPU\" class=\"headerlink\" title=\"GPU\"></a>GPU</h4><pre class=\" language-python\"><code class=\"language-python\">torch<span class=\"token punctuation\">.</span>distributed<span class=\"token punctuation\">.</span>init_process_group<span class=\"token punctuation\">(</span>backend<span class=\"token operator\">=</span><span class=\"token string\">\"nccl\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\" spellcheck=\"true\"># device_ids will include all GPU devices by default</span>\nmodel <span class=\"token operator\">=</span> DistributedDataParallel<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">)</span> \n</code></pre>\n<h4 id=\"GPU\"><a href=\"#GPU\" class=\"headerlink\" title=\"GPU\"></a>GPU</h4><p>GPUGILDDP(DistributedDataParallel)GPUtorch.nn.DataParallelPytorch</p>\n<p></p>\n<ol>\n<li>NGPUNtorch.distributed.launch</li>\n</ol>\n<pre class=\" language-bash\"><code class=\"language-bash\">python -m torch.distributed.launch --nproc_per_node<span class=\"token operator\">=</span>n distributed_data_parallel.py</code></pre>\n<ol start=\"2\">\n<li>GPU model</li>\n</ol>\n<pre class=\" language-python\"><code class=\"language-python\">parser <span class=\"token operator\">=</span> argparse<span class=\"token punctuation\">.</span>ArgumentParser<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\" spellcheck=\"true\"># FOR DISTRIBUTED:  Parse for the local_rank argument, which will be supplied</span>\n<span class=\"token comment\" spellcheck=\"true\"># automatically by torch.distributed.launch.</span>\nparser<span class=\"token punctuation\">.</span>add_argument<span class=\"token punctuation\">(</span><span class=\"token string\">\"--local_rank\"</span><span class=\"token punctuation\">,</span> default<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> type<span class=\"token operator\">=</span>int<span class=\"token punctuation\">)</span>\nargs <span class=\"token operator\">=</span> parser<span class=\"token punctuation\">.</span>parse_args<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\">#  GPU rank id</span>\ntorch<span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">.</span>set_device<span class=\"token punctuation\">(</span>args<span class=\"token punctuation\">.</span>local_rank<span class=\"token punctuation\">)</span>\n<span class=\"token comment\" spellcheck=\"true\"># model</span>\ntorch<span class=\"token punctuation\">.</span>distributed<span class=\"token punctuation\">.</span>init_process_group<span class=\"token punctuation\">(</span>backend<span class=\"token operator\">=</span><span class=\"token string\">'nccl'</span><span class=\"token punctuation\">,</span> world_size<span class=\"token operator\">=</span>n<span class=\"token punctuation\">,</span> init_method<span class=\"token operator\">=</span><span class=\"token string\">'env://'</span><span class=\"token punctuation\">)</span>\nmodel <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>parallel<span class=\"token punctuation\">.</span>DistributedDataParallel<span class=\"token punctuation\">(</span>\n                                      model<span class=\"token punctuation\">,</span>\n                                        device_ids<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>args<span class=\"token punctuation\">.</span>local_rank<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n                                        output_device<span class=\"token operator\">=</span>args<span class=\"token punctuation\">.</span>local_rank<span class=\"token punctuation\">)</span></code></pre>\n<p>Note:</p>\n<ol>\n<li>nccl </li>\n<li>nccl</li>\n<li>no_sync DDPForward-Backward</li>\n</ol>\n<pre class=\" language-python\"><code class=\"language-python\">ddp <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>DistributedDataParallel<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">,</span> pg<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">with</span> ddp<span class=\"token punctuation\">.</span>no_sync<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n<span class=\"token keyword\">for</span> input <span class=\"token keyword\">in</span> inputs<span class=\"token punctuation\">:</span>\n    ddp<span class=\"token punctuation\">(</span>input<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>backward<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\" spellcheck=\"true\"># no synchronization, accumulate grads</span>\nddp<span class=\"token punctuation\">(</span>another_input<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>backward<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\" spellcheck=\"true\"># synchronize grads</span></code></pre>\n<h3 id=\"apex-parallel-DistributedDataParallel\"><a href=\"#apex-parallel-DistributedDataParallel\" class=\"headerlink\" title=\"apex.parallel.DistributedDataParallel\"></a>apex.parallel.DistributedDataParallel</h3><p>torch.nn.parallel.DistributedDataParallelwrapperNCCL</p>\n<pre class=\" language-bash\"><code class=\"language-bash\"><span class=\"token comment\" spellcheck=\"true\">#  n &lt;= GPU  1GPU1</span>\ntorch.distributed.launch --nproc_per_node<span class=\"token operator\">=</span>n distributed_data_parallel.py\n<span class=\"token comment\" spellcheck=\"true\"># :</span>\n<span class=\"token comment\" spellcheck=\"true\"># args.local_rank</span>\n<span class=\"token comment\" spellcheck=\"true\"># os.environ['WORLD_SIZE']</span>\n</code></pre>\n<p></p>\n<ol>\n<li><p>model = DDP(model)  devices_ids output_device</p>\n</li>\n<li><p>init_process_group  init_method=env://</p>\n<pre class=\" language-python\"><code class=\"language-python\">torch<span class=\"token punctuation\">.</span>distributed<span class=\"token punctuation\">.</span>init_process_group<span class=\"token punctuation\">(</span>backend<span class=\"token operator\">=</span><span class=\"token string\">'nccl'</span><span class=\"token punctuation\">,</span>init_method<span class=\"token operator\">=</span><span class=\"token string\">'env://'</span><span class=\"token punctuation\">)</span></code></pre>\n</li>\n</ol>\n<p></p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token comment\" spellcheck=\"true\"># distributed_data_parallel.py</span>\n<span class=\"token keyword\">import</span> torch\n<span class=\"token keyword\">import</span> argparse\n<span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">from</span> apex <span class=\"token keyword\">import</span> amp\n<span class=\"token comment\" spellcheck=\"true\"># FOR DISTRIBUTED: (can also use torch.nn.parallel.DistributedDataParallel instead)</span>\n<span class=\"token keyword\">from</span> apex<span class=\"token punctuation\">.</span>parallel <span class=\"token keyword\">import</span> DistributedDataParallel\n\nparser <span class=\"token operator\">=</span> argparse<span class=\"token punctuation\">.</span>ArgumentParser<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\" spellcheck=\"true\"># FOR DISTRIBUTED:  Parse for the local_rank argument, which will be supplied</span>\n<span class=\"token comment\" spellcheck=\"true\"># automatically by torch.distributed.launch.</span>\nparser<span class=\"token punctuation\">.</span>add_argument<span class=\"token punctuation\">(</span><span class=\"token string\">\"--local_rank\"</span><span class=\"token punctuation\">,</span> default<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> type<span class=\"token operator\">=</span>int<span class=\"token punctuation\">)</span>\nargs <span class=\"token operator\">=</span> parser<span class=\"token punctuation\">.</span>parse_args<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># FOR DISTRIBUTED:  If we are running under torch.distributed.launch,</span>\n<span class=\"token comment\" spellcheck=\"true\"># the 'WORLD_SIZE' environment variable will also be set automatically.</span>\nargs<span class=\"token punctuation\">.</span>distributed <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span>\n<span class=\"token keyword\">if</span> <span class=\"token string\">'WORLD_SIZE'</span> <span class=\"token keyword\">in</span> os<span class=\"token punctuation\">.</span>environ<span class=\"token punctuation\">:</span>\n    args<span class=\"token punctuation\">.</span>distributed <span class=\"token operator\">=</span> int<span class=\"token punctuation\">(</span>os<span class=\"token punctuation\">.</span>environ<span class=\"token punctuation\">[</span><span class=\"token string\">'WORLD_SIZE'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">></span> <span class=\"token number\">1</span>\n\n<span class=\"token keyword\">if</span> args<span class=\"token punctuation\">.</span>distributed<span class=\"token punctuation\">:</span>\n    <span class=\"token comment\" spellcheck=\"true\"># FOR DISTRIBUTED:  Set the device according to local_rank.</span>\n    torch<span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">.</span>set_device<span class=\"token punctuation\">(</span>args<span class=\"token punctuation\">.</span>local_rank<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># FOR DISTRIBUTED:  Initialize the backend.  torch.distributed.launch will provide</span>\n    <span class=\"token comment\" spellcheck=\"true\"># environment variables, and requires that you use init_method=`env://`.</span>\n    torch<span class=\"token punctuation\">.</span>distributed<span class=\"token punctuation\">.</span>init_process_group<span class=\"token punctuation\">(</span>backend<span class=\"token operator\">=</span><span class=\"token string\">'nccl'</span><span class=\"token punctuation\">,</span>\n                                         init_method<span class=\"token operator\">=</span><span class=\"token string\">'env://'</span><span class=\"token punctuation\">)</span>\n\ntorch<span class=\"token punctuation\">.</span>backends<span class=\"token punctuation\">.</span>cudnn<span class=\"token punctuation\">.</span>benchmark <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span>\n\nN<span class=\"token punctuation\">,</span> D_in<span class=\"token punctuation\">,</span> D_out <span class=\"token operator\">=</span> <span class=\"token number\">64</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1024</span><span class=\"token punctuation\">,</span> <span class=\"token number\">16</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># Each process receives its own batch of \"fake input data\" and \"fake target data.\"</span>\n<span class=\"token comment\" spellcheck=\"true\"># The \"training loop\" in each process just uses this fake batch over and over.</span>\n<span class=\"token comment\" spellcheck=\"true\"># https://github.com/NVIDIA/apex/tree/master/examples/imagenet provides a more realistic</span>\n<span class=\"token comment\" spellcheck=\"true\"># example of distributed data sampling for both training and validation.</span>\nx <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>randn<span class=\"token punctuation\">(</span>N<span class=\"token punctuation\">,</span> D_in<span class=\"token punctuation\">,</span> device<span class=\"token operator\">=</span><span class=\"token string\">'cuda'</span><span class=\"token punctuation\">)</span>\ny <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>randn<span class=\"token punctuation\">(</span>N<span class=\"token punctuation\">,</span> D_out<span class=\"token punctuation\">,</span> device<span class=\"token operator\">=</span><span class=\"token string\">'cuda'</span><span class=\"token punctuation\">)</span>\n\nmodel <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span>D_in<span class=\"token punctuation\">,</span> D_out<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\noptimizer <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>optim<span class=\"token punctuation\">.</span>SGD<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">.</span>parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> lr<span class=\"token operator\">=</span><span class=\"token number\">1e</span><span class=\"token operator\">-</span><span class=\"token number\">3</span><span class=\"token punctuation\">)</span>\n\nmodel<span class=\"token punctuation\">,</span> optimizer <span class=\"token operator\">=</span> amp<span class=\"token punctuation\">.</span>initialize<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">,</span> optimizer<span class=\"token punctuation\">,</span> opt_level<span class=\"token operator\">=</span><span class=\"token string\">\"O1\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">if</span> args<span class=\"token punctuation\">.</span>distributed<span class=\"token punctuation\">:</span>\n    <span class=\"token comment\" spellcheck=\"true\"># FOR DISTRIBUTED:  After amp.initialize, wrap the model with</span>\n    <span class=\"token comment\" spellcheck=\"true\"># apex.parallel.DistributedDataParallel.</span>\n    model <span class=\"token operator\">=</span> DistributedDataParallel<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">)</span>\n    <span class=\"token comment\" spellcheck=\"true\"># torch.nn.parallel.DistributedDataParallel is also fine, with some added args:</span>\n    <span class=\"token comment\" spellcheck=\"true\"># model = torch.nn.parallel.DistributedDataParallel(model,</span>\n    <span class=\"token comment\" spellcheck=\"true\">#                                                   device_ids=[args.local_rank],</span>\n    <span class=\"token comment\" spellcheck=\"true\">#                                                   output_device=args.local_rank)</span>\n\nloss_fn <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>MSELoss<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">for</span> t <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span><span class=\"token number\">500</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    optimizer<span class=\"token punctuation\">.</span>zero_grad<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    y_pred <span class=\"token operator\">=</span> model<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n    loss <span class=\"token operator\">=</span> loss_fn<span class=\"token punctuation\">(</span>y_pred<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">with</span> amp<span class=\"token punctuation\">.</span>scale_loss<span class=\"token punctuation\">(</span>loss<span class=\"token punctuation\">,</span> optimizer<span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> scaled_loss<span class=\"token punctuation\">:</span>\n        scaled_loss<span class=\"token punctuation\">.</span>backward<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    optimizer<span class=\"token punctuation\">.</span>step<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">if</span> args<span class=\"token punctuation\">.</span>local_rank <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"final loss = \"</span><span class=\"token punctuation\">,</span> loss<span class=\"token punctuation\">)</span></code></pre>\n<p> <a href=\"https://github.com/NVIDIA/apex/tree/master/examples/imagenet\">mixed precision training with DDP</a></p>\n<h3 id=\"DDP-\"><a href=\"#DDP-\" class=\"headerlink\" title=\"DDP \"></a>DDP </h3><p>torch.save  torch.load </p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> tempfile\n<span class=\"token keyword\">import</span> torch\n<span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>distributed <span class=\"token keyword\">as</span> dist\n<span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>nn <span class=\"token keyword\">as</span> nn\n<span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>optim <span class=\"token keyword\">as</span> optim\n<span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>multiprocessing <span class=\"token keyword\">as</span> mp\n\n<span class=\"token keyword\">from</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>parallel <span class=\"token keyword\">import</span> DistributedDataParallel <span class=\"token keyword\">as</span> DDP\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">demo_checkpoint</span><span class=\"token punctuation\">(</span>rank<span class=\"token punctuation\">,</span> world_size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    setup<span class=\"token punctuation\">(</span>rank<span class=\"token punctuation\">,</span> world_size<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># setup devices for this process, rank 1 uses GPUs [0, 1, 2, 3] and</span>\n    <span class=\"token comment\" spellcheck=\"true\"># rank 2 uses GPUs [4, 5, 6, 7].</span>\n    n <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">.</span>device_count<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">//</span> world_size\n    device_ids <span class=\"token operator\">=</span> list<span class=\"token punctuation\">(</span>range<span class=\"token punctuation\">(</span>rank <span class=\"token operator\">*</span> n<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>rank <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    model <span class=\"token operator\">=</span> ToyModel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device_ids<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\" spellcheck=\"true\"># output_device defaults to device_ids[0]</span>\n    ddp_model <span class=\"token operator\">=</span> DDP<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">,</span> device_ids<span class=\"token operator\">=</span>device_ids<span class=\"token punctuation\">)</span>\n\n    loss_fn <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>MSELoss<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    optimizer <span class=\"token operator\">=</span> optim<span class=\"token punctuation\">.</span>SGD<span class=\"token punctuation\">(</span>ddp_model<span class=\"token punctuation\">.</span>parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> lr<span class=\"token operator\">=</span><span class=\"token number\">0.001</span><span class=\"token punctuation\">)</span>\n\n    CHECKPOINT_PATH <span class=\"token operator\">=</span> tempfile<span class=\"token punctuation\">.</span>gettempdir<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token string\">\"/model.checkpoint\"</span>\n    <span class=\"token keyword\">if</span> rank <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\" spellcheck=\"true\"># All processes should see same parameters as they all start from same</span>\n        <span class=\"token comment\" spellcheck=\"true\"># random parameters and gradients are synchronized in backward passes.</span>\n        <span class=\"token comment\" spellcheck=\"true\"># Therefore, saving it in one process is sufficient.</span>\n        torch<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span>ddp_model<span class=\"token punctuation\">.</span>state_dict<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> CHECKPOINT_PATH<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Use a barrier() to make sure that process 1 loads the model after process</span>\n    <span class=\"token comment\" spellcheck=\"true\"># 0 saves it.</span>\n    dist<span class=\"token punctuation\">.</span>barrier<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\" spellcheck=\"true\"># configure map_location properly</span>\n    rank0_devices <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>x <span class=\"token operator\">-</span> rank <span class=\"token operator\">*</span> len<span class=\"token punctuation\">(</span>device_ids<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> x <span class=\"token keyword\">in</span> device_ids<span class=\"token punctuation\">]</span>\n    device_pairs <span class=\"token operator\">=</span> zip<span class=\"token punctuation\">(</span>rank0_devices<span class=\"token punctuation\">,</span> device_ids<span class=\"token punctuation\">)</span>\n    map_location <span class=\"token operator\">=</span> <span class=\"token operator\">&amp;</span><span class=\"token comment\" spellcheck=\"true\">#123;'cuda:%d' % x: 'cuda:%d' % y for x, y in device_pairs&amp;#125;</span>\n    ddp_model<span class=\"token punctuation\">.</span>load_state_dict<span class=\"token punctuation\">(</span>\n        torch<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span>CHECKPOINT_PATH<span class=\"token punctuation\">,</span> map_location<span class=\"token operator\">=</span>map_location<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    optimizer<span class=\"token punctuation\">.</span>zero_grad<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    outputs <span class=\"token operator\">=</span> ddp_model<span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>randn<span class=\"token punctuation\">(</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    labels <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>randn<span class=\"token punctuation\">(</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device_ids<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    loss_fn <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>MSELoss<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    loss_fn<span class=\"token punctuation\">(</span>outputs<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>backward<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    optimizer<span class=\"token punctuation\">.</span>step<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Use a barrier() to make sure that all processes have finished reading the</span>\n    <span class=\"token comment\" spellcheck=\"true\"># checkpoint</span>\n    dist<span class=\"token punctuation\">.</span>barrier<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">if</span> rank <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n        os<span class=\"token punctuation\">.</span>remove<span class=\"token punctuation\">(</span>CHECKPOINT_PATH<span class=\"token punctuation\">)</span>\n\n    cleanup<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre>\n<h3 id=\"DDP-\"><a href=\"#DDP-\" class=\"headerlink\" title=\"DDP \"></a>DDP </h3><p>DDP  GPU   DDP  GPU   GPU </p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">ToyMpModel</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> dev0<span class=\"token punctuation\">,</span> dev1<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        super<span class=\"token punctuation\">(</span>ToyMpModel<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>dev0 <span class=\"token operator\">=</span> dev0\n        self<span class=\"token punctuation\">.</span>dev1 <span class=\"token operator\">=</span> dev1\n        self<span class=\"token punctuation\">.</span>net1 <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>dev0<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>relu <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>net2 <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>dev1<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        x <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>dev0<span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>relu<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>net1<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">=</span> x<span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>dev1<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>net2<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span></code></pre>\n<p> GPU  DDP <code>device_ids</code><code>output_device</code> <code>forward()</code></p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">demo_model_parallel</span><span class=\"token punctuation\">(</span>rank<span class=\"token punctuation\">,</span> world_size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    setup<span class=\"token punctuation\">(</span>rank<span class=\"token punctuation\">,</span> world_size<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># setup mp_model and devices for this process</span>\n    dev0 <span class=\"token operator\">=</span> rank <span class=\"token operator\">*</span> <span class=\"token number\">2</span>\n    dev1 <span class=\"token operator\">=</span> rank <span class=\"token operator\">*</span> <span class=\"token number\">2</span> <span class=\"token operator\">+</span> <span class=\"token number\">1</span>\n    mp_model <span class=\"token operator\">=</span> ToyMpModel<span class=\"token punctuation\">(</span>dev0<span class=\"token punctuation\">,</span> dev1<span class=\"token punctuation\">)</span>\n    ddp_mp_model <span class=\"token operator\">=</span> DDP<span class=\"token punctuation\">(</span>mp_model<span class=\"token punctuation\">)</span>\n\n    loss_fn <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>MSELoss<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    optimizer <span class=\"token operator\">=</span> optim<span class=\"token punctuation\">.</span>SGD<span class=\"token punctuation\">(</span>ddp_mp_model<span class=\"token punctuation\">.</span>parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> lr<span class=\"token operator\">=</span><span class=\"token number\">0.001</span><span class=\"token punctuation\">)</span>\n\n    optimizer<span class=\"token punctuation\">.</span>zero_grad<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\" spellcheck=\"true\"># outputs will be on dev1</span>\n    outputs <span class=\"token operator\">=</span> ddp_mp_model<span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>randn<span class=\"token punctuation\">(</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    labels <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>randn<span class=\"token punctuation\">(</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>dev1<span class=\"token punctuation\">)</span>\n    loss_fn<span class=\"token punctuation\">(</span>outputs<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>backward<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    optimizer<span class=\"token punctuation\">.</span>step<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    cleanup<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">\"__main__\"</span><span class=\"token punctuation\">:</span>\n    run_demo<span class=\"token punctuation\">(</span>demo_basic<span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n    run_demo<span class=\"token punctuation\">(</span>demo_checkpoint<span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">if</span> torch<span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">.</span>device_count<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">>=</span> <span class=\"token number\">8</span><span class=\"token punctuation\">:</span>\n        run_demo<span class=\"token punctuation\">(</span>demo_model_parallel<span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span></code></pre>\n<p>setup  torch.multiprocessing.spawn setup</p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> tempfile\n<span class=\"token keyword\">import</span> torch\n<span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>distributed <span class=\"token keyword\">as</span> dist\n<span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>nn <span class=\"token keyword\">as</span> nn\n<span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>optim <span class=\"token keyword\">as</span> optim\n<span class=\"token keyword\">import</span> torch<span class=\"token punctuation\">.</span>multiprocessing <span class=\"token keyword\">as</span> mp\n\n<span class=\"token keyword\">from</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>parallel <span class=\"token keyword\">import</span> DistributedDataParallel <span class=\"token keyword\">as</span> DDP\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">setup</span><span class=\"token punctuation\">(</span>rank<span class=\"token punctuation\">,</span> world_size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    os<span class=\"token punctuation\">.</span>environ<span class=\"token punctuation\">[</span><span class=\"token string\">'MASTER_ADDR'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token string\">'localhost'</span>\n    os<span class=\"token punctuation\">.</span>environ<span class=\"token punctuation\">[</span><span class=\"token string\">'MASTER_PORT'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token string\">'12355'</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># initialize the process group</span>\n    dist<span class=\"token punctuation\">.</span>init_process_group<span class=\"token punctuation\">(</span><span class=\"token string\">\"gloo\"</span><span class=\"token punctuation\">,</span> rank<span class=\"token operator\">=</span>rank<span class=\"token punctuation\">,</span> world_size<span class=\"token operator\">=</span>world_size<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># Explicitly setting seed to make sure that models created in two processes</span>\n    <span class=\"token comment\" spellcheck=\"true\"># start from same random weights and biases.</span>\n    torch<span class=\"token punctuation\">.</span>manual_seed<span class=\"token punctuation\">(</span><span class=\"token number\">42</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">cleanup</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    dist<span class=\"token punctuation\">.</span>destroy_process_group<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">ToyModel</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        super<span class=\"token punctuation\">(</span>ToyModel<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>net1 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>relu <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>net2 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>net2<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>relu<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>net1<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">demo_basic</span><span class=\"token punctuation\">(</span>rank<span class=\"token punctuation\">,</span> world_size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    setup<span class=\"token punctuation\">(</span>rank<span class=\"token punctuation\">,</span> world_size<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># setup devices for this process, rank 1 uses GPUs [0, 1, 2, 3] and</span>\n    <span class=\"token comment\" spellcheck=\"true\"># rank 2 uses GPUs [4, 5, 6, 7].</span>\n    n <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>cuda<span class=\"token punctuation\">.</span>device_count<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">//</span> world_size\n    device_ids <span class=\"token operator\">=</span> list<span class=\"token punctuation\">(</span>range<span class=\"token punctuation\">(</span>rank <span class=\"token operator\">*</span> n<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>rank <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># create model and move it to device_ids[0]</span>\n    model <span class=\"token operator\">=</span> ToyModel<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device_ids<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\" spellcheck=\"true\"># output_device defaults to device_ids[0]</span>\n    ddp_model <span class=\"token operator\">=</span> DDP<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">,</span> device_ids<span class=\"token operator\">=</span>device_ids<span class=\"token punctuation\">)</span>\n\n    loss_fn <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>MSELoss<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    optimizer <span class=\"token operator\">=</span> optim<span class=\"token punctuation\">.</span>SGD<span class=\"token punctuation\">(</span>ddp_model<span class=\"token punctuation\">.</span>parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> lr<span class=\"token operator\">=</span><span class=\"token number\">0.001</span><span class=\"token punctuation\">)</span>\n\n    optimizer<span class=\"token punctuation\">.</span>zero_grad<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    outputs <span class=\"token operator\">=</span> ddp_model<span class=\"token punctuation\">(</span>torch<span class=\"token punctuation\">.</span>randn<span class=\"token punctuation\">(</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    labels <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>randn<span class=\"token punctuation\">(</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span>device_ids<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    loss_fn<span class=\"token punctuation\">(</span>outputs<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>backward<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    optimizer<span class=\"token punctuation\">.</span>step<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    cleanup<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">run_demo</span><span class=\"token punctuation\">(</span>demo_fn<span class=\"token punctuation\">,</span> world_size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    mp<span class=\"token punctuation\">.</span>spawn<span class=\"token punctuation\">(</span>demo_fn<span class=\"token punctuation\">,</span>\n             args<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>world_size<span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n             nprocs<span class=\"token operator\">=</span>world_size<span class=\"token punctuation\">,</span>\n             join<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></code></pre>\n<h3 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h3><p>PytorchGPUGILDDP model </p>\n<p>References:</p>\n<p><a href=\"https://pytorch.apachecn.org/docs/1.4/75.html\">torch.nn</a></p>\n<p><a href=\"https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html?highlight=distributeddataparallel#torch.nn.parallel.DistributedDataParallel\">DistributedDataParallel API</a></p>\n<p><a href=\"https://pytorch.org/docs/stable/notes/cuda.html#cuda-nn-ddp-instead\">CUDA Semantics</a></p>\n<p><a href=\"https://pytorch.apachecn.org/docs/1.4/34.html\"></a></p>\n<p><a href=\"https://pytorch.apachecn.org/docs/1.4/35.html\">Pytorch</a></p>\n<p><a href=\"https://nvidia.github.io/apex/parallel.html\">apex.parallel</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>CUDAGPUPytorch</p>\n<p>Pytorch 3torch.multiprocessing, nn.DataParallel, nn.parallel.DistributedDataParallelGPU nn.parallle.DistributedDataParallel, <a href=\"https://pytorch.org/docs/stable/notes/cuda.html#cuda-nn-ddp-instead\">CUDA SEMANTIC</a> </p>\n<blockquote>\n<p><strong>Use nn.parallel.DistributedDataParallel instead of multiprocessing or nn.DataParallel</strong></p>\n<p>Most use cases involving batched inputs and multiple GPUs should default to using <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel\"><code>DistributedDataParallel</code></a> to utilize more than one GPU.</p>\n<p>There are significant caveats to using CUDA models with <a href=\"https://pytorch.org/docs/stable/multiprocessing.html#module-torch.multiprocessing\"><code>multiprocessing</code></a>; unless care is taken to meet the data handling requirements exactly, it is likely that your program will have incorrect or undefined behavior.</p>\n<p>It is recommended to use <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel\"><code>DistributedDataParallel</code></a>, instead of <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html#torch.nn.DataParallel\"><code>DataParallel</code></a> to do multi-GPU training, even if there is only a single node.</p>\n<p>The difference between <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel\"><code>DistributedDataParallel</code></a> and <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html#torch.nn.DataParallel\"><code>DataParallel</code></a> is: <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel\"><code>DistributedDataParallel</code></a> uses multiprocessing where a process is created for each GPU, while <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html#torch.nn.DataParallel\"><code>DataParallel</code></a> uses multithreading. By using multiprocessing, each GPU has its dedicated process, this avoids the performance overhead caused by GIL of Python interpreter.</p>\n<p>If you use <a href=\"https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel\"><code>DistributedDataParallel</code></a>, you could use torch.distributed.launch utility to launch your program, see <a href=\"https://pytorch.org/docs/stable/distributed.html#distributed-launch\">Third-party backends</a>.</p>\n</blockquote>\n<h3 id=\"torch-multiprocessing\"><a href=\"#torch-multiprocessing\" class=\"headerlink\" title=\"torch.multiprocessing\"></a>torch.multiprocessing</h3><p>torch.multiprocessing  Python multiprocessing  python: multiprocessing.Queue Pytorch <a href=\"https://pytorch.org/docs/stable/notes/multiprocessing.html\">MULTIPROCESSING BEST PRACTICES</a>, <a href=\"https://pytorch.apachecn.org/docs/1.4/64.html\"></a></p>\n<pre><code class=\"python\">import torch.multiprocessing as mp\nfrom model import MyModel\n\ndef train(model):\n    # Construct data_loader, optimizer, etc.\n    for data, labels in data_loader:\n        optimizer.zero_grad()\n        loss_fn(model(data), labels).backward()\n        optimizer.step()  # This will update the shared parameters\n\nif __name__ == &#39;__main__&#39;:\n    num_processes = 4\n    model = MyModel()\n    # NOTE: this is required for the ``fork`` method to work\n    model.share_memory()\n    processes = []\n    for rank in range(num_processes):\n        p = mp.Process(target=train, args=(model,))\n        p.start()\n        processes.append(p)\n    for p in processes:\n        p.join()</code></pre>\n<h3 id=\"DataParallel\"><a href=\"#DataParallel\" class=\"headerlink\" title=\"DataParallel\"></a>DataParallel</h3><p>DataParallelmodel copyGPUGPUSIMDGPU</p>\n<h4 id=\"DataParallel\"><a href=\"#DataParallel\" class=\"headerlink\" title=\"DataParallel\"></a>DataParallel</h4><pre><code class=\"python\">model = nn.DataParallel(model)</code></pre>\n<p> outside model    inside model </p>\n<pre><code class=\"python\">class Model(nn.Module):\n    # Our model\n\n    def __init__(self, input_size, output_size):\n        super(Model, self).__init__()\n        self.fc = nn.Linear(input_size, output_size)\n\n    def forward(self, input):\n        output = self.fc(input)\n        print(&quot;\\tIn Model: input size&quot;, input.size(),\n              &quot;output size&quot;, output.size())\n\n        return output\n\n\nmodel = Model(input_size, output_size)\nif torch.cuda.device_count() &gt; 1:\n  print(&quot;Let&#39;s use&quot;, torch.cuda.device_count(), &quot;GPUs!&quot;)\n  # dim = 0 [30, xxx] -&gt; [10, ...], [10, ...], [10, ...] on 3 GPUs\n  model = nn.DataParallel(model)\n\nmodel.to(device)\n\nfor data in rand_loader:\n    input = data.to(device)\n    output = model(input)\n    print(&quot;Outside: input size&quot;, input.size(),\n          &quot;output_size&quot;, output.size())\n\n# 2 GPUs\n# on 2 GPUs\nLet&#39;s use 2 GPUs!\n    In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\n    In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\nOutside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])\n    In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\n    In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\nOutside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])\n    In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\n    In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])\nOutside: input size torch.Size([30, 5]) output_size torch.Size([30, 2])\n    In Model: input size torch.Size([5, 5]) output size torch.Size([5, 2])\n    In Model: input size torch.Size([5, 5]) output size torch.Size([5, 2])\nOutside: input size torch.Size([10, 5]) output_size torch.Size([10, 2])</code></pre>\n<p>GPUTrickGPU GPU  GPU ( <code>m</code> 10 <code>DataParallel</code> GPU  10  GPU  GPU  5 </p>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><pre><code class=\"python\">import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nclass ToyModel(nn.Module):\n    def __init__(self):\n        super(ToyModel, self).__init__()\n        self.net1 = torch.nn.Linear(10, 10).to(&#39;cuda:0&#39;)\n        self.relu = torch.nn.ReLU()\n        self.net2 = torch.nn.Linear(10, 5).to(&#39;cuda:1&#39;)\n\n    def forward(self, x):\n        x = self.relu(self.net1(x.to(&#39;cuda:0&#39;)))\n        return self.net2(x.to(&#39;cuda:1&#39;))</code></pre>\n<p> GPU  GPU GPU   GPU  <code>layer2</code><code>layer3</code><code>cuda:0</code><code>cuda:1</code></p>\n<p>Trick</p>\n<h4 id=\"Pipeline-\"><a href=\"#Pipeline-\" class=\"headerlink\" title=\"Pipeline \"></a>Pipeline </h4><pre><code class=\"python\">class PipelineParallelResNet50(ModelParallelResNet50):\n    def __init__(self, split_size=20, *args, **kwargs):\n        super(PipelineParallelResNet50, self).__init__(*args, **kwargs)\n        self.split_size = split_size\n\n    def forward(self, x):\n        splits = iter(x.split(self.split_size, dim=0))\n        s_next = next(splits)\n        s_prev = self.seq1(s_next).to(&#39;cuda:1&#39;)\n        ret = []\n\n        for s_next in splits:\n            # A. s_prev runs on cuda:1\n            s_prev = self.seq2(s_prev)\n            ret.append(self.fc(s_prev.view(s_prev.size(0), -1)))\n\n            # B. s_next runs on cuda:0, which can run concurrently with A\n            s_prev = self.seq1(s_next).to(&#39;cuda:1&#39;)\n\n        s_prev = self.seq2(s_prev)\n        ret.append(self.fc(s_prev.view(s_prev.size(0), -1)))\n\n        return torch.cat(ret)\n\nsetup = &quot;model = PipelineParallelResNet50()&quot;\npp_run_times = timeit.repeat(\n    stmt, setup, number=1, repeat=num_repeat, globals=globals())\npp_mean, pp_std = np.mean(pp_run_times), np.std(pp_run_times)\n\nplot([mp_mean, rn_mean, pp_mean],\n     [mp_std, rn_std, pp_std],\n     [&#39;Model Parallel&#39;, &#39;Single GPU&#39;, &#39;Pipelining Model Parallel&#39;],\n     &#39;mp_vs_rn_vs_pp.png&#39;)</code></pre>\n<p>2 GPUs50%100%</p>\n<p>###<img src=\"1.png\" alt=\"1\"> </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p> 2-GPU 1-GPU 2-GPU Pipelining  </p>\n<h3 id=\"nn-parallel-DistributedDataParallel\"><a href=\"#nn-parallel-DistributedDataParallel\" class=\"headerlink\" title=\"nn.parallel.DistributedDataParallel\"></a>nn.parallel.DistributedDataParallel</h3><p>torch.distributed DataParallel </p>\n<p><code>DistributedDataParallel</code></p>\n<h4 id=\"GPU\"><a href=\"#GPU\" class=\"headerlink\" title=\"GPU\"></a>GPU</h4><pre><code class=\"python\">torch.distributed.init_process_group(backend=&quot;nccl&quot;)\n# device_ids will include all GPU devices by default\nmodel = DistributedDataParallel(model) \n</code></pre>\n<h4 id=\"GPU\"><a href=\"#GPU\" class=\"headerlink\" title=\"GPU\"></a>GPU</h4><p>GPUGILDDP(DistributedDataParallel)GPUtorch.nn.DataParallelPytorch</p>\n<p></p>\n<ol>\n<li>NGPUNtorch.distributed.launch</li>\n</ol>\n<pre><code class=\"bash\">python -m torch.distributed.launch --nproc_per_node=n distributed_data_parallel.py</code></pre>\n<ol start=\"2\">\n<li>GPU model</li>\n</ol>\n<pre><code class=\"python\">parser = argparse.ArgumentParser()\n# FOR DISTRIBUTED:  Parse for the local_rank argument, which will be supplied\n# automatically by torch.distributed.launch.\nparser.add_argument(&quot;--local_rank&quot;, default=0, type=int)\nargs = parser.parse_args()\n\n#  GPU rank id\ntorch.cuda.set_device(args.local_rank)\n# model\ntorch.distributed.init_process_group(backend=&#39;nccl&#39;, world_size=n, init_method=&#39;env://&#39;)\nmodel = torch.nn.parallel.DistributedDataParallel(\n                                      model,\n                                        device_ids=[args.local_rank],\n                                        output_device=args.local_rank)</code></pre>\n<p>Note:</p>\n<ol>\n<li>nccl </li>\n<li>nccl</li>\n<li>no_sync DDPForward-Backward</li>\n</ol>\n<pre><code class=\"python\">ddp = torch.nn.DistributedDataParallel(model, pg)\nwith ddp.no_sync():\nfor input in inputs:\n    ddp(input).backward()  # no synchronization, accumulate grads\nddp(another_input).backward()  # synchronize grads</code></pre>\n<h3 id=\"apex-parallel-DistributedDataParallel\"><a href=\"#apex-parallel-DistributedDataParallel\" class=\"headerlink\" title=\"apex.parallel.DistributedDataParallel\"></a>apex.parallel.DistributedDataParallel</h3><p>torch.nn.parallel.DistributedDataParallelwrapperNCCL</p>\n<pre><code class=\"bash\">#  n &lt;= GPU  1GPU1\ntorch.distributed.launch --nproc_per_node=n distributed_data_parallel.py\n# :\n# args.local_rank\n# os.environ[&#39;WORLD_SIZE&#39;]\n</code></pre>\n<p></p>\n<ol>\n<li><p>model = DDP(model)  devices_ids output_device</p>\n</li>\n<li><p>init_process_group  init_method=env://</p>\n<pre><code class=\"python\">torch.distributed.init_process_group(backend=&#39;nccl&#39;,init_method=&#39;env://&#39;)</code></pre>\n</li>\n</ol>\n<p></p>\n<pre><code class=\"python\"># distributed_data_parallel.py\nimport torch\nimport argparse\nimport os\nfrom apex import amp\n# FOR DISTRIBUTED: (can also use torch.nn.parallel.DistributedDataParallel instead)\nfrom apex.parallel import DistributedDataParallel\n\nparser = argparse.ArgumentParser()\n# FOR DISTRIBUTED:  Parse for the local_rank argument, which will be supplied\n# automatically by torch.distributed.launch.\nparser.add_argument(&quot;--local_rank&quot;, default=0, type=int)\nargs = parser.parse_args()\n\n# FOR DISTRIBUTED:  If we are running under torch.distributed.launch,\n# the &#39;WORLD_SIZE&#39; environment variable will also be set automatically.\nargs.distributed = False\nif &#39;WORLD_SIZE&#39; in os.environ:\n    args.distributed = int(os.environ[&#39;WORLD_SIZE&#39;]) &gt; 1\n\nif args.distributed:\n    # FOR DISTRIBUTED:  Set the device according to local_rank.\n    torch.cuda.set_device(args.local_rank)\n\n    # FOR DISTRIBUTED:  Initialize the backend.  torch.distributed.launch will provide\n    # environment variables, and requires that you use init_method=`env://`.\n    torch.distributed.init_process_group(backend=&#39;nccl&#39;,\n                                         init_method=&#39;env://&#39;)\n\ntorch.backends.cudnn.benchmark = True\n\nN, D_in, D_out = 64, 1024, 16\n\n# Each process receives its own batch of &quot;fake input data&quot; and &quot;fake target data.&quot;\n# The &quot;training loop&quot; in each process just uses this fake batch over and over.\n# https://github.com/NVIDIA/apex/tree/master/examples/imagenet provides a more realistic\n# example of distributed data sampling for both training and validation.\nx = torch.randn(N, D_in, device=&#39;cuda&#39;)\ny = torch.randn(N, D_out, device=&#39;cuda&#39;)\n\nmodel = torch.nn.Linear(D_in, D_out).cuda()\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n\nmodel, optimizer = amp.initialize(model, optimizer, opt_level=&quot;O1&quot;)\n\nif args.distributed:\n    # FOR DISTRIBUTED:  After amp.initialize, wrap the model with\n    # apex.parallel.DistributedDataParallel.\n    model = DistributedDataParallel(model)\n    # torch.nn.parallel.DistributedDataParallel is also fine, with some added args:\n    # model = torch.nn.parallel.DistributedDataParallel(model,\n    #                                                   device_ids=[args.local_rank],\n    #                                                   output_device=args.local_rank)\n\nloss_fn = torch.nn.MSELoss()\n\nfor t in range(500):\n    optimizer.zero_grad()\n    y_pred = model(x)\n    loss = loss_fn(y_pred, y)\n    with amp.scale_loss(loss, optimizer) as scaled_loss:\n        scaled_loss.backward()\n    optimizer.step()\n\nif args.local_rank == 0:\n    print(&quot;final loss = &quot;, loss)</code></pre>\n<p> <a href=\"https://github.com/NVIDIA/apex/tree/master/examples/imagenet\">mixed precision training with DDP</a></p>\n<h3 id=\"DDP-\"><a href=\"#DDP-\" class=\"headerlink\" title=\"DDP \"></a>DDP </h3><p>torch.save  torch.load </p>\n<pre><code class=\"python\">import os\nimport tempfile\nimport torch\nimport torch.distributed as dist\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.multiprocessing as mp\n\nfrom torch.nn.parallel import DistributedDataParallel as DDP\n\ndef demo_checkpoint(rank, world_size):\n    setup(rank, world_size)\n\n    # setup devices for this process, rank 1 uses GPUs [0, 1, 2, 3] and\n    # rank 2 uses GPUs [4, 5, 6, 7].\n    n = torch.cuda.device_count() // world_size\n    device_ids = list(range(rank * n, (rank + 1) * n))\n\n    model = ToyModel().to(device_ids[0])\n    # output_device defaults to device_ids[0]\n    ddp_model = DDP(model, device_ids=device_ids)\n\n    loss_fn = nn.MSELoss()\n    optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)\n\n    CHECKPOINT_PATH = tempfile.gettempdir() + &quot;/model.checkpoint&quot;\n    if rank == 0:\n        # All processes should see same parameters as they all start from same\n        # random parameters and gradients are synchronized in backward passes.\n        # Therefore, saving it in one process is sufficient.\n        torch.save(ddp_model.state_dict(), CHECKPOINT_PATH)\n\n    # Use a barrier() to make sure that process 1 loads the model after process\n    # 0 saves it.\n    dist.barrier()\n    # configure map_location properly\n    rank0_devices = [x - rank * len(device_ids) for x in device_ids]\n    device_pairs = zip(rank0_devices, device_ids)\n    map_location = &#123;&#39;cuda:%d&#39; % x: &#39;cuda:%d&#39; % y for x, y in device_pairs&#125;\n    ddp_model.load_state_dict(\n        torch.load(CHECKPOINT_PATH, map_location=map_location))\n\n    optimizer.zero_grad()\n    outputs = ddp_model(torch.randn(20, 10))\n    labels = torch.randn(20, 5).to(device_ids[0])\n    loss_fn = nn.MSELoss()\n    loss_fn(outputs, labels).backward()\n    optimizer.step()\n\n    # Use a barrier() to make sure that all processes have finished reading the\n    # checkpoint\n    dist.barrier()\n\n    if rank == 0:\n        os.remove(CHECKPOINT_PATH)\n\n    cleanup()</code></pre>\n<h3 id=\"DDP-\"><a href=\"#DDP-\" class=\"headerlink\" title=\"DDP \"></a>DDP </h3><p>DDP  GPU   DDP  GPU   GPU </p>\n<pre><code class=\"python\">class ToyMpModel(nn.Module):\n    def __init__(self, dev0, dev1):\n        super(ToyMpModel, self).__init__()\n        self.dev0 = dev0\n        self.dev1 = dev1\n        self.net1 = torch.nn.Linear(10, 10).to(dev0)\n        self.relu = torch.nn.ReLU()\n        self.net2 = torch.nn.Linear(10, 5).to(dev1)\n\n    def forward(self, x):\n        x = x.to(self.dev0)\n        x = self.relu(self.net1(x))\n        x = x.to(self.dev1)\n        return self.net2(x)</code></pre>\n<p> GPU  DDP <code>device_ids</code><code>output_device</code> <code>forward()</code></p>\n<pre><code class=\"python\">def demo_model_parallel(rank, world_size):\n    setup(rank, world_size)\n\n    # setup mp_model and devices for this process\n    dev0 = rank * 2\n    dev1 = rank * 2 + 1\n    mp_model = ToyMpModel(dev0, dev1)\n    ddp_mp_model = DDP(mp_model)\n\n    loss_fn = nn.MSELoss()\n    optimizer = optim.SGD(ddp_mp_model.parameters(), lr=0.001)\n\n    optimizer.zero_grad()\n    # outputs will be on dev1\n    outputs = ddp_mp_model(torch.randn(20, 10))\n    labels = torch.randn(20, 5).to(dev1)\n    loss_fn(outputs, labels).backward()\n    optimizer.step()\n\n    cleanup()\n\nif __name__ == &quot;__main__&quot;:\n    run_demo(demo_basic, 2)\n    run_demo(demo_checkpoint, 2)\n\n    if torch.cuda.device_count() &gt;= 8:\n        run_demo(demo_model_parallel, 4)</code></pre>\n<p>setup  torch.multiprocessing.spawn setup</p>\n<pre><code class=\"python\">import os\nimport tempfile\nimport torch\nimport torch.distributed as dist\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.multiprocessing as mp\n\nfrom torch.nn.parallel import DistributedDataParallel as DDP\n\ndef setup(rank, world_size):\n    os.environ[&#39;MASTER_ADDR&#39;] = &#39;localhost&#39;\n    os.environ[&#39;MASTER_PORT&#39;] = &#39;12355&#39;\n\n    # initialize the process group\n    dist.init_process_group(&quot;gloo&quot;, rank=rank, world_size=world_size)\n\n    # Explicitly setting seed to make sure that models created in two processes\n    # start from same random weights and biases.\n    torch.manual_seed(42)\n\ndef cleanup():\n    dist.destroy_process_group()\n\nclass ToyModel(nn.Module):\n    def __init__(self):\n        super(ToyModel, self).__init__()\n        self.net1 = nn.Linear(10, 10)\n        self.relu = nn.ReLU()\n        self.net2 = nn.Linear(10, 5)\n\n    def forward(self, x):\n        return self.net2(self.relu(self.net1(x)))\n\ndef demo_basic(rank, world_size):\n    setup(rank, world_size)\n\n    # setup devices for this process, rank 1 uses GPUs [0, 1, 2, 3] and\n    # rank 2 uses GPUs [4, 5, 6, 7].\n    n = torch.cuda.device_count() // world_size\n    device_ids = list(range(rank * n, (rank + 1) * n))\n\n    # create model and move it to device_ids[0]\n    model = ToyModel().to(device_ids[0])\n    # output_device defaults to device_ids[0]\n    ddp_model = DDP(model, device_ids=device_ids)\n\n    loss_fn = nn.MSELoss()\n    optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)\n\n    optimizer.zero_grad()\n    outputs = ddp_model(torch.randn(20, 10))\n    labels = torch.randn(20, 5).to(device_ids[0])\n    loss_fn(outputs, labels).backward()\n    optimizer.step()\n\n    cleanup()\n\ndef run_demo(demo_fn, world_size):\n    mp.spawn(demo_fn,\n             args=(world_size,),\n             nprocs=world_size,\n             join=True)</code></pre>\n<h3 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h3><p>PytorchGPUGILDDP model </p>\n<p>References:</p>\n<p><a href=\"https://pytorch.apachecn.org/docs/1.4/75.html\">torch.nn</a></p>\n<p><a href=\"https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html?highlight=distributeddataparallel#torch.nn.parallel.DistributedDataParallel\">DistributedDataParallel API</a></p>\n<p><a href=\"https://pytorch.org/docs/stable/notes/cuda.html#cuda-nn-ddp-instead\">CUDA Semantics</a></p>\n<p><a href=\"https://pytorch.apachecn.org/docs/1.4/34.html\"></a></p>\n<p><a href=\"https://pytorch.apachecn.org/docs/1.4/35.html\">Pytorch</a></p>\n<p><a href=\"https://nvidia.github.io/apex/parallel.html\">apex.parallel</a></p>\n"},{"title":"LeetCode 1-100 ","toc":true,"mathjax":true,"top":false,"cover":true,"date":"2020-12-07T03:06:05.000Z","updated":"2020-12-10T08:01:47.037Z","_content":"\nLeetCode 100 2012LeetCode 100LeetCodePOJACM2\n\nLeetCode2012OJOJLeetCode10EasyJavaLeetCodeJava mediumeasyHardDiscussLeetCode OJDebugDiscussLeetCode 100HardLeetCode\n\n LeetCode ****OJAC****-JavaJavaJavaI/OJavaJavaJarLeetCode OJJavaJavaLeetCode  \n\nLeetCode 100%BlogPython\n\nPythonPython 202Hard 100\n\n AC100100Blog100-200Blog100Blog\n\nLeetCode 100","source":"_posts/LeetCode-1-100-.md","raw":"---\ntitle: LeetCode 1-100 \ntoc: true\nmathjax: true\ntop: false\ncover: true\ndate: 2020-12-07 11:06:05\nupdated:\ncategories: \ntags:\n\t- Algorithms\n\t- LeetCode\n\t- \n---\n\nLeetCode 100 2012LeetCode 100LeetCodePOJACM2\n\nLeetCode2012OJOJLeetCode10EasyJavaLeetCodeJava mediumeasyHardDiscussLeetCode OJDebugDiscussLeetCode 100HardLeetCode\n\n LeetCode ****OJAC****-JavaJavaJavaI/OJavaJavaJarLeetCode OJJavaJavaLeetCode  \n\nLeetCode 100%BlogPython\n\nPythonPython 202Hard 100\n\n AC100100Blog100-200Blog100Blog\n\nLeetCode 100","slug":"LeetCode-1-100-","published":1,"_id":"ckiedp6df0000ue287z2u4kkg","comments":1,"layout":"post","photos":[],"link":"","content":"<p>LeetCode 100 2012LeetCode 100LeetCodePOJACM2</p>\n<p>LeetCode2012OJOJLeetCode10EasyJavaLeetCodeJava mediumeasyHardDiscussLeetCode OJDebugDiscussLeetCode 100HardLeetCode</p>\n<p> LeetCode <strong></strong>OJAC<strong></strong>-JavaJavaJavaI/OJavaJavaJarLeetCode OJJavaJavaLeetCode  </p>\n<p>LeetCode 100%BlogPython</p>\n<p>PythonPython 202Hard 100</p>\n<p> AC100100Blog100-200Blog100Blog</p>\n<p>LeetCode 100</p>\n","site":{"data":{}},"excerpt":"","more":"<p>LeetCode 100 2012LeetCode 100LeetCodePOJACM2</p>\n<p>LeetCode2012OJOJLeetCode10EasyJavaLeetCodeJava mediumeasyHardDiscussLeetCode OJDebugDiscussLeetCode 100HardLeetCode</p>\n<p> LeetCode <strong></strong>OJAC<strong></strong>-JavaJavaJavaI/OJavaJavaJarLeetCode OJJavaJavaLeetCode  </p>\n<p>LeetCode 100%BlogPython</p>\n<p>PythonPython 202Hard 100</p>\n<p> AC100100Blog100-200Blog100Blog</p>\n<p>LeetCode 100</p>\n"},{"title":"LeetCode 115. Distinct Subsequences","toc":true,"mathjax":true,"top":false,"cover":true,"date":"2020-12-09T09:52:16.000Z","updated":"2020-12-10T10:11:23.217Z","_content":"\n> Given two strings `s` and `t`, return *the number of distinct subsequences of `s` which equals `t`*.\n>\n> A string's **subsequence** is a new string formed from the original string by deleting some (can be none) of the characters without disturbing the relative positions of the remaining characters. (i.e., `\"ACE\"` is a subsequence of `\"ABCDE\"` while `\"AEC\"` is not).\n>\n> It's guaranteed the answer fits on a 32-bit signed integer.\n>\n>  \n>\n> **Example 1:**\n>\n> ```\n> Input: s = \"rabbbit\", t = \"rabbit\"\n> Output: 3\n> Explanation:\n> As shown below, there are 3 ways you can generate \"rabbit\" from S.\n> rabbbit\n> rabbbit\n> rabbbit\n> ```\n>\n> **Example 2:**\n>\n> ```\n> Input: s = \"babgbag\", t = \"bag\"\n> Output: 5\n> Explanation:\n> As shown below, there are 5 ways you can generate \"bag\" from S.\n> babgbag\n> babgbag\n> babgbag\n> babgbag\n> babgbag\n> ```\n>\n>  \n>\n> **Constraints:**\n>\n> - `0 <= s.length, t.length <= 1000`\n> - `s` and `t` consist of English letters.\n\n\n\nHard100DFSDFSDFSDFSAC  ACdpACACHard\n\n### DFS\n\nst3\n\n1. s == '' ts0\n2. t == '' t1\n3. s==t 1\n4. \n\ntt[0]sst[0]stsum\n\n``` python\nclass Solution:\n    # DFS\n    def numDistinct(self, s: str, t: str) -> int:\n        if len(t) == 0:\n            return 1\n        if len(s) == 0:\n            return 0\n        if s == t:\n            return 1\n\n        r = 0\n        t0 = t[0]\n        pos = -1\n        news = s[pos+1: ]\n        while t0 in news:\n            pos = news.index(t0)\n            news = news[pos+1: ]\n            r += self.numDistinct(news, t[1: ])\n        return r\n```\n\n106/116 ACsDP\n\n###   Dynamic Programming (DP)\n\nDPDPDPDP\n\nDP(LCS)DP$dp[i][j]$$s[i]!=t[j]$$dp[i-1][j]$$dp[i][j-1]$DPLCS\n\n|      |  r   |  a   |  b   |  b   |  b   |  i   |  t   |\n| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |\n|  r   |  1   |  0   |  0   |  0   |  0   |  0   |  0   |\n|  a   |  0   |  1   |  0   |  0   |  0   |  0   |  0   |\n|  b   |  0   |  0   |  1   |  1   |  1   |  0   |  0   |\n|  b   |  0   |  0   |  0   |  1   |  2   |  0   |  0   |\n|  i   |  0   |  0   |  0   |  0   |  0   |  3   |  0   |\n|  t   |  0   |  0   |  0   |  0   |  0   |  0   |  3   |\n\n$dp[i][j]$ii-1$dp[i-1][ :j]$$s[i]==t[j]$0$sum(dp[-1])$\n\n2.\n\n|      |  b   |  a   |  b   |  g   |  b   |  a   |  g   |\n| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |\n|  b   |  1   |  0   |  1   |  0   |  1   |  0   |  0   |\n|  a   |  0   |  1   |  0   |  0   |  0   |  3   |  0   |\n|  g   |  0   |  0   |  0   |  1   |  0   |  0   |  4   |\n\n copydpList 2List\n\n``` python\n# dp\n    def numDistinct(self, s, t):\n        dp = [0]* len(s)\n        for i,char in enumerate(s):\n            if char == t[0]:\n                dp[i] = 1\n\n        for char in t[1: ]:\n            count = 0\n            dp_next = [0] * len(s)\n            for i in range(len(s)):\n                if s[i] == char:\n                    dp_next[i] = count\n                count += dp[i]\n            dp = dp_next\n\n        return sum(dp)\n```\n\n36ms AC ACDP\n\n\n\n### Conclusion\n\nAC\n\n","source":"_posts/LeetCode-115-Distinct-Subsequences.md","raw":"---\ntitle: LeetCode 115. Distinct Subsequences\ntoc: true\nmathjax: true\ntop: false\ncover: true\ndate: 2020-12-09 17:52:16\nupdated:\ncategories: Algorithms\ntags:\n\t- Algorithms\n\t- LeetCode\n---\n\n> Given two strings `s` and `t`, return *the number of distinct subsequences of `s` which equals `t`*.\n>\n> A string's **subsequence** is a new string formed from the original string by deleting some (can be none) of the characters without disturbing the relative positions of the remaining characters. (i.e., `\"ACE\"` is a subsequence of `\"ABCDE\"` while `\"AEC\"` is not).\n>\n> It's guaranteed the answer fits on a 32-bit signed integer.\n>\n>  \n>\n> **Example 1:**\n>\n> ```\n> Input: s = \"rabbbit\", t = \"rabbit\"\n> Output: 3\n> Explanation:\n> As shown below, there are 3 ways you can generate \"rabbit\" from S.\n> rabbbit\n> rabbbit\n> rabbbit\n> ```\n>\n> **Example 2:**\n>\n> ```\n> Input: s = \"babgbag\", t = \"bag\"\n> Output: 5\n> Explanation:\n> As shown below, there are 5 ways you can generate \"bag\" from S.\n> babgbag\n> babgbag\n> babgbag\n> babgbag\n> babgbag\n> ```\n>\n>  \n>\n> **Constraints:**\n>\n> - `0 <= s.length, t.length <= 1000`\n> - `s` and `t` consist of English letters.\n\n\n\nHard100DFSDFSDFSDFSAC  ACdpACACHard\n\n### DFS\n\nst3\n\n1. s == '' ts0\n2. t == '' t1\n3. s==t 1\n4. \n\ntt[0]sst[0]stsum\n\n``` python\nclass Solution:\n    # DFS\n    def numDistinct(self, s: str, t: str) -> int:\n        if len(t) == 0:\n            return 1\n        if len(s) == 0:\n            return 0\n        if s == t:\n            return 1\n\n        r = 0\n        t0 = t[0]\n        pos = -1\n        news = s[pos+1: ]\n        while t0 in news:\n            pos = news.index(t0)\n            news = news[pos+1: ]\n            r += self.numDistinct(news, t[1: ])\n        return r\n```\n\n106/116 ACsDP\n\n###   Dynamic Programming (DP)\n\nDPDPDPDP\n\nDP(LCS)DP$dp[i][j]$$s[i]!=t[j]$$dp[i-1][j]$$dp[i][j-1]$DPLCS\n\n|      |  r   |  a   |  b   |  b   |  b   |  i   |  t   |\n| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |\n|  r   |  1   |  0   |  0   |  0   |  0   |  0   |  0   |\n|  a   |  0   |  1   |  0   |  0   |  0   |  0   |  0   |\n|  b   |  0   |  0   |  1   |  1   |  1   |  0   |  0   |\n|  b   |  0   |  0   |  0   |  1   |  2   |  0   |  0   |\n|  i   |  0   |  0   |  0   |  0   |  0   |  3   |  0   |\n|  t   |  0   |  0   |  0   |  0   |  0   |  0   |  3   |\n\n$dp[i][j]$ii-1$dp[i-1][ :j]$$s[i]==t[j]$0$sum(dp[-1])$\n\n2.\n\n|      |  b   |  a   |  b   |  g   |  b   |  a   |  g   |\n| :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |\n|  b   |  1   |  0   |  1   |  0   |  1   |  0   |  0   |\n|  a   |  0   |  1   |  0   |  0   |  0   |  3   |  0   |\n|  g   |  0   |  0   |  0   |  1   |  0   |  0   |  4   |\n\n copydpList 2List\n\n``` python\n# dp\n    def numDistinct(self, s, t):\n        dp = [0]* len(s)\n        for i,char in enumerate(s):\n            if char == t[0]:\n                dp[i] = 1\n\n        for char in t[1: ]:\n            count = 0\n            dp_next = [0] * len(s)\n            for i in range(len(s)):\n                if s[i] == char:\n                    dp_next[i] = count\n                count += dp[i]\n            dp = dp_next\n\n        return sum(dp)\n```\n\n36ms AC ACDP\n\n\n\n### Conclusion\n\nAC\n\n","slug":"LeetCode-115-Distinct-Subsequences","published":1,"_id":"ckiijvpg20000ce28c4jz8x92","comments":1,"layout":"post","photos":[],"link":"","content":"<blockquote>\n<p>Given two strings <code>s</code> and <code>t</code>, return <em>the number of distinct subsequences of <code>s</code> which equals <code>t</code></em>.</p>\n<p>A strings <strong>subsequence</strong> is a new string formed from the original string by deleting some (can be none) of the characters without disturbing the relative positions of the remaining characters. (i.e., <code>&quot;ACE&quot;</code> is a subsequence of <code>&quot;ABCDE&quot;</code> while <code>&quot;AEC&quot;</code> is not).</p>\n<p>Its guaranteed the answer fits on a 32-bit signed integer.</p>\n<p><strong>Example 1:</strong></p>\n<pre><code>Input: s = &quot;rabbbit&quot;, t = &quot;rabbit&quot;\nOutput: 3\nExplanation:\nAs shown below, there are 3 ways you can generate &quot;rabbit&quot; from S.\nrabbbit\nrabbbit\nrabbbit</code></pre>\n<p><strong>Example 2:</strong></p>\n<pre><code>Input: s = &quot;babgbag&quot;, t = &quot;bag&quot;\nOutput: 5\nExplanation:\nAs shown below, there are 5 ways you can generate &quot;bag&quot; from S.\nbabgbag\nbabgbag\nbabgbag\nbabgbag\nbabgbag</code></pre>\n<p><strong>Constraints:</strong></p>\n<ul>\n<li><code>0 &lt;= s.length, t.length &lt;= 1000</code></li>\n<li><code>s</code> and <code>t</code> consist of English letters.</li>\n</ul>\n</blockquote>\n<p>Hard100DFSDFSDFSDFSAC  ACdpACACHard</p>\n<h3 id=\"DFS\"><a href=\"#DFS\" class=\"headerlink\" title=\"DFS\"></a>DFS</h3><p>st3</p>\n<ol>\n<li>s ==  ts0</li>\n<li>t ==  t1</li>\n<li>s==t 1</li>\n<li></li>\n</ol>\n<p>tt[0]sst[0]stsum</p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">Solution</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\" spellcheck=\"true\"># DFS</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">numDistinct</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> s<span class=\"token punctuation\">:</span> str<span class=\"token punctuation\">,</span> t<span class=\"token punctuation\">:</span> str<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> int<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> len<span class=\"token punctuation\">(</span>t<span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span> <span class=\"token number\">1</span>\n        <span class=\"token keyword\">if</span> len<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span> <span class=\"token number\">0</span>\n        <span class=\"token keyword\">if</span> s <span class=\"token operator\">==</span> t<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span> <span class=\"token number\">1</span>\n\n        r <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n        t0 <span class=\"token operator\">=</span> t<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n        pos <span class=\"token operator\">=</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span>\n        news <span class=\"token operator\">=</span> s<span class=\"token punctuation\">[</span>pos<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">while</span> t0 <span class=\"token keyword\">in</span> news<span class=\"token punctuation\">:</span>\n            pos <span class=\"token operator\">=</span> news<span class=\"token punctuation\">.</span>index<span class=\"token punctuation\">(</span>t0<span class=\"token punctuation\">)</span>\n            news <span class=\"token operator\">=</span> news<span class=\"token punctuation\">[</span>pos<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">]</span>\n            r <span class=\"token operator\">+=</span> self<span class=\"token punctuation\">.</span>numDistinct<span class=\"token punctuation\">(</span>news<span class=\"token punctuation\">,</span> t<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> r</code></pre>\n<p>106/116 ACsDP</p>\n<h3 id=\"--Dynamic-Programming-DP\"><a href=\"#--Dynamic-Programming-DP\" class=\"headerlink\" title=\"  Dynamic Programming (DP)\"></a>  Dynamic Programming (DP)</h3><p>DPDPDPDP</p>\n<p>DP(LCS)DP$dp[i][j]$$s[i]!=t[j]$$dp[i-1][j]$$dp[i][j-1]$DPLCS</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\"></th>\n<th align=\"center\">r</th>\n<th align=\"center\">a</th>\n<th align=\"center\">b</th>\n<th align=\"center\">b</th>\n<th align=\"center\">b</th>\n<th align=\"center\">i</th>\n<th align=\"center\">t</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">r</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">a</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">b</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">b</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">2</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">i</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">3</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">t</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">3</td>\n</tr>\n</tbody></table>\n<p>$dp[i][j]$ii-1$dp[i-1][ :j]$$s[i]==t[j]$0$sum(dp[-1])$</p>\n<p>2.</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\"></th>\n<th align=\"center\">b</th>\n<th align=\"center\">a</th>\n<th align=\"center\">b</th>\n<th align=\"center\">g</th>\n<th align=\"center\">b</th>\n<th align=\"center\">a</th>\n<th align=\"center\">g</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">b</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">a</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">3</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">g</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">4</td>\n</tr>\n</tbody></table>\n<p> copydpList 2List</p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token comment\" spellcheck=\"true\"># dp</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">numDistinct</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> s<span class=\"token punctuation\">,</span> t<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        dp <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token operator\">*</span> len<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span>char <span class=\"token keyword\">in</span> enumerate<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">if</span> char <span class=\"token operator\">==</span> t<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n                dp<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">1</span>\n\n        <span class=\"token keyword\">for</span> char <span class=\"token keyword\">in</span> t<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n            count <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n            dp_next <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> len<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span>len<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                <span class=\"token keyword\">if</span> s<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> char<span class=\"token punctuation\">:</span>\n                    dp_next<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> count\n                count <span class=\"token operator\">+=</span> dp<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span>\n            dp <span class=\"token operator\">=</span> dp_next\n\n        <span class=\"token keyword\">return</span> sum<span class=\"token punctuation\">(</span>dp<span class=\"token punctuation\">)</span></code></pre>\n<p>36ms AC ACDP</p>\n<h3 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h3><p>AC</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>Given two strings <code>s</code> and <code>t</code>, return <em>the number of distinct subsequences of <code>s</code> which equals <code>t</code></em>.</p>\n<p>A strings <strong>subsequence</strong> is a new string formed from the original string by deleting some (can be none) of the characters without disturbing the relative positions of the remaining characters. (i.e., <code>&quot;ACE&quot;</code> is a subsequence of <code>&quot;ABCDE&quot;</code> while <code>&quot;AEC&quot;</code> is not).</p>\n<p>Its guaranteed the answer fits on a 32-bit signed integer.</p>\n<p><strong>Example 1:</strong></p>\n<pre><code>Input: s = &quot;rabbbit&quot;, t = &quot;rabbit&quot;\nOutput: 3\nExplanation:\nAs shown below, there are 3 ways you can generate &quot;rabbit&quot; from S.\nrabbbit\nrabbbit\nrabbbit</code></pre>\n<p><strong>Example 2:</strong></p>\n<pre><code>Input: s = &quot;babgbag&quot;, t = &quot;bag&quot;\nOutput: 5\nExplanation:\nAs shown below, there are 5 ways you can generate &quot;bag&quot; from S.\nbabgbag\nbabgbag\nbabgbag\nbabgbag\nbabgbag</code></pre>\n<p><strong>Constraints:</strong></p>\n<ul>\n<li><code>0 &lt;= s.length, t.length &lt;= 1000</code></li>\n<li><code>s</code> and <code>t</code> consist of English letters.</li>\n</ul>\n</blockquote>\n<p>Hard100DFSDFSDFSDFSAC  ACdpACACHard</p>\n<h3 id=\"DFS\"><a href=\"#DFS\" class=\"headerlink\" title=\"DFS\"></a>DFS</h3><p>st3</p>\n<ol>\n<li>s ==  ts0</li>\n<li>t ==  t1</li>\n<li>s==t 1</li>\n<li></li>\n</ol>\n<p>tt[0]sst[0]stsum</p>\n<pre><code class=\"python\">class Solution:\n    # DFS\n    def numDistinct(self, s: str, t: str) -&gt; int:\n        if len(t) == 0:\n            return 1\n        if len(s) == 0:\n            return 0\n        if s == t:\n            return 1\n\n        r = 0\n        t0 = t[0]\n        pos = -1\n        news = s[pos+1: ]\n        while t0 in news:\n            pos = news.index(t0)\n            news = news[pos+1: ]\n            r += self.numDistinct(news, t[1: ])\n        return r</code></pre>\n<p>106/116 ACsDP</p>\n<h3 id=\"--Dynamic-Programming-DP\"><a href=\"#--Dynamic-Programming-DP\" class=\"headerlink\" title=\"  Dynamic Programming (DP)\"></a>  Dynamic Programming (DP)</h3><p>DPDPDPDP</p>\n<p>DP(LCS)DP$dp[i][j]$$s[i]!=t[j]$$dp[i-1][j]$$dp[i][j-1]$DPLCS</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\"></th>\n<th align=\"center\">r</th>\n<th align=\"center\">a</th>\n<th align=\"center\">b</th>\n<th align=\"center\">b</th>\n<th align=\"center\">b</th>\n<th align=\"center\">i</th>\n<th align=\"center\">t</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">r</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">a</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">b</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">b</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">2</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">i</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">3</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">t</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">3</td>\n</tr>\n</tbody></table>\n<p>$dp[i][j]$ii-1$dp[i-1][ :j]$$s[i]==t[j]$0$sum(dp[-1])$</p>\n<p>2.</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\"></th>\n<th align=\"center\">b</th>\n<th align=\"center\">a</th>\n<th align=\"center\">b</th>\n<th align=\"center\">g</th>\n<th align=\"center\">b</th>\n<th align=\"center\">a</th>\n<th align=\"center\">g</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">b</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">a</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">3</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">g</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">4</td>\n</tr>\n</tbody></table>\n<p> copydpList 2List</p>\n<pre><code class=\"python\"># dp\n    def numDistinct(self, s, t):\n        dp = [0]* len(s)\n        for i,char in enumerate(s):\n            if char == t[0]:\n                dp[i] = 1\n\n        for char in t[1: ]:\n            count = 0\n            dp_next = [0] * len(s)\n            for i in range(len(s)):\n                if s[i] == char:\n                    dp_next[i] = count\n                count += dp[i]\n            dp = dp_next\n\n        return sum(dp)</code></pre>\n<p>36ms AC ACDP</p>\n<h3 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h3><p>AC</p>\n"},{"title":"LeetCode 126. Word Ladder II","toc":true,"mathjax":true,"top":false,"cover":true,"date":"2020-12-15T03:33:20.000Z","updated":"2020-12-17T03:07:06.076Z","_content":"\n> Given two words (*beginWord* and *endWord*), and a dictionary's word list, find all shortest transformation sequence(s) from *beginWord* to *endWord*, such that:\n>\n> 1. Only one letter can be changed at a time\n> 2. Each transformed word must exist in the word list. Note that *beginWord* is *not* a transformed word.\n>\n> **Note:**\n>\n> - Return an empty list if there is no such transformation sequence.\n> - All words have the same length.\n> - All words contain only lowercase alphabetic characters.\n> - You may assume no duplicates in the word list.\n> - You may assume *beginWord* and *endWord* are non-empty and are not the same.\n>\n> **Example 1:**\n>\n> ```\n> Input:\n> beginWord = \"hit\",\n> endWord = \"cog\",\n> wordList = [\"hot\",\"dot\",\"dog\",\"lot\",\"log\",\"cog\"]\n> \n> Output:\n> [\n>   [\"hit\",\"hot\",\"dot\",\"dog\",\"cog\"],\n>   [\"hit\",\"hot\",\"lot\",\"log\",\"cog\"]\n> ]\n> ```\n>\n> **Example 2:**\n>\n> ```\n> Input:\n> beginWord = \"hit\"\n> endWord = \"cog\"\n> wordList = [\"hot\",\"dot\",\"dog\",\"lot\",\"log\"]\n> \n> Output: []\n> \n> Explanation: The endWord \"cog\" is not in wordList, therefore no possible transformation\n> ```\n\nHardACTLEDiscussPythonAC\n\nFrog Jump HardACHardHardFrog Jump HardACHardHardFrog Jump , Jump Game Word Ladder  DFA   NFAACDebugPattern \n\n### \n\nwordListbeginWord  endWord BFS\n\nJump\n\n### \n\nDFA/NFAwordList\n\n```python\n#   s1 s2 \ndef isPair(self, s1, s2):\n\tc = 0\n\tfor i,j in zip(s1, s2):\n\t\tif c > 1:\n\t\t\treturn False\n\t\tif i != j:\n\t\t\tc += 1\n\treturn c == 1\n      \n# word wordList \ndef constructidx(self, word, wordList, des2src):\n\tfor w in wordList:\n\tif w != word and self.isPair(w, word):\n\t\tdes2src[w].add(word)\n\t\tdes2src[word].add(w)\n\treturn\n```\n\nisPairwordListlengthisPairTLEDiscusswordList_setword26$O(N)$$O(MN)$$O(M^2)$ MwordList NwordM\n\n```python\ndef constructidx_1(self, word, wordList_set, des2src):\n\tfor i in range(len(word)):\n\t\tfor char in string.ascii_lowercase:\n\t\t\ttmp = word[ :i] + char + word[i+1: ]\n\t\t\tif tmp in wordList_set:\n\t\t\t\tdes2src[word].add(tmp)\n\t\t\t\t# des2src[tmp].add(word)\n\treturn\n```\n\nTLEAC\n\nBFSBFS1\n\nBFSqueuequeueBFSq, q_nextqq_nextvisited q_nextq_nexta2bc2bcb-a a q_next, visited[a] = True,b-a  c-a visited[a]==True if elif \n\n```python\nq = deque()\nq.append(endWord)\nvisited = {endWord:True}\nbp = defaultdict(set)\n#res = defaultdict(list)\n#res[endWord] = [ [endWord] ]\nwhile len(q) > 0 :\n\tq_next = deque()\n\tfor e in q:\n\t\t# self.constructidx(e, wordList_set, des2src)\n\t\tself.constructidx_1(e, wordList_set, des2src)\n\t\tfor src in des2src[e]:\n\t\t\tif not visited.get(src, False)  :\n\t\t\t\tvisited[src] = True\n\t\t\t\tq_next.append(src)\n\n#\t\t\t\tr = [ [src] ]if len(res[e]) == 0 else [[src] + re for re in res[e]]\n#\t\t\t\tres[src].extend(r)\n\t\t\t\tbp[src].add(e)\n\t\t\telif src in q_next:\n#\t\t\t\tr = [ [src] ]if len(res[e]) == 0 else [[src] + re for re in res[e]]\n#\t\t\t\tres[src].extend(r)\n\t\t\t\tbp[src].add(e)\n\tif beginWord in q_next:\n\t\tbreak\n\twordList_set = wordList_set - set(bp.keys())\n\tq = q_next\n  \n# return res[beginWord]\nres = []\nself.backPath(beginWord, endWord, [], res, bp)\nreturn res\n\n# \ndef backPath(self, start,endWord, r ,res,bp):\n        if start == endWord:\n            res.append(r+[endWord])\n            return\n\n        for st in bp[start]:\n            self.backPath(st, endWord, r+[start], res, bp)\n\n        return\n```\n\nBFSTLEresword\n\n### BFS\n\nDiscuss PythonBFSif/elifres resword\n\n```python\nq = defaultdict(list)\nq[beginWord] = [[beginWord]]\nwordList_set = set(wordList)\nres = []\nwhile len(q) > 0:\n  q_next = defaultdict(list)\n  for word in q:\n    if word == endWord:\n      res.extend(k for k in q[word])\n    for i in len(word):\n      for char in string.ascii_lowercase:\n        tmp = word[ :i] + char + word[i+1: ]\n        # \n        # visited \n        #set\n        if tmp in wordList_set:\n\t\t\t\t\tq_next[tmp] = [r + [tmp] for r in q[word]]\n          \n\t# wordList_set \n  #BFSif/elif \n  #\n\twordList_set = wordList_set - set(q_next.keys())\n  q = q_next\nreturn res\n```\n\n### Conclusion\n\nMNBFSBFSPython\n\n","source":"_posts/LeetCode-126-Word-Ladder-II.md","raw":"---\ntitle: LeetCode 126. Word Ladder II\ntoc: true\nmathjax: true\ntop: false\ncover: true\ndate: 2020-12-15 11:33:20\nupdated:\ncategories: Algorithms\ntags:\n\t- Algorithms\n\t- LeetCode\n---\n\n> Given two words (*beginWord* and *endWord*), and a dictionary's word list, find all shortest transformation sequence(s) from *beginWord* to *endWord*, such that:\n>\n> 1. Only one letter can be changed at a time\n> 2. Each transformed word must exist in the word list. Note that *beginWord* is *not* a transformed word.\n>\n> **Note:**\n>\n> - Return an empty list if there is no such transformation sequence.\n> - All words have the same length.\n> - All words contain only lowercase alphabetic characters.\n> - You may assume no duplicates in the word list.\n> - You may assume *beginWord* and *endWord* are non-empty and are not the same.\n>\n> **Example 1:**\n>\n> ```\n> Input:\n> beginWord = \"hit\",\n> endWord = \"cog\",\n> wordList = [\"hot\",\"dot\",\"dog\",\"lot\",\"log\",\"cog\"]\n> \n> Output:\n> [\n>   [\"hit\",\"hot\",\"dot\",\"dog\",\"cog\"],\n>   [\"hit\",\"hot\",\"lot\",\"log\",\"cog\"]\n> ]\n> ```\n>\n> **Example 2:**\n>\n> ```\n> Input:\n> beginWord = \"hit\"\n> endWord = \"cog\"\n> wordList = [\"hot\",\"dot\",\"dog\",\"lot\",\"log\"]\n> \n> Output: []\n> \n> Explanation: The endWord \"cog\" is not in wordList, therefore no possible transformation\n> ```\n\nHardACTLEDiscussPythonAC\n\nFrog Jump HardACHardHardFrog Jump HardACHardHardFrog Jump , Jump Game Word Ladder  DFA   NFAACDebugPattern \n\n### \n\nwordListbeginWord  endWord BFS\n\nJump\n\n### \n\nDFA/NFAwordList\n\n```python\n#   s1 s2 \ndef isPair(self, s1, s2):\n\tc = 0\n\tfor i,j in zip(s1, s2):\n\t\tif c > 1:\n\t\t\treturn False\n\t\tif i != j:\n\t\t\tc += 1\n\treturn c == 1\n      \n# word wordList \ndef constructidx(self, word, wordList, des2src):\n\tfor w in wordList:\n\tif w != word and self.isPair(w, word):\n\t\tdes2src[w].add(word)\n\t\tdes2src[word].add(w)\n\treturn\n```\n\nisPairwordListlengthisPairTLEDiscusswordList_setword26$O(N)$$O(MN)$$O(M^2)$ MwordList NwordM\n\n```python\ndef constructidx_1(self, word, wordList_set, des2src):\n\tfor i in range(len(word)):\n\t\tfor char in string.ascii_lowercase:\n\t\t\ttmp = word[ :i] + char + word[i+1: ]\n\t\t\tif tmp in wordList_set:\n\t\t\t\tdes2src[word].add(tmp)\n\t\t\t\t# des2src[tmp].add(word)\n\treturn\n```\n\nTLEAC\n\nBFSBFS1\n\nBFSqueuequeueBFSq, q_nextqq_nextvisited q_nextq_nexta2bc2bcb-a a q_next, visited[a] = True,b-a  c-a visited[a]==True if elif \n\n```python\nq = deque()\nq.append(endWord)\nvisited = {endWord:True}\nbp = defaultdict(set)\n#res = defaultdict(list)\n#res[endWord] = [ [endWord] ]\nwhile len(q) > 0 :\n\tq_next = deque()\n\tfor e in q:\n\t\t# self.constructidx(e, wordList_set, des2src)\n\t\tself.constructidx_1(e, wordList_set, des2src)\n\t\tfor src in des2src[e]:\n\t\t\tif not visited.get(src, False)  :\n\t\t\t\tvisited[src] = True\n\t\t\t\tq_next.append(src)\n\n#\t\t\t\tr = [ [src] ]if len(res[e]) == 0 else [[src] + re for re in res[e]]\n#\t\t\t\tres[src].extend(r)\n\t\t\t\tbp[src].add(e)\n\t\t\telif src in q_next:\n#\t\t\t\tr = [ [src] ]if len(res[e]) == 0 else [[src] + re for re in res[e]]\n#\t\t\t\tres[src].extend(r)\n\t\t\t\tbp[src].add(e)\n\tif beginWord in q_next:\n\t\tbreak\n\twordList_set = wordList_set - set(bp.keys())\n\tq = q_next\n  \n# return res[beginWord]\nres = []\nself.backPath(beginWord, endWord, [], res, bp)\nreturn res\n\n# \ndef backPath(self, start,endWord, r ,res,bp):\n        if start == endWord:\n            res.append(r+[endWord])\n            return\n\n        for st in bp[start]:\n            self.backPath(st, endWord, r+[start], res, bp)\n\n        return\n```\n\nBFSTLEresword\n\n### BFS\n\nDiscuss PythonBFSif/elifres resword\n\n```python\nq = defaultdict(list)\nq[beginWord] = [[beginWord]]\nwordList_set = set(wordList)\nres = []\nwhile len(q) > 0:\n  q_next = defaultdict(list)\n  for word in q:\n    if word == endWord:\n      res.extend(k for k in q[word])\n    for i in len(word):\n      for char in string.ascii_lowercase:\n        tmp = word[ :i] + char + word[i+1: ]\n        # \n        # visited \n        #set\n        if tmp in wordList_set:\n\t\t\t\t\tq_next[tmp] = [r + [tmp] for r in q[word]]\n          \n\t# wordList_set \n  #BFSif/elif \n  #\n\twordList_set = wordList_set - set(q_next.keys())\n  q = q_next\nreturn res\n```\n\n### Conclusion\n\nMNBFSBFSPython\n\n","slug":"LeetCode-126-Word-Ladder-II","published":1,"_id":"ckipop2xt0000ej28e6qn6mng","comments":1,"layout":"post","photos":[],"link":"","content":"<blockquote>\n<p>Given two words (<em>beginWord</em> and <em>endWord</em>), and a dictionarys word list, find all shortest transformation sequence(s) from <em>beginWord</em> to <em>endWord</em>, such that:</p>\n<ol>\n<li>Only one letter can be changed at a time</li>\n<li>Each transformed word must exist in the word list. Note that <em>beginWord</em> is <em>not</em> a transformed word.</li>\n</ol>\n<p><strong>Note:</strong></p>\n<ul>\n<li>Return an empty list if there is no such transformation sequence.</li>\n<li>All words have the same length.</li>\n<li>All words contain only lowercase alphabetic characters.</li>\n<li>You may assume no duplicates in the word list.</li>\n<li>You may assume <em>beginWord</em> and <em>endWord</em> are non-empty and are not the same.</li>\n</ul>\n<p><strong>Example 1:</strong></p>\n<pre><code>Input:\nbeginWord = &quot;hit&quot;,\nendWord = &quot;cog&quot;,\nwordList = [&quot;hot&quot;,&quot;dot&quot;,&quot;dog&quot;,&quot;lot&quot;,&quot;log&quot;,&quot;cog&quot;]\n\nOutput:\n[\n  [&quot;hit&quot;,&quot;hot&quot;,&quot;dot&quot;,&quot;dog&quot;,&quot;cog&quot;],\n  [&quot;hit&quot;,&quot;hot&quot;,&quot;lot&quot;,&quot;log&quot;,&quot;cog&quot;]\n]</code></pre>\n<p><strong>Example 2:</strong></p>\n<pre><code>Input:\nbeginWord = &quot;hit&quot;\nendWord = &quot;cog&quot;\nwordList = [&quot;hot&quot;,&quot;dot&quot;,&quot;dog&quot;,&quot;lot&quot;,&quot;log&quot;]\n\nOutput: []\n\nExplanation: The endWord &quot;cog&quot; is not in wordList, therefore no possible transformation</code></pre>\n</blockquote>\n<p>HardACTLEDiscussPythonAC</p>\n<p>Frog Jump HardACHardHardFrog Jump HardACHardHardFrog Jump , Jump Game Word Ladder  DFA   NFAACDebugPattern </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>wordListbeginWord  endWord BFS</p>\n<p>Jump</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>DFA/NFAwordList</p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token comment\" spellcheck=\"true\">#   s1 s2 </span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">isPair</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> s1<span class=\"token punctuation\">,</span> s2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    c <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n    <span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span>j <span class=\"token keyword\">in</span> zip<span class=\"token punctuation\">(</span>s1<span class=\"token punctuation\">,</span> s2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> c <span class=\"token operator\">></span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span> <span class=\"token boolean\">False</span>\n        <span class=\"token keyword\">if</span> i <span class=\"token operator\">!=</span> j<span class=\"token punctuation\">:</span>\n            c <span class=\"token operator\">+=</span> <span class=\"token number\">1</span>\n    <span class=\"token keyword\">return</span> c <span class=\"token operator\">==</span> <span class=\"token number\">1</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># word wordList </span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">constructidx</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> word<span class=\"token punctuation\">,</span> wordList<span class=\"token punctuation\">,</span> des2src<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">for</span> w <span class=\"token keyword\">in</span> wordList<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">if</span> w <span class=\"token operator\">!=</span> word <span class=\"token operator\">and</span> self<span class=\"token punctuation\">.</span>isPair<span class=\"token punctuation\">(</span>w<span class=\"token punctuation\">,</span> word<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        des2src<span class=\"token punctuation\">[</span>w<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>word<span class=\"token punctuation\">)</span>\n        des2src<span class=\"token punctuation\">[</span>word<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>w<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span></code></pre>\n<p>isPairwordListlengthisPairTLEDiscusswordList_setword26$O(N)$$O(MN)$$O(M^2)$ MwordList NwordM</p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">constructidx_1</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> word<span class=\"token punctuation\">,</span> wordList_set<span class=\"token punctuation\">,</span> des2src<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span>len<span class=\"token punctuation\">(</span>word<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">for</span> char <span class=\"token keyword\">in</span> string<span class=\"token punctuation\">.</span>ascii_lowercase<span class=\"token punctuation\">:</span>\n            tmp <span class=\"token operator\">=</span> word<span class=\"token punctuation\">[</span> <span class=\"token punctuation\">:</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> char <span class=\"token operator\">+</span> word<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">]</span>\n            <span class=\"token keyword\">if</span> tmp <span class=\"token keyword\">in</span> wordList_set<span class=\"token punctuation\">:</span>\n                des2src<span class=\"token punctuation\">[</span>word<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>tmp<span class=\"token punctuation\">)</span>\n                <span class=\"token comment\" spellcheck=\"true\"># des2src[tmp].add(word)</span>\n    <span class=\"token keyword\">return</span></code></pre>\n<p>TLEAC</p>\n<p>BFSBFS1</p>\n<p>BFSqueuequeueBFSq, q_nextqq_nextvisited q_nextq_nexta2bc2bcb-a a q_next, visited[a] = True,b-a  c-a visited[a]==True if elif </p>\n<pre class=\" language-python\"><code class=\"language-python\">q <span class=\"token operator\">=</span> deque<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nq<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>endWord<span class=\"token punctuation\">)</span>\nvisited <span class=\"token operator\">=</span> <span class=\"token operator\">&amp;</span><span class=\"token comment\" spellcheck=\"true\">#123;endWord:True&amp;#125;</span>\nbp <span class=\"token operator\">=</span> defaultdict<span class=\"token punctuation\">(</span>set<span class=\"token punctuation\">)</span>\n<span class=\"token comment\" spellcheck=\"true\">#res = defaultdict(list)</span>\n<span class=\"token comment\" spellcheck=\"true\">#res[endWord] = [ [endWord] ]</span>\n<span class=\"token keyword\">while</span> len<span class=\"token punctuation\">(</span>q<span class=\"token punctuation\">)</span> <span class=\"token operator\">></span> <span class=\"token number\">0</span> <span class=\"token punctuation\">:</span>\n    q_next <span class=\"token operator\">=</span> deque<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span> e <span class=\"token keyword\">in</span> q<span class=\"token punctuation\">:</span>\n        <span class=\"token comment\" spellcheck=\"true\"># self.constructidx(e, wordList_set, des2src)</span>\n        self<span class=\"token punctuation\">.</span>constructidx_1<span class=\"token punctuation\">(</span>e<span class=\"token punctuation\">,</span> wordList_set<span class=\"token punctuation\">,</span> des2src<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">for</span> src <span class=\"token keyword\">in</span> des2src<span class=\"token punctuation\">[</span>e<span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">if</span> <span class=\"token operator\">not</span> visited<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span>src<span class=\"token punctuation\">,</span> <span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span>  <span class=\"token punctuation\">:</span>\n                visited<span class=\"token punctuation\">[</span>src<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span>\n                q_next<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>src<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\">#                r = [ [src] ]if len(res[e]) == 0 else [[src] + re for re in res[e]]</span>\n<span class=\"token comment\" spellcheck=\"true\">#                res[src].extend(r)</span>\n                bp<span class=\"token punctuation\">[</span>src<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>e<span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">elif</span> src <span class=\"token keyword\">in</span> q_next<span class=\"token punctuation\">:</span>\n<span class=\"token comment\" spellcheck=\"true\">#                r = [ [src] ]if len(res[e]) == 0 else [[src] + re for re in res[e]]</span>\n<span class=\"token comment\" spellcheck=\"true\">#                res[src].extend(r)</span>\n                bp<span class=\"token punctuation\">[</span>src<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>e<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">if</span> beginWord <span class=\"token keyword\">in</span> q_next<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">break</span>\n    wordList_set <span class=\"token operator\">=</span> wordList_set <span class=\"token operator\">-</span> set<span class=\"token punctuation\">(</span>bp<span class=\"token punctuation\">.</span>keys<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    q <span class=\"token operator\">=</span> q_next\n\n<span class=\"token comment\" spellcheck=\"true\"># return res[beginWord]</span>\nres <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\nself<span class=\"token punctuation\">.</span>backPath<span class=\"token punctuation\">(</span>beginWord<span class=\"token punctuation\">,</span> endWord<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> res<span class=\"token punctuation\">,</span> bp<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">return</span> res\n\n<span class=\"token comment\" spellcheck=\"true\"># </span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">backPath</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> start<span class=\"token punctuation\">,</span>endWord<span class=\"token punctuation\">,</span> r <span class=\"token punctuation\">,</span>res<span class=\"token punctuation\">,</span>bp<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> start <span class=\"token operator\">==</span> endWord<span class=\"token punctuation\">:</span>\n            res<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>r<span class=\"token operator\">+</span><span class=\"token punctuation\">[</span>endWord<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">return</span>\n\n        <span class=\"token keyword\">for</span> st <span class=\"token keyword\">in</span> bp<span class=\"token punctuation\">[</span>start<span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n            self<span class=\"token punctuation\">.</span>backPath<span class=\"token punctuation\">(</span>st<span class=\"token punctuation\">,</span> endWord<span class=\"token punctuation\">,</span> r<span class=\"token operator\">+</span><span class=\"token punctuation\">[</span>start<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> res<span class=\"token punctuation\">,</span> bp<span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">return</span></code></pre>\n<p>BFSTLEresword</p>\n<h3 id=\"BFS\"><a href=\"#BFS\" class=\"headerlink\" title=\"BFS\"></a>BFS</h3><p>Discuss PythonBFSif/elifres resword</p>\n<pre class=\" language-python\"><code class=\"language-python\">q <span class=\"token operator\">=</span> defaultdict<span class=\"token punctuation\">(</span>list<span class=\"token punctuation\">)</span>\nq<span class=\"token punctuation\">[</span>beginWord<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span>beginWord<span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span>\nwordList_set <span class=\"token operator\">=</span> set<span class=\"token punctuation\">(</span>wordList<span class=\"token punctuation\">)</span>\nres <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n<span class=\"token keyword\">while</span> len<span class=\"token punctuation\">(</span>q<span class=\"token punctuation\">)</span> <span class=\"token operator\">></span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n  q_next <span class=\"token operator\">=</span> defaultdict<span class=\"token punctuation\">(</span>list<span class=\"token punctuation\">)</span>\n  <span class=\"token keyword\">for</span> word <span class=\"token keyword\">in</span> q<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">if</span> word <span class=\"token operator\">==</span> endWord<span class=\"token punctuation\">:</span>\n      res<span class=\"token punctuation\">.</span>extend<span class=\"token punctuation\">(</span>k <span class=\"token keyword\">for</span> k <span class=\"token keyword\">in</span> q<span class=\"token punctuation\">[</span>word<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> len<span class=\"token punctuation\">(</span>word<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n      <span class=\"token keyword\">for</span> char <span class=\"token keyword\">in</span> string<span class=\"token punctuation\">.</span>ascii_lowercase<span class=\"token punctuation\">:</span>\n        tmp <span class=\"token operator\">=</span> word<span class=\"token punctuation\">[</span> <span class=\"token punctuation\">:</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> char <span class=\"token operator\">+</span> word<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">]</span>\n        <span class=\"token comment\" spellcheck=\"true\"># </span>\n        <span class=\"token comment\" spellcheck=\"true\"># visited </span>\n        <span class=\"token comment\" spellcheck=\"true\">#set</span>\n        <span class=\"token keyword\">if</span> tmp <span class=\"token keyword\">in</span> wordList_set<span class=\"token punctuation\">:</span>\n                    q_next<span class=\"token punctuation\">[</span>tmp<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>r <span class=\"token operator\">+</span> <span class=\"token punctuation\">[</span>tmp<span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> r <span class=\"token keyword\">in</span> q<span class=\"token punctuation\">[</span>word<span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span>\n\n    <span class=\"token comment\" spellcheck=\"true\"># wordList_set </span>\n  <span class=\"token comment\" spellcheck=\"true\">#BFSif/elif </span>\n  <span class=\"token comment\" spellcheck=\"true\">#</span>\n    wordList_set <span class=\"token operator\">=</span> wordList_set <span class=\"token operator\">-</span> set<span class=\"token punctuation\">(</span>q_next<span class=\"token punctuation\">.</span>keys<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n  q <span class=\"token operator\">=</span> q_next\n<span class=\"token keyword\">return</span> res</code></pre>\n<h3 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h3><p>MNBFSBFSPython</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>Given two words (<em>beginWord</em> and <em>endWord</em>), and a dictionarys word list, find all shortest transformation sequence(s) from <em>beginWord</em> to <em>endWord</em>, such that:</p>\n<ol>\n<li>Only one letter can be changed at a time</li>\n<li>Each transformed word must exist in the word list. Note that <em>beginWord</em> is <em>not</em> a transformed word.</li>\n</ol>\n<p><strong>Note:</strong></p>\n<ul>\n<li>Return an empty list if there is no such transformation sequence.</li>\n<li>All words have the same length.</li>\n<li>All words contain only lowercase alphabetic characters.</li>\n<li>You may assume no duplicates in the word list.</li>\n<li>You may assume <em>beginWord</em> and <em>endWord</em> are non-empty and are not the same.</li>\n</ul>\n<p><strong>Example 1:</strong></p>\n<pre><code>Input:\nbeginWord = &quot;hit&quot;,\nendWord = &quot;cog&quot;,\nwordList = [&quot;hot&quot;,&quot;dot&quot;,&quot;dog&quot;,&quot;lot&quot;,&quot;log&quot;,&quot;cog&quot;]\n\nOutput:\n[\n  [&quot;hit&quot;,&quot;hot&quot;,&quot;dot&quot;,&quot;dog&quot;,&quot;cog&quot;],\n  [&quot;hit&quot;,&quot;hot&quot;,&quot;lot&quot;,&quot;log&quot;,&quot;cog&quot;]\n]</code></pre>\n<p><strong>Example 2:</strong></p>\n<pre><code>Input:\nbeginWord = &quot;hit&quot;\nendWord = &quot;cog&quot;\nwordList = [&quot;hot&quot;,&quot;dot&quot;,&quot;dog&quot;,&quot;lot&quot;,&quot;log&quot;]\n\nOutput: []\n\nExplanation: The endWord &quot;cog&quot; is not in wordList, therefore no possible transformation</code></pre>\n</blockquote>\n<p>HardACTLEDiscussPythonAC</p>\n<p>Frog Jump HardACHardHardFrog Jump HardACHardHardFrog Jump , Jump Game Word Ladder  DFA   NFAACDebugPattern </p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>wordListbeginWord  endWord BFS</p>\n<p>Jump</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>DFA/NFAwordList</p>\n<pre><code class=\"python\">#   s1 s2 \ndef isPair(self, s1, s2):\n    c = 0\n    for i,j in zip(s1, s2):\n        if c &gt; 1:\n            return False\n        if i != j:\n            c += 1\n    return c == 1\n\n# word wordList \ndef constructidx(self, word, wordList, des2src):\n    for w in wordList:\n    if w != word and self.isPair(w, word):\n        des2src[w].add(word)\n        des2src[word].add(w)\n    return</code></pre>\n<p>isPairwordListlengthisPairTLEDiscusswordList_setword26$O(N)$$O(MN)$$O(M^2)$ MwordList NwordM</p>\n<pre><code class=\"python\">def constructidx_1(self, word, wordList_set, des2src):\n    for i in range(len(word)):\n        for char in string.ascii_lowercase:\n            tmp = word[ :i] + char + word[i+1: ]\n            if tmp in wordList_set:\n                des2src[word].add(tmp)\n                # des2src[tmp].add(word)\n    return</code></pre>\n<p>TLEAC</p>\n<p>BFSBFS1</p>\n<p>BFSqueuequeueBFSq, q_nextqq_nextvisited q_nextq_nexta2bc2bcb-a a q_next, visited[a] = True,b-a  c-a visited[a]==True if elif </p>\n<pre><code class=\"python\">q = deque()\nq.append(endWord)\nvisited = &#123;endWord:True&#125;\nbp = defaultdict(set)\n#res = defaultdict(list)\n#res[endWord] = [ [endWord] ]\nwhile len(q) &gt; 0 :\n    q_next = deque()\n    for e in q:\n        # self.constructidx(e, wordList_set, des2src)\n        self.constructidx_1(e, wordList_set, des2src)\n        for src in des2src[e]:\n            if not visited.get(src, False)  :\n                visited[src] = True\n                q_next.append(src)\n\n#                r = [ [src] ]if len(res[e]) == 0 else [[src] + re for re in res[e]]\n#                res[src].extend(r)\n                bp[src].add(e)\n            elif src in q_next:\n#                r = [ [src] ]if len(res[e]) == 0 else [[src] + re for re in res[e]]\n#                res[src].extend(r)\n                bp[src].add(e)\n    if beginWord in q_next:\n        break\n    wordList_set = wordList_set - set(bp.keys())\n    q = q_next\n\n# return res[beginWord]\nres = []\nself.backPath(beginWord, endWord, [], res, bp)\nreturn res\n\n# \ndef backPath(self, start,endWord, r ,res,bp):\n        if start == endWord:\n            res.append(r+[endWord])\n            return\n\n        for st in bp[start]:\n            self.backPath(st, endWord, r+[start], res, bp)\n\n        return</code></pre>\n<p>BFSTLEresword</p>\n<h3 id=\"BFS\"><a href=\"#BFS\" class=\"headerlink\" title=\"BFS\"></a>BFS</h3><p>Discuss PythonBFSif/elifres resword</p>\n<pre><code class=\"python\">q = defaultdict(list)\nq[beginWord] = [[beginWord]]\nwordList_set = set(wordList)\nres = []\nwhile len(q) &gt; 0:\n  q_next = defaultdict(list)\n  for word in q:\n    if word == endWord:\n      res.extend(k for k in q[word])\n    for i in len(word):\n      for char in string.ascii_lowercase:\n        tmp = word[ :i] + char + word[i+1: ]\n        # \n        # visited \n        #set\n        if tmp in wordList_set:\n                    q_next[tmp] = [r + [tmp] for r in q[word]]\n\n    # wordList_set \n  #BFSif/elif \n  #\n    wordList_set = wordList_set - set(q_next.keys())\n  q = q_next\nreturn res</code></pre>\n<h3 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h3><p>MNBFSBFSPython</p>\n"},{"title":"132. Palindrome Partitioning II","toc":true,"mathjax":true,"top":false,"cover":true,"date":"2020-12-17T03:06:04.000Z","updated":"2020-12-17T09:33:00.529Z","_content":"\n> Given a string `s`, partition `s` such that every substring of the partition is a palindrome.\n>\n> Return *the minimum cuts needed* for a palindrome partitioning of `s`.\n>\n>  \n>\n> **Example 1:**\n>\n> ```\n> Input: s = \"aab\"\n> Output: 1\n> Explanation: The palindrome partitioning [\"aa\",\"b\"] could be produced using 1 cut.\n> ```\n>\n> **Example 2:**\n>\n> ```\n> Input: s = \"a\"\n> Output: 0\n> ```\n>\n> **Example 3:**\n>\n> ```\n> Input: s = \"ab\"\n> Output: 1\n> ```\n>\n>  \n>\n> **Constraints:**\n>\n> - `1 <= s.length <= 2000`\n> - `s` consists of lower-case English letters only.\n\nDFANFAOJACsubstringAC\n\n### \n\nsubstring 132131 Palindrome Partitioning I  mediums  substring 131OJ132AC131DPDP ACACDP\n\n```python\n# 131 Palindrome Partitioning I\nclass Solution:\n    def partition(self, s: str) -> List[List[str]]:\n        res = []\n        memo = {}\n        self.splitPalindrome(s, [], res, memo)\n        return res\n        \n    def isPalindrome(self, s, memo):\n        if len(s) == 0:\n            return False\n        if len(s) == 1:\n            return True\n\n        if s in memo:\n            return memo[s]\n\n        news = '_'.join(s)\n        mid = len(news) // 2\n        for i in range(1,mid+1):\n            pre = mid - i\n            post = mid + i \n            if news[pre] != news[post]:\n                memo[s] = False\n                return False\n        memo[s] = True\n        return True\n\n    def splitPalindrome(self, s, rs, res,memo):\n        if len(s) == 0:\n            res.append(rs)\n            return\n        if len(s) == 1:\n            res.append(rs+[s])\n            return\n\n        for i in range(1,len(s)+1):\n            if self.isPalindrome(s[ :i], memo):\n                self.splitPalindrome(s[i: ], rs + [s[ :i]], res, memo)\n        return\n\n```\n\nDFSsrssresssubstringmemoAC.\n\nHard\n\n  nnstring$s[i][j]$ substring$s[i][j]$$O(N^2)$substring $O(N^2)$Tricksubstring\n\n####  Longest Palindrome Substring\n\n[](https://segmentfault.com/a/1190000003914228)1.2.$O(N^2)$2Manacher$s[i][j]$dp$dp[i][j] = dp[i+1][j-1] ,if \\quad s[i]==s[j] $ $dp[i][j]==dp[j][i]$\n\n```python\n# dp substring  \n    def longestPalindrome(self, s):\n        length = len(s)\n        dp = [[False]*length for _ in range(length)]\n        for i in range(length):\n            j = i\n            while j >= 0:\n                if s[j] == s[i] and (i-j<2 or dp[j+1][i-1]):\n                    dp[j][i] = True\n                j -= 1\n        return dp\n```\n\n$O(N^2)$\n\n$O(N^2)$AC\n\n```python\n#  O(N**2) \n    def longestPalindrome(self, s):\n        length = len(s)\n        d = [[False]*length for _ in range(length)]\n\n        news = '_'.join(s)\n        for i in range(len(news)):\n            d[i//2][i//2] = True\n            end = min(i, len(news)-i)\n            flag = True\n            for j in range(1,end+1):\n                pre = i-j\n                post = i+j\n              \n                if news[pre] != '_' and  flag:\n                    if  news[pre] == news[post]:\n                        d[pre//2][post//2] = True\n                    else:\n                        flag = False\n        return d\n```\n\n\n\n#### DFS\n\nDFS131\n\n```python\n# s2-1  dp AC 456ms\n    def calLength(self, start, s, dp, memo):\n        if start == len(s):\n            return 0\n        if start == len(s)-1:\n            memo[start][len(s)-1] = 1\n            return 1\n        if dp[start][len(s)-1]:\n            memo[start][len(s)-1] = 1\n            return 1\n        if memo[start][len(s)-1] != 0:\n            return memo[start][len(s)-1]\n\n        res = float('inf')\n        for i in range(start, len(s)):\n            if dp[start][i] :\n                res = min(res, self.calLength(i+1, s, dp , memo))\n        memo[start][len(s)-1] = res + 1\n        return memo[start][len(s)-1]\n```\n\nAC\n\nDFSDPDP\n\n$dp[i][j] = min(dp[i][k] + dp[k+1][j] + 1) ,if \\quad s[i:j+1]$\n\n dp i-j gapgapgapdp\n\n```python\ndef calLength(self, s, dp ):\n        length = len(s)\n        dp_2 = [[0]*length for _ in range(length)]\n        if dp[0][length-1]:\n            dp_2[0][-1] = 0\n            return dp_2\n        # s1 gap dp\n        for gap in range(1, length):\n            for i in range(length-gap):\n                j = i+gap\n                if not dp[i][j]:\n                    r = float('inf')\n                    for k in range(i, j):\n                        r = min(r, dp_2[i][k] + dp_2[k+1][j] + 1)\n                    \n                    dp_2[i][j] = r\n\t\t\t\treturn dp_2\n```\n\n$O(N^3)$TLE$O(N^2)$\n\n\n\n### Manacher \n\nRL[i]iRLiposRL[pos]posij\n\n![1](1.png)\n\n![2](2.png)\n\nRL[j]RL[j]RL[i]RL[i]0RL[j]pos2R[i],posRL[i]\n\n![3](3.png)\n\nimaxRight 0![4](4.png)\n\n```python\ndef manacher(s):\n  s = '_'.join(s)\n  rl = [0]*len(s)\n  maxRight = 0\n  pos = 0\n  maxLen = 0\n  \n  for i in range(len(s)):\n    if i < maxRight:\n      rl[i] = min(rl[2*pos-i], maxRight-i)\n    else:\n      rl[i] = 1\n    # rl[i]\n    while i-rl[i]>=0 and i+rl[i]<len(s) and s[i-rl[i]]==s[i+rl[i]]:\n      rl[i] += 1\n      \n    if rl[i]+i-1>maxRight:\n      maxRight = rl[i] + i -1\n      pos = i\n      \n    maxLen = max(maxLen, rl[i])\n  return maxLen-1\n```\n\n$O(N)$$O(N^2)$RL[j]0RL[i]RL[j]RL[j]RL[i]$O(N)$$O(N^2)$\n\n### Conclusion\n\nmanacherNFA$O(N^2)$\n\n\n\nReference:\n\n[-Manacher](https://segmentfault.com/a/1190000003914228)\n\n","source":"_posts/132-Palindrome-Partitioning-II.md","raw":"---\ntitle: 132. Palindrome Partitioning II\ntoc: true\nmathjax: true\ntop: false\ncover: true\ndate: 2020-12-17 11:06:04\nupdated:\ncategories: Algorithms\ntags:\n\t- Algorithms\n\t- LeetCode\n---\n\n> Given a string `s`, partition `s` such that every substring of the partition is a palindrome.\n>\n> Return *the minimum cuts needed* for a palindrome partitioning of `s`.\n>\n>  \n>\n> **Example 1:**\n>\n> ```\n> Input: s = \"aab\"\n> Output: 1\n> Explanation: The palindrome partitioning [\"aa\",\"b\"] could be produced using 1 cut.\n> ```\n>\n> **Example 2:**\n>\n> ```\n> Input: s = \"a\"\n> Output: 0\n> ```\n>\n> **Example 3:**\n>\n> ```\n> Input: s = \"ab\"\n> Output: 1\n> ```\n>\n>  \n>\n> **Constraints:**\n>\n> - `1 <= s.length <= 2000`\n> - `s` consists of lower-case English letters only.\n\nDFANFAOJACsubstringAC\n\n### \n\nsubstring 132131 Palindrome Partitioning I  mediums  substring 131OJ132AC131DPDP ACACDP\n\n```python\n# 131 Palindrome Partitioning I\nclass Solution:\n    def partition(self, s: str) -> List[List[str]]:\n        res = []\n        memo = {}\n        self.splitPalindrome(s, [], res, memo)\n        return res\n        \n    def isPalindrome(self, s, memo):\n        if len(s) == 0:\n            return False\n        if len(s) == 1:\n            return True\n\n        if s in memo:\n            return memo[s]\n\n        news = '_'.join(s)\n        mid = len(news) // 2\n        for i in range(1,mid+1):\n            pre = mid - i\n            post = mid + i \n            if news[pre] != news[post]:\n                memo[s] = False\n                return False\n        memo[s] = True\n        return True\n\n    def splitPalindrome(self, s, rs, res,memo):\n        if len(s) == 0:\n            res.append(rs)\n            return\n        if len(s) == 1:\n            res.append(rs+[s])\n            return\n\n        for i in range(1,len(s)+1):\n            if self.isPalindrome(s[ :i], memo):\n                self.splitPalindrome(s[i: ], rs + [s[ :i]], res, memo)\n        return\n\n```\n\nDFSsrssresssubstringmemoAC.\n\nHard\n\n  nnstring$s[i][j]$ substring$s[i][j]$$O(N^2)$substring $O(N^2)$Tricksubstring\n\n####  Longest Palindrome Substring\n\n[](https://segmentfault.com/a/1190000003914228)1.2.$O(N^2)$2Manacher$s[i][j]$dp$dp[i][j] = dp[i+1][j-1] ,if \\quad s[i]==s[j] $ $dp[i][j]==dp[j][i]$\n\n```python\n# dp substring  \n    def longestPalindrome(self, s):\n        length = len(s)\n        dp = [[False]*length for _ in range(length)]\n        for i in range(length):\n            j = i\n            while j >= 0:\n                if s[j] == s[i] and (i-j<2 or dp[j+1][i-1]):\n                    dp[j][i] = True\n                j -= 1\n        return dp\n```\n\n$O(N^2)$\n\n$O(N^2)$AC\n\n```python\n#  O(N**2) \n    def longestPalindrome(self, s):\n        length = len(s)\n        d = [[False]*length for _ in range(length)]\n\n        news = '_'.join(s)\n        for i in range(len(news)):\n            d[i//2][i//2] = True\n            end = min(i, len(news)-i)\n            flag = True\n            for j in range(1,end+1):\n                pre = i-j\n                post = i+j\n              \n                if news[pre] != '_' and  flag:\n                    if  news[pre] == news[post]:\n                        d[pre//2][post//2] = True\n                    else:\n                        flag = False\n        return d\n```\n\n\n\n#### DFS\n\nDFS131\n\n```python\n# s2-1  dp AC 456ms\n    def calLength(self, start, s, dp, memo):\n        if start == len(s):\n            return 0\n        if start == len(s)-1:\n            memo[start][len(s)-1] = 1\n            return 1\n        if dp[start][len(s)-1]:\n            memo[start][len(s)-1] = 1\n            return 1\n        if memo[start][len(s)-1] != 0:\n            return memo[start][len(s)-1]\n\n        res = float('inf')\n        for i in range(start, len(s)):\n            if dp[start][i] :\n                res = min(res, self.calLength(i+1, s, dp , memo))\n        memo[start][len(s)-1] = res + 1\n        return memo[start][len(s)-1]\n```\n\nAC\n\nDFSDPDP\n\n$dp[i][j] = min(dp[i][k] + dp[k+1][j] + 1) ,if \\quad s[i:j+1]$\n\n dp i-j gapgapgapdp\n\n```python\ndef calLength(self, s, dp ):\n        length = len(s)\n        dp_2 = [[0]*length for _ in range(length)]\n        if dp[0][length-1]:\n            dp_2[0][-1] = 0\n            return dp_2\n        # s1 gap dp\n        for gap in range(1, length):\n            for i in range(length-gap):\n                j = i+gap\n                if not dp[i][j]:\n                    r = float('inf')\n                    for k in range(i, j):\n                        r = min(r, dp_2[i][k] + dp_2[k+1][j] + 1)\n                    \n                    dp_2[i][j] = r\n\t\t\t\treturn dp_2\n```\n\n$O(N^3)$TLE$O(N^2)$\n\n\n\n### Manacher \n\nRL[i]iRLiposRL[pos]posij\n\n![1](1.png)\n\n![2](2.png)\n\nRL[j]RL[j]RL[i]RL[i]0RL[j]pos2R[i],posRL[i]\n\n![3](3.png)\n\nimaxRight 0![4](4.png)\n\n```python\ndef manacher(s):\n  s = '_'.join(s)\n  rl = [0]*len(s)\n  maxRight = 0\n  pos = 0\n  maxLen = 0\n  \n  for i in range(len(s)):\n    if i < maxRight:\n      rl[i] = min(rl[2*pos-i], maxRight-i)\n    else:\n      rl[i] = 1\n    # rl[i]\n    while i-rl[i]>=0 and i+rl[i]<len(s) and s[i-rl[i]]==s[i+rl[i]]:\n      rl[i] += 1\n      \n    if rl[i]+i-1>maxRight:\n      maxRight = rl[i] + i -1\n      pos = i\n      \n    maxLen = max(maxLen, rl[i])\n  return maxLen-1\n```\n\n$O(N)$$O(N^2)$RL[j]0RL[i]RL[j]RL[j]RL[i]$O(N)$$O(N^2)$\n\n### Conclusion\n\nmanacherNFA$O(N^2)$\n\n\n\nReference:\n\n[-Manacher](https://segmentfault.com/a/1190000003914228)\n\n","slug":"132-Palindrome-Partitioning-II","published":1,"_id":"ckisn8crf0000vy28agpvc03h","comments":1,"layout":"post","photos":[],"link":"","content":"<blockquote>\n<p>Given a string <code>s</code>, partition <code>s</code> such that every substring of the partition is a palindrome.</p>\n<p>Return <em>the minimum cuts needed</em> for a palindrome partitioning of <code>s</code>.</p>\n<p><strong>Example 1:</strong></p>\n<pre><code>Input: s = &quot;aab&quot;\nOutput: 1\nExplanation: The palindrome partitioning [&quot;aa&quot;,&quot;b&quot;] could be produced using 1 cut.</code></pre>\n<p><strong>Example 2:</strong></p>\n<pre><code>Input: s = &quot;a&quot;\nOutput: 0</code></pre>\n<p><strong>Example 3:</strong></p>\n<pre><code>Input: s = &quot;ab&quot;\nOutput: 1</code></pre>\n<p><strong>Constraints:</strong></p>\n<ul>\n<li><code>1 &lt;= s.length &lt;= 2000</code></li>\n<li><code>s</code> consists of lower-case English letters only.</li>\n</ul>\n</blockquote>\n<p>DFANFAOJACsubstringAC</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>substring 132131 Palindrome Partitioning I  mediums  substring 131OJ132AC131DPDP ACACDP</p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token comment\" spellcheck=\"true\"># 131 Palindrome Partitioning I</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Solution</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">partition</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> s<span class=\"token punctuation\">:</span> str<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> List<span class=\"token punctuation\">[</span>List<span class=\"token punctuation\">[</span>str<span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n        res <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        memo <span class=\"token operator\">=</span> <span class=\"token operator\">&amp;</span><span class=\"token comment\" spellcheck=\"true\">#123;&amp;#125;</span>\n        self<span class=\"token punctuation\">.</span>splitPalindrome<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> res<span class=\"token punctuation\">,</span> memo<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> res\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">isPalindrome</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> s<span class=\"token punctuation\">,</span> memo<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> len<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span> <span class=\"token boolean\">False</span>\n        <span class=\"token keyword\">if</span> len<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span> <span class=\"token boolean\">True</span>\n\n        <span class=\"token keyword\">if</span> s <span class=\"token keyword\">in</span> memo<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span> memo<span class=\"token punctuation\">[</span>s<span class=\"token punctuation\">]</span>\n\n        news <span class=\"token operator\">=</span> <span class=\"token string\">'_'</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span>\n        mid <span class=\"token operator\">=</span> len<span class=\"token punctuation\">(</span>news<span class=\"token punctuation\">)</span> <span class=\"token operator\">//</span> <span class=\"token number\">2</span>\n        <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span>mid<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            pre <span class=\"token operator\">=</span> mid <span class=\"token operator\">-</span> i\n            post <span class=\"token operator\">=</span> mid <span class=\"token operator\">+</span> i \n            <span class=\"token keyword\">if</span> news<span class=\"token punctuation\">[</span>pre<span class=\"token punctuation\">]</span> <span class=\"token operator\">!=</span> news<span class=\"token punctuation\">[</span>post<span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n                memo<span class=\"token punctuation\">[</span>s<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span>\n                <span class=\"token keyword\">return</span> <span class=\"token boolean\">False</span>\n        memo<span class=\"token punctuation\">[</span>s<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span>\n        <span class=\"token keyword\">return</span> <span class=\"token boolean\">True</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">splitPalindrome</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> s<span class=\"token punctuation\">,</span> rs<span class=\"token punctuation\">,</span> res<span class=\"token punctuation\">,</span>memo<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> len<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n            res<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>rs<span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">return</span>\n        <span class=\"token keyword\">if</span> len<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span> <span class=\"token operator\">==</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span>\n            res<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>rs<span class=\"token operator\">+</span><span class=\"token punctuation\">[</span>s<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">return</span>\n\n        <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span>len<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span><span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">if</span> self<span class=\"token punctuation\">.</span>isPalindrome<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">[</span> <span class=\"token punctuation\">:</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> memo<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                self<span class=\"token punctuation\">.</span>splitPalindrome<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">:</span> <span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> rs <span class=\"token operator\">+</span> <span class=\"token punctuation\">[</span>s<span class=\"token punctuation\">[</span> <span class=\"token punctuation\">:</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> res<span class=\"token punctuation\">,</span> memo<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span>\n</code></pre>\n<p>DFSsrssresssubstringmemoAC.</p>\n<p>Hard</p>\n<p>  nnstring$s[i][j]$ substring$s[i][j]$$O(N^2)$substring $O(N^2)$Tricksubstring</p>\n<h4 id=\"-Longest-Palindrome-Substring\"><a href=\"#-Longest-Palindrome-Substring\" class=\"headerlink\" title=\" Longest Palindrome Substring\"></a> Longest Palindrome Substring</h4><p><a href=\"https://segmentfault.com/a/1190000003914228\"></a>1.2.$O(N^2)$2Manacher$s[i][j]$dp$dp[i][j] = dp[i+1][j-1] ,if \\quad s[i]==s[j] $ $dp[i][j]==dp[j][i]$</p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token comment\" spellcheck=\"true\"># dp substring  </span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">longestPalindrome</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> s<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        length <span class=\"token operator\">=</span> len<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span>\n        dp <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">]</span><span class=\"token operator\">*</span>length <span class=\"token keyword\">for</span> _ <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span>length<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span>length<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            j <span class=\"token operator\">=</span> i\n            <span class=\"token keyword\">while</span> j <span class=\"token operator\">>=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n                <span class=\"token keyword\">if</span> s<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> s<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">and</span> <span class=\"token punctuation\">(</span>i<span class=\"token operator\">-</span>j<span class=\"token operator\">&lt;</span><span class=\"token number\">2</span> <span class=\"token operator\">or</span> dp<span class=\"token punctuation\">[</span>j<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>i<span class=\"token number\">-1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                    dp<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span>\n                j <span class=\"token operator\">-=</span> <span class=\"token number\">1</span>\n        <span class=\"token keyword\">return</span> dp</code></pre>\n<p>$O(N^2)$</p>\n<p>$O(N^2)$AC</p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token comment\" spellcheck=\"true\">#  O(N**2) </span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">longestPalindrome</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> s<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        length <span class=\"token operator\">=</span> len<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span>\n        d <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">]</span><span class=\"token operator\">*</span>length <span class=\"token keyword\">for</span> _ <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span>length<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n\n        news <span class=\"token operator\">=</span> <span class=\"token string\">'_'</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span>len<span class=\"token punctuation\">(</span>news<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            d<span class=\"token punctuation\">[</span>i<span class=\"token operator\">//</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>i<span class=\"token operator\">//</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span>\n            end <span class=\"token operator\">=</span> min<span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">,</span> len<span class=\"token punctuation\">(</span>news<span class=\"token punctuation\">)</span><span class=\"token operator\">-</span>i<span class=\"token punctuation\">)</span>\n            flag <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span>\n            <span class=\"token keyword\">for</span> j <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span>end<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                pre <span class=\"token operator\">=</span> i<span class=\"token operator\">-</span>j\n                post <span class=\"token operator\">=</span> i<span class=\"token operator\">+</span>j\n\n                <span class=\"token keyword\">if</span> news<span class=\"token punctuation\">[</span>pre<span class=\"token punctuation\">]</span> <span class=\"token operator\">!=</span> <span class=\"token string\">'_'</span> <span class=\"token operator\">and</span>  flag<span class=\"token punctuation\">:</span>\n                    <span class=\"token keyword\">if</span>  news<span class=\"token punctuation\">[</span>pre<span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> news<span class=\"token punctuation\">[</span>post<span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n                        d<span class=\"token punctuation\">[</span>pre<span class=\"token operator\">//</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>post<span class=\"token operator\">//</span><span class=\"token number\">2</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span>\n                    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n                        flag <span class=\"token operator\">=</span> <span class=\"token boolean\">False</span>\n        <span class=\"token keyword\">return</span> d</code></pre>\n<h4 id=\"DFS\"><a href=\"#DFS\" class=\"headerlink\" title=\"DFS\"></a>DFS</h4><p>DFS131</p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token comment\" spellcheck=\"true\"># s2-1  dp AC 456ms</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">calLength</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> start<span class=\"token punctuation\">,</span> s<span class=\"token punctuation\">,</span> dp<span class=\"token punctuation\">,</span> memo<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> start <span class=\"token operator\">==</span> len<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span> <span class=\"token number\">0</span>\n        <span class=\"token keyword\">if</span> start <span class=\"token operator\">==</span> len<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span>\n            memo<span class=\"token punctuation\">[</span>start<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>len<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">1</span>\n            <span class=\"token keyword\">return</span> <span class=\"token number\">1</span>\n        <span class=\"token keyword\">if</span> dp<span class=\"token punctuation\">[</span>start<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>len<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n            memo<span class=\"token punctuation\">[</span>start<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>len<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">1</span>\n            <span class=\"token keyword\">return</span> <span class=\"token number\">1</span>\n        <span class=\"token keyword\">if</span> memo<span class=\"token punctuation\">[</span>start<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>len<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">!=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span> memo<span class=\"token punctuation\">[</span>start<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>len<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>\n\n        res <span class=\"token operator\">=</span> float<span class=\"token punctuation\">(</span><span class=\"token string\">'inf'</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span>start<span class=\"token punctuation\">,</span> len<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">if</span> dp<span class=\"token punctuation\">[</span>start<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token punctuation\">:</span>\n                res <span class=\"token operator\">=</span> min<span class=\"token punctuation\">(</span>res<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>calLength<span class=\"token punctuation\">(</span>i<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> s<span class=\"token punctuation\">,</span> dp <span class=\"token punctuation\">,</span> memo<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        memo<span class=\"token punctuation\">[</span>start<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>len<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> res <span class=\"token operator\">+</span> <span class=\"token number\">1</span>\n        <span class=\"token keyword\">return</span> memo<span class=\"token punctuation\">[</span>start<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>len<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span></code></pre>\n<p>AC</p>\n<p>DFSDPDP</p>\n<p>$dp[i][j] = min(dp[i][k] + dp[k+1][j] + 1) ,if \\quad s[i:j+1]$</p>\n<p> dp i-j gapgapgapdp</p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">calLength</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> s<span class=\"token punctuation\">,</span> dp <span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        length <span class=\"token operator\">=</span> len<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span>\n        dp_2 <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token operator\">*</span>length <span class=\"token keyword\">for</span> _ <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span>length<span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">if</span> dp<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>length<span class=\"token number\">-1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n            dp_2<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n            <span class=\"token keyword\">return</span> dp_2\n        <span class=\"token comment\" spellcheck=\"true\"># s1 gap dp</span>\n        <span class=\"token keyword\">for</span> gap <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> length<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span>length<span class=\"token operator\">-</span>gap<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                j <span class=\"token operator\">=</span> i<span class=\"token operator\">+</span>gap\n                <span class=\"token keyword\">if</span> <span class=\"token operator\">not</span> dp<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n                    r <span class=\"token operator\">=</span> float<span class=\"token punctuation\">(</span><span class=\"token string\">'inf'</span><span class=\"token punctuation\">)</span>\n                    <span class=\"token keyword\">for</span> k <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">,</span> j<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                        r <span class=\"token operator\">=</span> min<span class=\"token punctuation\">(</span>r<span class=\"token punctuation\">,</span> dp_2<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>k<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> dp_2<span class=\"token punctuation\">[</span>k<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\n                    dp_2<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> r\n                <span class=\"token keyword\">return</span> dp_2</code></pre>\n<p>$O(N^3)$TLE$O(N^2)$</p>\n<h3 id=\"Manacher\"><a href=\"#Manacher\" class=\"headerlink\" title=\"Manacher\"></a>Manacher</h3><p>RL[i]iRLiposRL[pos]posij</p>\n<p><img src=\"1.png\" alt=\"1\"></p>\n<p><img src=\"2.png\" alt=\"2\"></p>\n<p>RL[j]RL[j]RL[i]RL[i]0RL[j]pos2R[i],posRL[i]</p>\n<p><img src=\"3.png\" alt=\"3\"></p>\n<p>imaxRight 0<img src=\"4.png\" alt=\"4\"></p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">manacher</span><span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  s <span class=\"token operator\">=</span> <span class=\"token string\">'_'</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span>\n  rl <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token operator\">*</span>len<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span>\n  maxRight <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n  pos <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n  maxLen <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n\n  <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span>len<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">if</span> i <span class=\"token operator\">&lt;</span> maxRight<span class=\"token punctuation\">:</span>\n      rl<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> min<span class=\"token punctuation\">(</span>rl<span class=\"token punctuation\">[</span><span class=\"token number\">2</span><span class=\"token operator\">*</span>pos<span class=\"token operator\">-</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> maxRight<span class=\"token operator\">-</span>i<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n      rl<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">1</span>\n    <span class=\"token comment\" spellcheck=\"true\"># rl[i]</span>\n    <span class=\"token keyword\">while</span> i<span class=\"token operator\">-</span>rl<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token operator\">>=</span><span class=\"token number\">0</span> <span class=\"token operator\">and</span> i<span class=\"token operator\">+</span>rl<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token operator\">&lt;</span>len<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span> <span class=\"token operator\">and</span> s<span class=\"token punctuation\">[</span>i<span class=\"token operator\">-</span>rl<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token operator\">==</span>s<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span>rl<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n      rl<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">+=</span> <span class=\"token number\">1</span>\n\n    <span class=\"token keyword\">if</span> rl<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token operator\">+</span>i<span class=\"token number\">-1</span><span class=\"token operator\">></span>maxRight<span class=\"token punctuation\">:</span>\n      maxRight <span class=\"token operator\">=</span> rl<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> i <span class=\"token operator\">-</span><span class=\"token number\">1</span>\n      pos <span class=\"token operator\">=</span> i\n\n    maxLen <span class=\"token operator\">=</span> max<span class=\"token punctuation\">(</span>maxLen<span class=\"token punctuation\">,</span> rl<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n  <span class=\"token keyword\">return</span> maxLen<span class=\"token number\">-1</span></code></pre>\n<p>$O(N)$$O(N^2)$RL[j]0RL[i]RL[j]RL[j]RL[i]$O(N)$$O(N^2)$</p>\n<h3 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h3><p>manacherNFA$O(N^2)$</p>\n<p>Reference:</p>\n<p><a href=\"https://segmentfault.com/a/1190000003914228\">-Manacher</a></p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>Given a string <code>s</code>, partition <code>s</code> such that every substring of the partition is a palindrome.</p>\n<p>Return <em>the minimum cuts needed</em> for a palindrome partitioning of <code>s</code>.</p>\n<p><strong>Example 1:</strong></p>\n<pre><code>Input: s = &quot;aab&quot;\nOutput: 1\nExplanation: The palindrome partitioning [&quot;aa&quot;,&quot;b&quot;] could be produced using 1 cut.</code></pre>\n<p><strong>Example 2:</strong></p>\n<pre><code>Input: s = &quot;a&quot;\nOutput: 0</code></pre>\n<p><strong>Example 3:</strong></p>\n<pre><code>Input: s = &quot;ab&quot;\nOutput: 1</code></pre>\n<p><strong>Constraints:</strong></p>\n<ul>\n<li><code>1 &lt;= s.length &lt;= 2000</code></li>\n<li><code>s</code> consists of lower-case English letters only.</li>\n</ul>\n</blockquote>\n<p>DFANFAOJACsubstringAC</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>substring 132131 Palindrome Partitioning I  mediums  substring 131OJ132AC131DPDP ACACDP</p>\n<pre><code class=\"python\"># 131 Palindrome Partitioning I\nclass Solution:\n    def partition(self, s: str) -&gt; List[List[str]]:\n        res = []\n        memo = &#123;&#125;\n        self.splitPalindrome(s, [], res, memo)\n        return res\n\n    def isPalindrome(self, s, memo):\n        if len(s) == 0:\n            return False\n        if len(s) == 1:\n            return True\n\n        if s in memo:\n            return memo[s]\n\n        news = &#39;_&#39;.join(s)\n        mid = len(news) // 2\n        for i in range(1,mid+1):\n            pre = mid - i\n            post = mid + i \n            if news[pre] != news[post]:\n                memo[s] = False\n                return False\n        memo[s] = True\n        return True\n\n    def splitPalindrome(self, s, rs, res,memo):\n        if len(s) == 0:\n            res.append(rs)\n            return\n        if len(s) == 1:\n            res.append(rs+[s])\n            return\n\n        for i in range(1,len(s)+1):\n            if self.isPalindrome(s[ :i], memo):\n                self.splitPalindrome(s[i: ], rs + [s[ :i]], res, memo)\n        return\n</code></pre>\n<p>DFSsrssresssubstringmemoAC.</p>\n<p>Hard</p>\n<p>  nnstring$s[i][j]$ substring$s[i][j]$$O(N^2)$substring $O(N^2)$Tricksubstring</p>\n<h4 id=\"-Longest-Palindrome-Substring\"><a href=\"#-Longest-Palindrome-Substring\" class=\"headerlink\" title=\" Longest Palindrome Substring\"></a> Longest Palindrome Substring</h4><p><a href=\"https://segmentfault.com/a/1190000003914228\"></a>1.2.$O(N^2)$2Manacher$s[i][j]$dp$dp[i][j] = dp[i+1][j-1] ,if \\quad s[i]==s[j] $ $dp[i][j]==dp[j][i]$</p>\n<pre><code class=\"python\"># dp substring  \n    def longestPalindrome(self, s):\n        length = len(s)\n        dp = [[False]*length for _ in range(length)]\n        for i in range(length):\n            j = i\n            while j &gt;= 0:\n                if s[j] == s[i] and (i-j&lt;2 or dp[j+1][i-1]):\n                    dp[j][i] = True\n                j -= 1\n        return dp</code></pre>\n<p>$O(N^2)$</p>\n<p>$O(N^2)$AC</p>\n<pre><code class=\"python\">#  O(N**2) \n    def longestPalindrome(self, s):\n        length = len(s)\n        d = [[False]*length for _ in range(length)]\n\n        news = &#39;_&#39;.join(s)\n        for i in range(len(news)):\n            d[i//2][i//2] = True\n            end = min(i, len(news)-i)\n            flag = True\n            for j in range(1,end+1):\n                pre = i-j\n                post = i+j\n\n                if news[pre] != &#39;_&#39; and  flag:\n                    if  news[pre] == news[post]:\n                        d[pre//2][post//2] = True\n                    else:\n                        flag = False\n        return d</code></pre>\n<h4 id=\"DFS\"><a href=\"#DFS\" class=\"headerlink\" title=\"DFS\"></a>DFS</h4><p>DFS131</p>\n<pre><code class=\"python\"># s2-1  dp AC 456ms\n    def calLength(self, start, s, dp, memo):\n        if start == len(s):\n            return 0\n        if start == len(s)-1:\n            memo[start][len(s)-1] = 1\n            return 1\n        if dp[start][len(s)-1]:\n            memo[start][len(s)-1] = 1\n            return 1\n        if memo[start][len(s)-1] != 0:\n            return memo[start][len(s)-1]\n\n        res = float(&#39;inf&#39;)\n        for i in range(start, len(s)):\n            if dp[start][i] :\n                res = min(res, self.calLength(i+1, s, dp , memo))\n        memo[start][len(s)-1] = res + 1\n        return memo[start][len(s)-1]</code></pre>\n<p>AC</p>\n<p>DFSDPDP</p>\n<p>$dp[i][j] = min(dp[i][k] + dp[k+1][j] + 1) ,if \\quad s[i:j+1]$</p>\n<p> dp i-j gapgapgapdp</p>\n<pre><code class=\"python\">def calLength(self, s, dp ):\n        length = len(s)\n        dp_2 = [[0]*length for _ in range(length)]\n        if dp[0][length-1]:\n            dp_2[0][-1] = 0\n            return dp_2\n        # s1 gap dp\n        for gap in range(1, length):\n            for i in range(length-gap):\n                j = i+gap\n                if not dp[i][j]:\n                    r = float(&#39;inf&#39;)\n                    for k in range(i, j):\n                        r = min(r, dp_2[i][k] + dp_2[k+1][j] + 1)\n\n                    dp_2[i][j] = r\n                return dp_2</code></pre>\n<p>$O(N^3)$TLE$O(N^2)$</p>\n<h3 id=\"Manacher\"><a href=\"#Manacher\" class=\"headerlink\" title=\"Manacher\"></a>Manacher</h3><p>RL[i]iRLiposRL[pos]posij</p>\n<p><img src=\"1.png\" alt=\"1\"></p>\n<p><img src=\"2.png\" alt=\"2\"></p>\n<p>RL[j]RL[j]RL[i]RL[i]0RL[j]pos2R[i],posRL[i]</p>\n<p><img src=\"3.png\" alt=\"3\"></p>\n<p>imaxRight 0<img src=\"4.png\" alt=\"4\"></p>\n<pre><code class=\"python\">def manacher(s):\n  s = &#39;_&#39;.join(s)\n  rl = [0]*len(s)\n  maxRight = 0\n  pos = 0\n  maxLen = 0\n\n  for i in range(len(s)):\n    if i &lt; maxRight:\n      rl[i] = min(rl[2*pos-i], maxRight-i)\n    else:\n      rl[i] = 1\n    # rl[i]\n    while i-rl[i]&gt;=0 and i+rl[i]&lt;len(s) and s[i-rl[i]]==s[i+rl[i]]:\n      rl[i] += 1\n\n    if rl[i]+i-1&gt;maxRight:\n      maxRight = rl[i] + i -1\n      pos = i\n\n    maxLen = max(maxLen, rl[i])\n  return maxLen-1</code></pre>\n<p>$O(N)$$O(N^2)$RL[j]0RL[i]RL[j]RL[j]RL[i]$O(N)$$O(N^2)$</p>\n<h3 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h3><p>manacherNFA$O(N^2)$</p>\n<p>Reference:</p>\n<p><a href=\"https://segmentfault.com/a/1190000003914228\">-Manacher</a></p>\n"},{"title":"Python ","toc":true,"mathjax":true,"top":false,"cover":true,"date":"2020-12-30T06:22:34.000Z","updated":"2021-01-04T03:28:00.190Z","_content":"\nPython\n\n## (Process)  (Thread)\n\n> \n>\n> \n>\n> \n\nMaster-Worker MasterWorkerPython\n\nApacheOSOSOSIPv4  32 OSUnix/Linux forkWIndows\n\nCPUCacheCPU2CPUCPUUnix/LinuxCPUlscpuCPU(s)LinuxCPUCPU\n\nOSWindowsIISApache+RISC  CISCIntel x86 x64 CISCRISCRISCRISCCISCApacheIISNginxIOPython\n\n\n\n> - CPU\n> - CPU: CPU()\n> - CPUCPU\n> - \n> - \n> - \n> - \n> - \"\"Mutual exclusion Mutex\n> - nn\n> - n\"\"Semaphore\n> - mutexsemaphoren=1mutex\n\n[](http://www.ruanyifeng.com/blog/2013/04/processes_and_threads.html)\n\n\n\n## Python multiprocessing\n\n$8^{20}$sleep 2s\n\n```python\nimport time\nimport os\n\ndef long_time_task():\n    print(': {}'.format(os.getpid()))\n    time.sleep(2)\n    print(\": {}\".format(8 ** 20))\n\nif __name__ == \"__main__\":\n    print(': {}'.format(os.getpid()))\n    start = time.time()\n    for i in range(2):\n        long_time_task()\n\n    end = time.time()\n    print(\"{}\".format((end-start)))\n    \n: 33121\n: 33121\n: 1152921504606846976\n: 33121\n: 1152921504606846976\n4.004350185394287\n```\n\nsleep 4s\n\n\n\n```python\nfrom multiprocessing import Process\nimport os\nimport time\n\n\ndef long_time_task(i):\n    print(': {} - {}'.format(os.getpid(), i))\n    time.sleep(2)\n    print(\": {}\".format(8 ** 20))\n\nif __name__=='__main__':\n    print(': {}'.format(os.getpid()))\n    start = time.time()\n    p1 = Process(target=long_time_task, args=(1,))\n    p2 = Process(target=long_time_task, args=(2,))\n    print('')\n    p1.start()\n    p2.start()\n    p1.join()\n    p2.join()\n    end = time.time()\n    print(\"{}\".format((end - start)))\n    \n: 33121\n\n: 34270 - 1\n: 34271 - 2\n: 1152921504606846976\n: 1152921504606846976\n2.009559392929077\n```\n\n\n\np.join()p.join()\n\n```\n: 33121\n\n: 34669 - 1\n0.002809762954711914\n: 34670 - 2\n: 1152921504606846976\n: 1152921504606846976\n```\n\nOSCPUProcessPool\n\nPoolPool\n\nmultiprocessing Pool\n\n1. apply_async\n\napply_async(func[, args=()[, kwds={}[, callback=None]]])\n\n \n\n2. map()\n\nmap(func, iterable[, chunksize=None])\n\nPoolmapmap \n\n3. map_async()\n\nmap_async(func, iterable[, chunksize[, callback]])\nmapapply_async\n\n4. close()\n\npool\n\n5. terminate()\n\n\n\n6. join()\n\n joincloseterminate\n\n\n\n4Pool54\n\n```python\nfrom multiprocessing import Pool, cpu_count\nimport os\nimport time\n\n\ndef long_time_task(i):\n    print(': {} - {}'.format(os.getpid(), i))\n    time.sleep(2)\n    print(\": {}\".format(8 ** 20))\n\n\nif __name__=='__main__':\n    print(\"CPU:{}\".format(cpu_count()))\n    print(': {}'.format(os.getpid()))\n    start = time.time()\n    p = Pool(4)\n    for i in range(5):\n        p.apply_async(long_time_task, args=(i,))\n    print('')\n    p.close()\n    p.join()\n    end = time.time()\n    print(\"{}\".format((end - start)))\n    \nCPU:64\n: 33121\n\n: 37454 - 0\n: 37455 - 1\n: 37456 - 2\n: 37457 - 3\n: 1152921504606846976\n: 1152921504606846976\n: 37454 - 4\n: 1152921504606846976\n: 1152921504606846976\n: 1152921504606846976\n4.115360736846924\n```\n\n42s+2s4s+\n\nPythonGILCPU\n\nAddmultiprocessing.Queue \n\n```python\nfrom multiprocessing import Process, Queue\nimport os, time, random\n\n# :\ndef write(q):\n    print('Process to write: {}'.format(os.getpid()))\n    for value in ['A', 'B', 'C']:\n        print('Put %s to queue...' % value)\n        q.put(value)\n        time.sleep(random.random())\n\n# :\ndef read(q):\n    print('Process to read:{}'.format(os.getpid()))\n    while True:\n        value = q.get(True)\n        print('Get %s from queue.' % value)\n\nif __name__=='__main__':\n    # Queue\n    q = Queue()\n    pw = Process(target=write, args=(q,))\n    pr = Process(target=read, args=(q,))\n    # pw:\n    pw.start()\n    # pr:\n    pr.start()\n    # pw:\n    pw.join()\n    # pr:\n    pr.terminate()\n    \nProcess to write: 39190\nPut A to queue...\nProcess to read:39191\nGet A from queue.\nPut B to queue...\nGet B from queue.\nPut C to queue...\nGet C from queue.\n```\n\n##\n\n## Python  Threading \n\n\n\n```python\nimport threading\nimport time\n\n\ndef long_time_task(i):\n    print(': {} - {}'.format(threading.current_thread().name, i))\n    time.sleep(2)\n    print(\": {}\".format(8 ** 20))\n\n\nif __name__=='__main__':\n    start = time.time()\n    print('{}'.format(threading.current_thread().name))\n    t1 = threading.Thread(target=long_time_task, args=(1,))\n    t2 = threading.Thread(target=long_time_task, args=(2,))\n    t1.start()\n    t2.start()\n    \n    t1.join()\n    t2.join()\n    end = time.time()\n    print(\"{}\".format((end - start)))\n    \nMainThread\n: Thread-1316 - 1\n: Thread-1317 - 2\n: 1152921504606846976\n: 1152921504606846976\n2.0029757022857666\n```\n\nGILsleep ,sleepIOGILsleepCPUCPU $8^{1000000}$\n\n```python\ndef long_time_task(i):\n    print(': {} - {}'.format(threading.current_thread().name, i))\n    time.sleep(2)\n    t = time.time()\n    print(\": {}\".format(8 ** 1000000))\n    print(' ', time.time()-t)\n#  long_time_task(1)\n : 11.462863683700562\n13.43696641921997\n#  \n : 22.85654377937317\n : 23.088494300842285\n25.10121512413025\n\n```\n\n22s11s121222sPythonGIL\n\nqueue.Queue\n\n```python\nfrom queue import Queue\nimport random, threading, time\n\n\n# \nclass Producer(threading.Thread):\n    def __init__(self, name, queue):\n        threading.Thread.__init__(self, name=name)\n        self.queue = queue\n\n    def run(self):\n        for i in range(1, 5):\n            print(\"{} is producing {} to the queue!\".format(self.getName(), i))\n            self.queue.put(i)\n            time.sleep(random.randrange(10) / 5)\n        print(\"%s finished!\" % self.getName())\n\n\n# \nclass Consumer(threading.Thread):\n    def __init__(self, name, queue):\n        threading.Thread.__init__(self, name=name)\n        self.queue = queue\n\n    def run(self):\n        for i in range(1, 5):\n            val = self.queue.get()\n            print(\"{} is consuming {} in the queue.\".format(self.getName(), val))\n            time.sleep(random.randrange(10))\n        print(\"%s finished!\" % self.getName())\n\n\ndef main():\n    queue = Queue()\n    producer = Producer('Producer', queue)\n    consumer = Consumer('Consumer', queue)\n\n    producer.start()\n    consumer.start()\n    \n    producer.join()\n    consumer.join()\n    print('All threads finished!')\n\n\nif __name__ == '__main__':\n    main()\n```\n\n\n\n##  vs IO\n\npythonCPUPythonC  \n\nIOPythonIOCPUPythonwebIOPython\n\n## IO  \n\nCPUIOIO\n\nIOIOIONginxIOWebCPUCPUCPUCPUIO\n\nPython\n\n\n\n## Conclude\n\nPythonIO-\n\n\n\n\n\nReferences:\n\n[Python](https://zhuanlan.zhihu.com/p/46368084)\n\n[ vs  ](https://www.liaoxuefeng.com/wiki/1016959663602400/1017631469467456)\n\n[ Python3 CookBook](https://python3-cookbook.readthedocs.io/zh_CN/latest/c12/p03_communicating_between_threads.html)\n\n","source":"_posts/Python-.md","raw":"---\ntitle: Python \ntoc: true\nmathjax: true\ntop: false\ncover: true\ndate: 2020-12-30 14:22:34\nupdated:\ncategories: Algorithms\ntags:\n\t- Algorithms\n\t- OS\n---\n\nPython\n\n## (Process)  (Thread)\n\n> \n>\n> \n>\n> \n\nMaster-Worker MasterWorkerPython\n\nApacheOSOSOSIPv4  32 OSUnix/Linux forkWIndows\n\nCPUCacheCPU2CPUCPUUnix/LinuxCPUlscpuCPU(s)LinuxCPUCPU\n\nOSWindowsIISApache+RISC  CISCIntel x86 x64 CISCRISCRISCRISCCISCApacheIISNginxIOPython\n\n\n\n> - CPU\n> - CPU: CPU()\n> - CPUCPU\n> - \n> - \n> - \n> - \n> - \"\"Mutual exclusion Mutex\n> - nn\n> - n\"\"Semaphore\n> - mutexsemaphoren=1mutex\n\n[](http://www.ruanyifeng.com/blog/2013/04/processes_and_threads.html)\n\n\n\n## Python multiprocessing\n\n$8^{20}$sleep 2s\n\n```python\nimport time\nimport os\n\ndef long_time_task():\n    print(': {}'.format(os.getpid()))\n    time.sleep(2)\n    print(\": {}\".format(8 ** 20))\n\nif __name__ == \"__main__\":\n    print(': {}'.format(os.getpid()))\n    start = time.time()\n    for i in range(2):\n        long_time_task()\n\n    end = time.time()\n    print(\"{}\".format((end-start)))\n    \n: 33121\n: 33121\n: 1152921504606846976\n: 33121\n: 1152921504606846976\n4.004350185394287\n```\n\nsleep 4s\n\n\n\n```python\nfrom multiprocessing import Process\nimport os\nimport time\n\n\ndef long_time_task(i):\n    print(': {} - {}'.format(os.getpid(), i))\n    time.sleep(2)\n    print(\": {}\".format(8 ** 20))\n\nif __name__=='__main__':\n    print(': {}'.format(os.getpid()))\n    start = time.time()\n    p1 = Process(target=long_time_task, args=(1,))\n    p2 = Process(target=long_time_task, args=(2,))\n    print('')\n    p1.start()\n    p2.start()\n    p1.join()\n    p2.join()\n    end = time.time()\n    print(\"{}\".format((end - start)))\n    \n: 33121\n\n: 34270 - 1\n: 34271 - 2\n: 1152921504606846976\n: 1152921504606846976\n2.009559392929077\n```\n\n\n\np.join()p.join()\n\n```\n: 33121\n\n: 34669 - 1\n0.002809762954711914\n: 34670 - 2\n: 1152921504606846976\n: 1152921504606846976\n```\n\nOSCPUProcessPool\n\nPoolPool\n\nmultiprocessing Pool\n\n1. apply_async\n\napply_async(func[, args=()[, kwds={}[, callback=None]]])\n\n \n\n2. map()\n\nmap(func, iterable[, chunksize=None])\n\nPoolmapmap \n\n3. map_async()\n\nmap_async(func, iterable[, chunksize[, callback]])\nmapapply_async\n\n4. close()\n\npool\n\n5. terminate()\n\n\n\n6. join()\n\n joincloseterminate\n\n\n\n4Pool54\n\n```python\nfrom multiprocessing import Pool, cpu_count\nimport os\nimport time\n\n\ndef long_time_task(i):\n    print(': {} - {}'.format(os.getpid(), i))\n    time.sleep(2)\n    print(\": {}\".format(8 ** 20))\n\n\nif __name__=='__main__':\n    print(\"CPU:{}\".format(cpu_count()))\n    print(': {}'.format(os.getpid()))\n    start = time.time()\n    p = Pool(4)\n    for i in range(5):\n        p.apply_async(long_time_task, args=(i,))\n    print('')\n    p.close()\n    p.join()\n    end = time.time()\n    print(\"{}\".format((end - start)))\n    \nCPU:64\n: 33121\n\n: 37454 - 0\n: 37455 - 1\n: 37456 - 2\n: 37457 - 3\n: 1152921504606846976\n: 1152921504606846976\n: 37454 - 4\n: 1152921504606846976\n: 1152921504606846976\n: 1152921504606846976\n4.115360736846924\n```\n\n42s+2s4s+\n\nPythonGILCPU\n\nAddmultiprocessing.Queue \n\n```python\nfrom multiprocessing import Process, Queue\nimport os, time, random\n\n# :\ndef write(q):\n    print('Process to write: {}'.format(os.getpid()))\n    for value in ['A', 'B', 'C']:\n        print('Put %s to queue...' % value)\n        q.put(value)\n        time.sleep(random.random())\n\n# :\ndef read(q):\n    print('Process to read:{}'.format(os.getpid()))\n    while True:\n        value = q.get(True)\n        print('Get %s from queue.' % value)\n\nif __name__=='__main__':\n    # Queue\n    q = Queue()\n    pw = Process(target=write, args=(q,))\n    pr = Process(target=read, args=(q,))\n    # pw:\n    pw.start()\n    # pr:\n    pr.start()\n    # pw:\n    pw.join()\n    # pr:\n    pr.terminate()\n    \nProcess to write: 39190\nPut A to queue...\nProcess to read:39191\nGet A from queue.\nPut B to queue...\nGet B from queue.\nPut C to queue...\nGet C from queue.\n```\n\n##\n\n## Python  Threading \n\n\n\n```python\nimport threading\nimport time\n\n\ndef long_time_task(i):\n    print(': {} - {}'.format(threading.current_thread().name, i))\n    time.sleep(2)\n    print(\": {}\".format(8 ** 20))\n\n\nif __name__=='__main__':\n    start = time.time()\n    print('{}'.format(threading.current_thread().name))\n    t1 = threading.Thread(target=long_time_task, args=(1,))\n    t2 = threading.Thread(target=long_time_task, args=(2,))\n    t1.start()\n    t2.start()\n    \n    t1.join()\n    t2.join()\n    end = time.time()\n    print(\"{}\".format((end - start)))\n    \nMainThread\n: Thread-1316 - 1\n: Thread-1317 - 2\n: 1152921504606846976\n: 1152921504606846976\n2.0029757022857666\n```\n\nGILsleep ,sleepIOGILsleepCPUCPU $8^{1000000}$\n\n```python\ndef long_time_task(i):\n    print(': {} - {}'.format(threading.current_thread().name, i))\n    time.sleep(2)\n    t = time.time()\n    print(\": {}\".format(8 ** 1000000))\n    print(' ', time.time()-t)\n#  long_time_task(1)\n : 11.462863683700562\n13.43696641921997\n#  \n : 22.85654377937317\n : 23.088494300842285\n25.10121512413025\n\n```\n\n22s11s121222sPythonGIL\n\nqueue.Queue\n\n```python\nfrom queue import Queue\nimport random, threading, time\n\n\n# \nclass Producer(threading.Thread):\n    def __init__(self, name, queue):\n        threading.Thread.__init__(self, name=name)\n        self.queue = queue\n\n    def run(self):\n        for i in range(1, 5):\n            print(\"{} is producing {} to the queue!\".format(self.getName(), i))\n            self.queue.put(i)\n            time.sleep(random.randrange(10) / 5)\n        print(\"%s finished!\" % self.getName())\n\n\n# \nclass Consumer(threading.Thread):\n    def __init__(self, name, queue):\n        threading.Thread.__init__(self, name=name)\n        self.queue = queue\n\n    def run(self):\n        for i in range(1, 5):\n            val = self.queue.get()\n            print(\"{} is consuming {} in the queue.\".format(self.getName(), val))\n            time.sleep(random.randrange(10))\n        print(\"%s finished!\" % self.getName())\n\n\ndef main():\n    queue = Queue()\n    producer = Producer('Producer', queue)\n    consumer = Consumer('Consumer', queue)\n\n    producer.start()\n    consumer.start()\n    \n    producer.join()\n    consumer.join()\n    print('All threads finished!')\n\n\nif __name__ == '__main__':\n    main()\n```\n\n\n\n##  vs IO\n\npythonCPUPythonC  \n\nIOPythonIOCPUPythonwebIOPython\n\n## IO  \n\nCPUIOIO\n\nIOIOIONginxIOWebCPUCPUCPUCPUIO\n\nPython\n\n\n\n## Conclude\n\nPythonIO-\n\n\n\n\n\nReferences:\n\n[Python](https://zhuanlan.zhihu.com/p/46368084)\n\n[ vs  ](https://www.liaoxuefeng.com/wiki/1016959663602400/1017631469467456)\n\n[ Python3 CookBook](https://python3-cookbook.readthedocs.io/zh_CN/latest/c12/p03_communicating_between_threads.html)\n\n","slug":"Python-","published":1,"_id":"ckjb842170000pl28gqvdaaxk","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Python</p>\n<h2 id=\"-Process---Thread\"><a href=\"#-Process---Thread\" class=\"headerlink\" title=\"(Process)  (Thread)\"></a>(Process)  (Thread)</h2><blockquote>\n<p></p>\n<p></p>\n<p></p>\n</blockquote>\n<p>Master-Worker MasterWorkerPython</p>\n<p>ApacheOSOSOSIPv4  32 OSUnix/Linux forkWIndows</p>\n<p>CPUCacheCPU2CPUCPUUnix/LinuxCPUlscpuCPU(s)LinuxCPUCPU</p>\n<p>OSWindowsIISApache+RISC  CISCIntel x86 x64 CISCRISCRISCRISCCISCApacheIISNginxIOPython</p>\n<p></p>\n<blockquote>\n<ul>\n<li>CPU</li>\n<li>CPU: CPU()</li>\n<li>CPUCPU</li>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n<li>Mutual exclusion Mutex</li>\n<li>nn</li>\n<li>nSemaphore</li>\n<li>mutexsemaphoren=1mutex</li>\n</ul>\n</blockquote>\n<p><a href=\"http://www.ruanyifeng.com/blog/2013/04/processes_and_threads.html\"></a></p>\n<h2 id=\"Python-multiprocessing\"><a href=\"#Python-multiprocessing\" class=\"headerlink\" title=\"Python multiprocessing\"></a>Python multiprocessing</h2><p>$8^{20}$sleep 2s</p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> time\n<span class=\"token keyword\">import</span> os\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">long_time_task</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">': &amp;#123;&amp;#125;'</span><span class=\"token punctuation\">.</span>format<span class=\"token punctuation\">(</span>os<span class=\"token punctuation\">.</span>getpid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\": &amp;#123;&amp;#125;\"</span><span class=\"token punctuation\">.</span>format<span class=\"token punctuation\">(</span><span class=\"token number\">8</span> <span class=\"token operator\">**</span> <span class=\"token number\">20</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">\"__main__\"</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">': &amp;#123;&amp;#125;'</span><span class=\"token punctuation\">.</span>format<span class=\"token punctuation\">(</span>os<span class=\"token punctuation\">.</span>getpid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    start <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        long_time_task<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    end <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"&amp;#123;&amp;#125;\"</span><span class=\"token punctuation\">.</span>format<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>end<span class=\"token operator\">-</span>start<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token punctuation\">:</span> <span class=\"token number\">33121</span>\n<span class=\"token punctuation\">:</span> <span class=\"token number\">33121</span>\n<span class=\"token punctuation\">:</span> <span class=\"token number\">1152921504606846976</span>\n<span class=\"token punctuation\">:</span> <span class=\"token number\">33121</span>\n<span class=\"token punctuation\">:</span> <span class=\"token number\">1152921504606846976</span>\n<span class=\"token number\">4.004350185394287</span></code></pre>\n<p>sleep 4s</p>\n<p></p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> multiprocessing <span class=\"token keyword\">import</span> Process\n<span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> time\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">long_time_task</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">': &amp;#123;&amp;#125; - &amp;#123;&amp;#125;'</span><span class=\"token punctuation\">.</span>format<span class=\"token punctuation\">(</span>os<span class=\"token punctuation\">.</span>getpid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\": &amp;#123;&amp;#125;\"</span><span class=\"token punctuation\">.</span>format<span class=\"token punctuation\">(</span><span class=\"token number\">8</span> <span class=\"token operator\">**</span> <span class=\"token number\">20</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">if</span> __name__<span class=\"token operator\">==</span><span class=\"token string\">'__main__'</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">': &amp;#123;&amp;#125;'</span><span class=\"token punctuation\">.</span>format<span class=\"token punctuation\">(</span>os<span class=\"token punctuation\">.</span>getpid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    start <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    p1 <span class=\"token operator\">=</span> Process<span class=\"token punctuation\">(</span>target<span class=\"token operator\">=</span>long_time_task<span class=\"token punctuation\">,</span> args<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    p2 <span class=\"token operator\">=</span> Process<span class=\"token punctuation\">(</span>target<span class=\"token operator\">=</span>long_time_task<span class=\"token punctuation\">,</span> args<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">''</span><span class=\"token punctuation\">)</span>\n    p1<span class=\"token punctuation\">.</span>start<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    p2<span class=\"token punctuation\">.</span>start<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    p1<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    p2<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    end <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"&amp;#123;&amp;#125;\"</span><span class=\"token punctuation\">.</span>format<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>end <span class=\"token operator\">-</span> start<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token punctuation\">:</span> <span class=\"token number\">33121</span>\n\n<span class=\"token punctuation\">:</span> <span class=\"token number\">34270</span> <span class=\"token operator\">-</span> <span class=\"token number\">1</span>\n<span class=\"token punctuation\">:</span> <span class=\"token number\">34271</span> <span class=\"token operator\">-</span> <span class=\"token number\">2</span>\n<span class=\"token punctuation\">:</span> <span class=\"token number\">1152921504606846976</span>\n<span class=\"token punctuation\">:</span> <span class=\"token number\">1152921504606846976</span>\n<span class=\"token number\">2.009559392929077</span></code></pre>\n<p></p>\n<p>p.join()p.join()</p>\n<pre><code>: 33121\n\n: 34669 - 1\n0.002809762954711914\n: 34670 - 2\n: 1152921504606846976\n: 1152921504606846976</code></pre>\n<p>OSCPUProcessPool</p>\n<p>PoolPool</p>\n<p>multiprocessing Pool</p>\n<ol>\n<li>apply_async</li>\n</ol>\n<p>apply_async(func[, args=()[, kwds={}[, callback=None]]])</p>\n<p> </p>\n<ol start=\"2\">\n<li>map()</li>\n</ol>\n<p>map(func, iterable[, chunksize=None])</p>\n<p>Poolmapmap </p>\n<ol start=\"3\">\n<li>map_async()</li>\n</ol>\n<p>map_async(func, iterable[, chunksize[, callback]])<br>mapapply_async</p>\n<ol start=\"4\">\n<li>close()</li>\n</ol>\n<p>pool</p>\n<ol start=\"5\">\n<li>terminate()</li>\n</ol>\n<p></p>\n<ol start=\"6\">\n<li>join()</li>\n</ol>\n<p> joincloseterminate</p>\n<p>4Pool54</p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> multiprocessing <span class=\"token keyword\">import</span> Pool<span class=\"token punctuation\">,</span> cpu_count\n<span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> time\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">long_time_task</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">': &amp;#123;&amp;#125; - &amp;#123;&amp;#125;'</span><span class=\"token punctuation\">.</span>format<span class=\"token punctuation\">(</span>os<span class=\"token punctuation\">.</span>getpid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\": &amp;#123;&amp;#125;\"</span><span class=\"token punctuation\">.</span>format<span class=\"token punctuation\">(</span><span class=\"token number\">8</span> <span class=\"token operator\">**</span> <span class=\"token number\">20</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n\n<span class=\"token keyword\">if</span> __name__<span class=\"token operator\">==</span><span class=\"token string\">'__main__'</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"CPU:&amp;#123;&amp;#125;\"</span><span class=\"token punctuation\">.</span>format<span class=\"token punctuation\">(</span>cpu_count<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">': &amp;#123;&amp;#125;'</span><span class=\"token punctuation\">.</span>format<span class=\"token punctuation\">(</span>os<span class=\"token punctuation\">.</span>getpid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    start <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    p <span class=\"token operator\">=</span> Pool<span class=\"token punctuation\">(</span><span class=\"token number\">4</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        p<span class=\"token punctuation\">.</span>apply_async<span class=\"token punctuation\">(</span>long_time_task<span class=\"token punctuation\">,</span> args<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">''</span><span class=\"token punctuation\">)</span>\n    p<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    p<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    end <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"&amp;#123;&amp;#125;\"</span><span class=\"token punctuation\">.</span>format<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>end <span class=\"token operator\">-</span> start<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nCPU<span class=\"token punctuation\">:</span><span class=\"token number\">64</span>\n<span class=\"token punctuation\">:</span> <span class=\"token number\">33121</span>\n\n<span class=\"token punctuation\">:</span> <span class=\"token number\">37454</span> <span class=\"token operator\">-</span> <span class=\"token number\">0</span>\n<span class=\"token punctuation\">:</span> <span class=\"token number\">37455</span> <span class=\"token operator\">-</span> <span class=\"token number\">1</span>\n<span class=\"token punctuation\">:</span> <span class=\"token number\">37456</span> <span class=\"token operator\">-</span> <span class=\"token number\">2</span>\n<span class=\"token punctuation\">:</span> <span class=\"token number\">37457</span> <span class=\"token operator\">-</span> <span class=\"token number\">3</span>\n<span class=\"token punctuation\">:</span> <span class=\"token number\">1152921504606846976</span>\n<span class=\"token punctuation\">:</span> <span class=\"token number\">1152921504606846976</span>\n<span class=\"token punctuation\">:</span> <span class=\"token number\">37454</span> <span class=\"token operator\">-</span> <span class=\"token number\">4</span>\n<span class=\"token punctuation\">:</span> <span class=\"token number\">1152921504606846976</span>\n<span class=\"token punctuation\">:</span> <span class=\"token number\">1152921504606846976</span>\n<span class=\"token punctuation\">:</span> <span class=\"token number\">1152921504606846976</span>\n<span class=\"token number\">4.115360736846924</span></code></pre>\n<p>42s+2s4s+</p>\n<p>PythonGILCPU</p>\n<p>Addmultiprocessing.Queue </p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> multiprocessing <span class=\"token keyword\">import</span> Process<span class=\"token punctuation\">,</span> Queue\n<span class=\"token keyword\">import</span> os<span class=\"token punctuation\">,</span> time<span class=\"token punctuation\">,</span> random\n\n<span class=\"token comment\" spellcheck=\"true\"># :</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">write</span><span class=\"token punctuation\">(</span>q<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Process to write: &amp;#123;&amp;#125;'</span><span class=\"token punctuation\">.</span>format<span class=\"token punctuation\">(</span>os<span class=\"token punctuation\">.</span>getpid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span> value <span class=\"token keyword\">in</span> <span class=\"token punctuation\">[</span><span class=\"token string\">'A'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'B'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'C'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Put %s to queue...'</span> <span class=\"token operator\">%</span> value<span class=\"token punctuation\">)</span>\n        q<span class=\"token punctuation\">.</span>put<span class=\"token punctuation\">(</span>value<span class=\"token punctuation\">)</span>\n        time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span>random<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\" spellcheck=\"true\"># :</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">read</span><span class=\"token punctuation\">(</span>q<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Process to read:&amp;#123;&amp;#125;'</span><span class=\"token punctuation\">.</span>format<span class=\"token punctuation\">(</span>os<span class=\"token punctuation\">.</span>getpid<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">while</span> <span class=\"token boolean\">True</span><span class=\"token punctuation\">:</span>\n        value <span class=\"token operator\">=</span> q<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Get %s from queue.'</span> <span class=\"token operator\">%</span> value<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">if</span> __name__<span class=\"token operator\">==</span><span class=\"token string\">'__main__'</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\" spellcheck=\"true\"># Queue</span>\n    q <span class=\"token operator\">=</span> Queue<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    pw <span class=\"token operator\">=</span> Process<span class=\"token punctuation\">(</span>target<span class=\"token operator\">=</span>write<span class=\"token punctuation\">,</span> args<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>q<span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    pr <span class=\"token operator\">=</span> Process<span class=\"token punctuation\">(</span>target<span class=\"token operator\">=</span>read<span class=\"token punctuation\">,</span> args<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span>q<span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\" spellcheck=\"true\"># pw:</span>\n    pw<span class=\"token punctuation\">.</span>start<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\" spellcheck=\"true\"># pr:</span>\n    pr<span class=\"token punctuation\">.</span>start<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\" spellcheck=\"true\"># pw:</span>\n    pw<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\" spellcheck=\"true\"># pr:</span>\n    pr<span class=\"token punctuation\">.</span>terminate<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\nProcess to write<span class=\"token punctuation\">:</span> <span class=\"token number\">39190</span>\nPut A to queue<span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\nProcess to read<span class=\"token punctuation\">:</span><span class=\"token number\">39191</span>\nGet A <span class=\"token keyword\">from</span> queue<span class=\"token punctuation\">.</span>\nPut B to queue<span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\nGet B <span class=\"token keyword\">from</span> queue<span class=\"token punctuation\">.</span>\nPut C to queue<span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\nGet C <span class=\"token keyword\">from</span> queue<span class=\"token punctuation\">.</span></code></pre>\n<p>##</p>\n<h2 id=\"Python--Threading\"><a href=\"#Python--Threading\" class=\"headerlink\" title=\"Python  Threading\"></a>Python  Threading</h2><p></p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> threading\n<span class=\"token keyword\">import</span> time\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">long_time_task</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">': &amp;#123;&amp;#125; - &amp;#123;&amp;#125;'</span><span class=\"token punctuation\">.</span>format<span class=\"token punctuation\">(</span>threading<span class=\"token punctuation\">.</span>current_thread<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>name<span class=\"token punctuation\">,</span> i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\": &amp;#123;&amp;#125;\"</span><span class=\"token punctuation\">.</span>format<span class=\"token punctuation\">(</span><span class=\"token number\">8</span> <span class=\"token operator\">**</span> <span class=\"token number\">20</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n\n<span class=\"token keyword\">if</span> __name__<span class=\"token operator\">==</span><span class=\"token string\">'__main__'</span><span class=\"token punctuation\">:</span>\n    start <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'&amp;#123;&amp;#125;'</span><span class=\"token punctuation\">.</span>format<span class=\"token punctuation\">(</span>threading<span class=\"token punctuation\">.</span>current_thread<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>name<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    t1 <span class=\"token operator\">=</span> threading<span class=\"token punctuation\">.</span>Thread<span class=\"token punctuation\">(</span>target<span class=\"token operator\">=</span>long_time_task<span class=\"token punctuation\">,</span> args<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    t2 <span class=\"token operator\">=</span> threading<span class=\"token punctuation\">.</span>Thread<span class=\"token punctuation\">(</span>target<span class=\"token operator\">=</span>long_time_task<span class=\"token punctuation\">,</span> args<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    t1<span class=\"token punctuation\">.</span>start<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    t2<span class=\"token punctuation\">.</span>start<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    t1<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    t2<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    end <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"&amp;#123;&amp;#125;\"</span><span class=\"token punctuation\">.</span>format<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>end <span class=\"token operator\">-</span> start<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nMainThread\n<span class=\"token punctuation\">:</span> Thread<span class=\"token number\">-1316</span> <span class=\"token operator\">-</span> <span class=\"token number\">1</span>\n<span class=\"token punctuation\">:</span> Thread<span class=\"token number\">-1317</span> <span class=\"token operator\">-</span> <span class=\"token number\">2</span>\n<span class=\"token punctuation\">:</span> <span class=\"token number\">1152921504606846976</span>\n<span class=\"token punctuation\">:</span> <span class=\"token number\">1152921504606846976</span>\n<span class=\"token number\">2.0029757022857666</span></code></pre>\n<p>GILsleep ,sleepIOGILsleepCPUCPU $8^{1000000}$</p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">long_time_task</span><span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">': &amp;#123;&amp;#125; - &amp;#123;&amp;#125;'</span><span class=\"token punctuation\">.</span>format<span class=\"token punctuation\">(</span>threading<span class=\"token punctuation\">.</span>current_thread<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>name<span class=\"token punctuation\">,</span> i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n    t <span class=\"token operator\">=</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\": &amp;#123;&amp;#125;\"</span><span class=\"token punctuation\">.</span>format<span class=\"token punctuation\">(</span><span class=\"token number\">8</span> <span class=\"token operator\">**</span> <span class=\"token number\">1000000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">' '</span><span class=\"token punctuation\">,</span> time<span class=\"token punctuation\">.</span>time<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">-</span>t<span class=\"token punctuation\">)</span>\n<span class=\"token comment\" spellcheck=\"true\">#  long_time_task(1)</span>\n <span class=\"token punctuation\">:</span> <span class=\"token number\">11.462863683700562</span>\n<span class=\"token number\">13.43696641921997</span>\n<span class=\"token comment\" spellcheck=\"true\">#  </span>\n <span class=\"token punctuation\">:</span> <span class=\"token number\">22.85654377937317</span>\n <span class=\"token punctuation\">:</span> <span class=\"token number\">23.088494300842285</span>\n<span class=\"token number\">25.10121512413025</span>\n</code></pre>\n<p>22s11s121222sPythonGIL</p>\n<p>queue.Queue</p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> queue <span class=\"token keyword\">import</span> Queue\n<span class=\"token keyword\">import</span> random<span class=\"token punctuation\">,</span> threading<span class=\"token punctuation\">,</span> time\n\n\n<span class=\"token comment\" spellcheck=\"true\"># </span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Producer</span><span class=\"token punctuation\">(</span>threading<span class=\"token punctuation\">.</span>Thread<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> name<span class=\"token punctuation\">,</span> queue<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        threading<span class=\"token punctuation\">.</span>Thread<span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> name<span class=\"token operator\">=</span>name<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>queue <span class=\"token operator\">=</span> queue\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">run</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"&amp;#123;&amp;#125; is producing &amp;#123;&amp;#125; to the queue!\"</span><span class=\"token punctuation\">.</span>format<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>getName<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n            self<span class=\"token punctuation\">.</span>queue<span class=\"token punctuation\">.</span>put<span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span>\n            time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span>random<span class=\"token punctuation\">.</span>randrange<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"%s finished!\"</span> <span class=\"token operator\">%</span> self<span class=\"token punctuation\">.</span>getName<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n\n<span class=\"token comment\" spellcheck=\"true\"># </span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Consumer</span><span class=\"token punctuation\">(</span>threading<span class=\"token punctuation\">.</span>Thread<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> name<span class=\"token punctuation\">,</span> queue<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        threading<span class=\"token punctuation\">.</span>Thread<span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> name<span class=\"token operator\">=</span>name<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>queue <span class=\"token operator\">=</span> queue\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">run</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            val <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>queue<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"&amp;#123;&amp;#125; is consuming &amp;#123;&amp;#125; in the queue.\"</span><span class=\"token punctuation\">.</span>format<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>getName<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> val<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n            time<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span>random<span class=\"token punctuation\">.</span>randrange<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"%s finished!\"</span> <span class=\"token operator\">%</span> self<span class=\"token punctuation\">.</span>getName<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    queue <span class=\"token operator\">=</span> Queue<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    producer <span class=\"token operator\">=</span> Producer<span class=\"token punctuation\">(</span><span class=\"token string\">'Producer'</span><span class=\"token punctuation\">,</span> queue<span class=\"token punctuation\">)</span>\n    consumer <span class=\"token operator\">=</span> Consumer<span class=\"token punctuation\">(</span><span class=\"token string\">'Consumer'</span><span class=\"token punctuation\">,</span> queue<span class=\"token punctuation\">)</span>\n\n    producer<span class=\"token punctuation\">.</span>start<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    consumer<span class=\"token punctuation\">.</span>start<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    producer<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    consumer<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'All threads finished!'</span><span class=\"token punctuation\">)</span>\n\n\n<span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">'__main__'</span><span class=\"token punctuation\">:</span>\n    main<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre>\n<h2 id=\"-vs-IO\"><a href=\"#-vs-IO\" class=\"headerlink\" title=\" vs IO\"></a> vs IO</h2><p>pythonCPUPythonC  </p>\n<p>IOPythonIOCPUPythonwebIOPython</p>\n<h2 id=\"IO--\"><a href=\"#IO--\" class=\"headerlink\" title=\"IO  \"></a>IO  </h2><p>CPUIOIO</p>\n<p>IOIOIONginxIOWebCPUCPUCPUCPUIO</p>\n<p>Python</p>\n<h2 id=\"Conclude\"><a href=\"#Conclude\" class=\"headerlink\" title=\"Conclude\"></a>Conclude</h2><p>PythonIO-</p>\n<p></p>\n<p>References:</p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/46368084\">Python</a></p>\n<p><a href=\"https://www.liaoxuefeng.com/wiki/1016959663602400/1017631469467456\"> vs  </a></p>\n<p><a href=\"https://python3-cookbook.readthedocs.io/zh_CN/latest/c12/p03_communicating_between_threads.html\"> Python3 CookBook</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>Python</p>\n<h2 id=\"-Process---Thread\"><a href=\"#-Process---Thread\" class=\"headerlink\" title=\"(Process)  (Thread)\"></a>(Process)  (Thread)</h2><blockquote>\n<p></p>\n<p></p>\n<p></p>\n</blockquote>\n<p>Master-Worker MasterWorkerPython</p>\n<p>ApacheOSOSOSIPv4  32 OSUnix/Linux forkWIndows</p>\n<p>CPUCacheCPU2CPUCPUUnix/LinuxCPUlscpuCPU(s)LinuxCPUCPU</p>\n<p>OSWindowsIISApache+RISC  CISCIntel x86 x64 CISCRISCRISCRISCCISCApacheIISNginxIOPython</p>\n<p></p>\n<blockquote>\n<ul>\n<li>CPU</li>\n<li>CPU: CPU()</li>\n<li>CPUCPU</li>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n<li>Mutual exclusion Mutex</li>\n<li>nn</li>\n<li>nSemaphore</li>\n<li>mutexsemaphoren=1mutex</li>\n</ul>\n</blockquote>\n<p><a href=\"http://www.ruanyifeng.com/blog/2013/04/processes_and_threads.html\"></a></p>\n<h2 id=\"Python-multiprocessing\"><a href=\"#Python-multiprocessing\" class=\"headerlink\" title=\"Python multiprocessing\"></a>Python multiprocessing</h2><p>$8^{20}$sleep 2s</p>\n<pre><code class=\"python\">import time\nimport os\n\ndef long_time_task():\n    print(&#39;: &#123;&#125;&#39;.format(os.getpid()))\n    time.sleep(2)\n    print(&quot;: &#123;&#125;&quot;.format(8 ** 20))\n\nif __name__ == &quot;__main__&quot;:\n    print(&#39;: &#123;&#125;&#39;.format(os.getpid()))\n    start = time.time()\n    for i in range(2):\n        long_time_task()\n\n    end = time.time()\n    print(&quot;&#123;&#125;&quot;.format((end-start)))\n\n: 33121\n: 33121\n: 1152921504606846976\n: 33121\n: 1152921504606846976\n4.004350185394287</code></pre>\n<p>sleep 4s</p>\n<p></p>\n<pre><code class=\"python\">from multiprocessing import Process\nimport os\nimport time\n\n\ndef long_time_task(i):\n    print(&#39;: &#123;&#125; - &#123;&#125;&#39;.format(os.getpid(), i))\n    time.sleep(2)\n    print(&quot;: &#123;&#125;&quot;.format(8 ** 20))\n\nif __name__==&#39;__main__&#39;:\n    print(&#39;: &#123;&#125;&#39;.format(os.getpid()))\n    start = time.time()\n    p1 = Process(target=long_time_task, args=(1,))\n    p2 = Process(target=long_time_task, args=(2,))\n    print(&#39;&#39;)\n    p1.start()\n    p2.start()\n    p1.join()\n    p2.join()\n    end = time.time()\n    print(&quot;&#123;&#125;&quot;.format((end - start)))\n\n: 33121\n\n: 34270 - 1\n: 34271 - 2\n: 1152921504606846976\n: 1152921504606846976\n2.009559392929077</code></pre>\n<p></p>\n<p>p.join()p.join()</p>\n<pre><code>: 33121\n\n: 34669 - 1\n0.002809762954711914\n: 34670 - 2\n: 1152921504606846976\n: 1152921504606846976</code></pre>\n<p>OSCPUProcessPool</p>\n<p>PoolPool</p>\n<p>multiprocessing Pool</p>\n<ol>\n<li>apply_async</li>\n</ol>\n<p>apply_async(func[, args=()[, kwds={}[, callback=None]]])</p>\n<p> </p>\n<ol start=\"2\">\n<li>map()</li>\n</ol>\n<p>map(func, iterable[, chunksize=None])</p>\n<p>Poolmapmap </p>\n<ol start=\"3\">\n<li>map_async()</li>\n</ol>\n<p>map_async(func, iterable[, chunksize[, callback]])<br>mapapply_async</p>\n<ol start=\"4\">\n<li>close()</li>\n</ol>\n<p>pool</p>\n<ol start=\"5\">\n<li>terminate()</li>\n</ol>\n<p></p>\n<ol start=\"6\">\n<li>join()</li>\n</ol>\n<p> joincloseterminate</p>\n<p>4Pool54</p>\n<pre><code class=\"python\">from multiprocessing import Pool, cpu_count\nimport os\nimport time\n\n\ndef long_time_task(i):\n    print(&#39;: &#123;&#125; - &#123;&#125;&#39;.format(os.getpid(), i))\n    time.sleep(2)\n    print(&quot;: &#123;&#125;&quot;.format(8 ** 20))\n\n\nif __name__==&#39;__main__&#39;:\n    print(&quot;CPU:&#123;&#125;&quot;.format(cpu_count()))\n    print(&#39;: &#123;&#125;&#39;.format(os.getpid()))\n    start = time.time()\n    p = Pool(4)\n    for i in range(5):\n        p.apply_async(long_time_task, args=(i,))\n    print(&#39;&#39;)\n    p.close()\n    p.join()\n    end = time.time()\n    print(&quot;&#123;&#125;&quot;.format((end - start)))\n\nCPU:64\n: 33121\n\n: 37454 - 0\n: 37455 - 1\n: 37456 - 2\n: 37457 - 3\n: 1152921504606846976\n: 1152921504606846976\n: 37454 - 4\n: 1152921504606846976\n: 1152921504606846976\n: 1152921504606846976\n4.115360736846924</code></pre>\n<p>42s+2s4s+</p>\n<p>PythonGILCPU</p>\n<p>Addmultiprocessing.Queue </p>\n<pre><code class=\"python\">from multiprocessing import Process, Queue\nimport os, time, random\n\n# :\ndef write(q):\n    print(&#39;Process to write: &#123;&#125;&#39;.format(os.getpid()))\n    for value in [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;]:\n        print(&#39;Put %s to queue...&#39; % value)\n        q.put(value)\n        time.sleep(random.random())\n\n# :\ndef read(q):\n    print(&#39;Process to read:&#123;&#125;&#39;.format(os.getpid()))\n    while True:\n        value = q.get(True)\n        print(&#39;Get %s from queue.&#39; % value)\n\nif __name__==&#39;__main__&#39;:\n    # Queue\n    q = Queue()\n    pw = Process(target=write, args=(q,))\n    pr = Process(target=read, args=(q,))\n    # pw:\n    pw.start()\n    # pr:\n    pr.start()\n    # pw:\n    pw.join()\n    # pr:\n    pr.terminate()\n\nProcess to write: 39190\nPut A to queue...\nProcess to read:39191\nGet A from queue.\nPut B to queue...\nGet B from queue.\nPut C to queue...\nGet C from queue.</code></pre>\n<p>##</p>\n<h2 id=\"Python--Threading\"><a href=\"#Python--Threading\" class=\"headerlink\" title=\"Python  Threading\"></a>Python  Threading</h2><p></p>\n<pre><code class=\"python\">import threading\nimport time\n\n\ndef long_time_task(i):\n    print(&#39;: &#123;&#125; - &#123;&#125;&#39;.format(threading.current_thread().name, i))\n    time.sleep(2)\n    print(&quot;: &#123;&#125;&quot;.format(8 ** 20))\n\n\nif __name__==&#39;__main__&#39;:\n    start = time.time()\n    print(&#39;&#123;&#125;&#39;.format(threading.current_thread().name))\n    t1 = threading.Thread(target=long_time_task, args=(1,))\n    t2 = threading.Thread(target=long_time_task, args=(2,))\n    t1.start()\n    t2.start()\n\n    t1.join()\n    t2.join()\n    end = time.time()\n    print(&quot;&#123;&#125;&quot;.format((end - start)))\n\nMainThread\n: Thread-1316 - 1\n: Thread-1317 - 2\n: 1152921504606846976\n: 1152921504606846976\n2.0029757022857666</code></pre>\n<p>GILsleep ,sleepIOGILsleepCPUCPU $8^{1000000}$</p>\n<pre><code class=\"python\">def long_time_task(i):\n    print(&#39;: &#123;&#125; - &#123;&#125;&#39;.format(threading.current_thread().name, i))\n    time.sleep(2)\n    t = time.time()\n    print(&quot;: &#123;&#125;&quot;.format(8 ** 1000000))\n    print(&#39; &#39;, time.time()-t)\n#  long_time_task(1)\n : 11.462863683700562\n13.43696641921997\n#  \n : 22.85654377937317\n : 23.088494300842285\n25.10121512413025\n</code></pre>\n<p>22s11s121222sPythonGIL</p>\n<p>queue.Queue</p>\n<pre><code class=\"python\">from queue import Queue\nimport random, threading, time\n\n\n# \nclass Producer(threading.Thread):\n    def __init__(self, name, queue):\n        threading.Thread.__init__(self, name=name)\n        self.queue = queue\n\n    def run(self):\n        for i in range(1, 5):\n            print(&quot;&#123;&#125; is producing &#123;&#125; to the queue!&quot;.format(self.getName(), i))\n            self.queue.put(i)\n            time.sleep(random.randrange(10) / 5)\n        print(&quot;%s finished!&quot; % self.getName())\n\n\n# \nclass Consumer(threading.Thread):\n    def __init__(self, name, queue):\n        threading.Thread.__init__(self, name=name)\n        self.queue = queue\n\n    def run(self):\n        for i in range(1, 5):\n            val = self.queue.get()\n            print(&quot;&#123;&#125; is consuming &#123;&#125; in the queue.&quot;.format(self.getName(), val))\n            time.sleep(random.randrange(10))\n        print(&quot;%s finished!&quot; % self.getName())\n\n\ndef main():\n    queue = Queue()\n    producer = Producer(&#39;Producer&#39;, queue)\n    consumer = Consumer(&#39;Consumer&#39;, queue)\n\n    producer.start()\n    consumer.start()\n\n    producer.join()\n    consumer.join()\n    print(&#39;All threads finished!&#39;)\n\n\nif __name__ == &#39;__main__&#39;:\n    main()</code></pre>\n<h2 id=\"-vs-IO\"><a href=\"#-vs-IO\" class=\"headerlink\" title=\" vs IO\"></a> vs IO</h2><p>pythonCPUPythonC  </p>\n<p>IOPythonIOCPUPythonwebIOPython</p>\n<h2 id=\"IO--\"><a href=\"#IO--\" class=\"headerlink\" title=\"IO  \"></a>IO  </h2><p>CPUIOIO</p>\n<p>IOIOIONginxIOWebCPUCPUCPUCPUIO</p>\n<p>Python</p>\n<h2 id=\"Conclude\"><a href=\"#Conclude\" class=\"headerlink\" title=\"Conclude\"></a>Conclude</h2><p>PythonIO-</p>\n<p></p>\n<p>References:</p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/46368084\">Python</a></p>\n<p><a href=\"https://www.liaoxuefeng.com/wiki/1016959663602400/1017631469467456\"> vs  </a></p>\n<p><a href=\"https://python3-cookbook.readthedocs.io/zh_CN/latest/c12/p03_communicating_between_threads.html\"> Python3 CookBook</a></p>\n"},{"title":"2020 - ","toc":true,"mathjax":true,"top":false,"cover":true,"date":"2021-01-04T08:06:49.000Z","updated":"2021-01-04T08:08:13.230Z","_content":"\n","source":"_drafts/2020-.md","raw":"---\ntitle: 2020 - \ntoc: true\nmathjax: true\ntop: false\ncover: true\ndate: 2021-01-04 16:06:49\nupdated:\ncategories: \ntags:\n\t- \n\t- \n---\n\n","slug":"2020-","published":0,"comments":1,"layout":"post","photos":[],"link":"","_id":"ckowlff4h0000ye2852873zj8","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"","toc":true,"mathjax":true,"top":false,"cover":true,"date":"2021-04-23T06:56:17.000Z","updated":"2021-05-10T02:53:15.929Z","_content":"\nBlog\n\n\n\n ~~~~\n\ngapBloggap****MADMAD****MADMADMAD \n\nBlogBlog\n\n\n\n","source":"_drafts/.md","raw":"---\ntitle: \ntoc: true\nmathjax: true\ntop: false\ncover: true\ndate: 2021-04-23 14:56:17\nupdated:\ncategories: \ntags: \n\t- \n---\n\nBlog\n\n\n\n ~~~~\n\ngapBloggap****MADMAD****MADMADMAD \n\nBlogBlog\n\n\n\n","slug":"","published":0,"comments":1,"layout":"post","photos":[],"link":"","_id":"ckowlff4j0001ye28a2r33w49","content":"<p>Blog</p>\n<p></p>\n<p> <del></del></p>\n<p>gapBloggap<strong></strong>MADMAD<strong></strong>MADMADMAD </p>\n<p>BlogBlog</p>\n","site":{"data":{}},"excerpt":"","more":"<p>Blog</p>\n<p></p>\n<p> <del></del></p>\n<p>gapBloggap<strong></strong>MADMAD<strong></strong>MADMADMAD </p>\n<p>BlogBlog</p>\n"},{"title":"996:","toc":true,"mathjax":true,"top":false,"cover":true,"date":"2021-03-19T06:23:00.000Z","updated":"2021-03-22T10:59:39.687Z","_content":"\nElon Musk  First-Principles Thinking \n\n\n\n","source":"_drafts/996-.md","raw":"---\ntitle: 996:\ntoc: true\nmathjax: true\ntop: false\ncover: true\ndate: 2021-03-19 14:23:00\nupdated:\ncategories: \ntags:\n\t- \n\t- \n\t- \n---\n\nElon Musk  First-Principles Thinking \n\n\n\n","slug":"996-","published":0,"comments":1,"layout":"post","photos":[],"link":"","_id":"ckowlff4o0003ye289kzd8aq8","content":"<p>Elon Musk  First-Principles Thinking </p>\n<p></p>\n","site":{"data":{}},"excerpt":"","more":"<p>Elon Musk  First-Principles Thinking </p>\n<p></p>\n"},{"title":"135 Candy","toc":true,"mathjax":true,"top":false,"cover":true,"date":"2021-01-13T07:59:39.000Z","updated":"2021-01-13T10:03:53.128Z","_content":"\n> There are *N* children standing in a line. Each child is assigned a rating value.\n>\n> You are giving candies to these children subjected to the following requirements:\n>\n> - Each child must have at least one candy.\n> - Children with a higher rating get more candies than their neighbors.\n>\n> What is the minimum candies you must give?\n>\n> **Example 1:**\n>\n> ```\n> Input: [1,0,2]\n> Output: 5\n> Explanation: You can allocate to the first, second and third child with 2, 1, 2 candies respectively.\n> ```\n>\n> **Example 2:**\n>\n> ```\n> Input: [1,2,2]\n> Output: 4\n> Explanation: You can allocate to the first, second and third child with 1, 2, 1 candies respectively.\n>              The third child gets 1 candy because it satisfies the above two conditions.\n> ```\n\nHardDiscuss LeetCode\n\n### \n\n/candycandy+1Peak \n\n/candy111candy_sum,peak_candy max(left,right) + 1rating2rating2candy_sum 2candy1\n\n bottom -> peak -> bottom -> equal bottom -> peak -> equal /equal candy_sum\n\n```python\ndef candy(self, ratings: List[int]) -> int:\n    length = len(ratings)\n    if length == 0:\n        return 0\n\n    start = 0\n    sum_candy = 1 # init previous round bottom sum =1, because -1 each round to correct bottom double count problem\n    i = 0\n    while i < length-1: # cur = i, next = i+1\n        # botton -> peak : peak not included\n        while i<length-1 and ratings[i] < ratings[i+1]:\n            i += 1\n        left = i - start\n        start = i\n        # peak -> next bottom : peak not included\n        while i<length-1 and ratings[i] > ratings[i+1]:\n            i += 1\n        right = i - start\n        start = i\n        # count peak_candy and sum_candy\n        peak_candy = max(left, right) + 1\n        sum_candy += (left+1)*left//2 + (right+1)*right//2 + peak_candy - 1 # - 1 because left bottom included by previous round\n        # handle equal \n        while i<length-1 and ratings[i] == ratings[i+1]:\n            i += 1\n            sum_candy += 1\n        start = i\n\n    return sum_candy\n```\n\nbottom -> peak -> bottom -> equal bottom bottomsum_candybottomcandy1sum_candy1bottomrating[0]\n\n\n\n### \n\ncandy1candycandycandy1ratingcandy1\n\ncandycandy\n\n```python\ndef candy(self, ratings: List[int]) -> int:\n    length = len(ratings)\n    if length == 0:\n        return 0\n\n    candys = [1]*length\n    pre = ratings[0]\n    for i in range(1, length):\n        cur = ratings[i]\n        if cur > pre:\n            candys[i] = candys[i-1]+1\n        pre = cur\n\n    post = ratings[-1]\n    for j in range(length-2,-1,-1):\n        cur = ratings[j]\n        if cur > post and candys[j] <= candys[j+1]:\n            candys[j] = candys[j+1] + 1\n        post = cur\n    return sum(candys)\n```\n\n\n\n### Conclusion\n\ncandy\n\n","source":"_posts/135-Candy.md","raw":"---\ntitle: 135 Candy\ntoc: true\nmathjax: true\ntop: false\ncover: true\ndate: 2021-01-13 15:59:39\nupdated:\ncategories: Algorithms\ntags:\n\t- Algorithms\n\t- LeetCode\n---\n\n> There are *N* children standing in a line. Each child is assigned a rating value.\n>\n> You are giving candies to these children subjected to the following requirements:\n>\n> - Each child must have at least one candy.\n> - Children with a higher rating get more candies than their neighbors.\n>\n> What is the minimum candies you must give?\n>\n> **Example 1:**\n>\n> ```\n> Input: [1,0,2]\n> Output: 5\n> Explanation: You can allocate to the first, second and third child with 2, 1, 2 candies respectively.\n> ```\n>\n> **Example 2:**\n>\n> ```\n> Input: [1,2,2]\n> Output: 4\n> Explanation: You can allocate to the first, second and third child with 1, 2, 1 candies respectively.\n>              The third child gets 1 candy because it satisfies the above two conditions.\n> ```\n\nHardDiscuss LeetCode\n\n### \n\n/candycandy+1Peak \n\n/candy111candy_sum,peak_candy max(left,right) + 1rating2rating2candy_sum 2candy1\n\n bottom -> peak -> bottom -> equal bottom -> peak -> equal /equal candy_sum\n\n```python\ndef candy(self, ratings: List[int]) -> int:\n    length = len(ratings)\n    if length == 0:\n        return 0\n\n    start = 0\n    sum_candy = 1 # init previous round bottom sum =1, because -1 each round to correct bottom double count problem\n    i = 0\n    while i < length-1: # cur = i, next = i+1\n        # botton -> peak : peak not included\n        while i<length-1 and ratings[i] < ratings[i+1]:\n            i += 1\n        left = i - start\n        start = i\n        # peak -> next bottom : peak not included\n        while i<length-1 and ratings[i] > ratings[i+1]:\n            i += 1\n        right = i - start\n        start = i\n        # count peak_candy and sum_candy\n        peak_candy = max(left, right) + 1\n        sum_candy += (left+1)*left//2 + (right+1)*right//2 + peak_candy - 1 # - 1 because left bottom included by previous round\n        # handle equal \n        while i<length-1 and ratings[i] == ratings[i+1]:\n            i += 1\n            sum_candy += 1\n        start = i\n\n    return sum_candy\n```\n\nbottom -> peak -> bottom -> equal bottom bottomsum_candybottomcandy1sum_candy1bottomrating[0]\n\n\n\n### \n\ncandy1candycandycandy1ratingcandy1\n\ncandycandy\n\n```python\ndef candy(self, ratings: List[int]) -> int:\n    length = len(ratings)\n    if length == 0:\n        return 0\n\n    candys = [1]*length\n    pre = ratings[0]\n    for i in range(1, length):\n        cur = ratings[i]\n        if cur > pre:\n            candys[i] = candys[i-1]+1\n        pre = cur\n\n    post = ratings[-1]\n    for j in range(length-2,-1,-1):\n        cur = ratings[j]\n        if cur > post and candys[j] <= candys[j+1]:\n            candys[j] = candys[j+1] + 1\n        post = cur\n    return sum(candys)\n```\n\n\n\n### Conclusion\n\ncandy\n\n","slug":"135-Candy","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"ckowlff4p0005ye28hvhw7t2d","content":"<blockquote>\n<p>There are <em>N</em> children standing in a line. Each child is assigned a rating value.</p>\n<p>You are giving candies to these children subjected to the following requirements:</p>\n<ul>\n<li>Each child must have at least one candy.</li>\n<li>Children with a higher rating get more candies than their neighbors.</li>\n</ul>\n<p>What is the minimum candies you must give?</p>\n<p><strong>Example 1:</strong></p>\n<pre><code>Input: [1,0,2]\nOutput: 5\nExplanation: You can allocate to the first, second and third child with 2, 1, 2 candies respectively.</code></pre>\n<p><strong>Example 2:</strong></p>\n<pre><code>Input: [1,2,2]\nOutput: 4\nExplanation: You can allocate to the first, second and third child with 1, 2, 1 candies respectively.\n             The third child gets 1 candy because it satisfies the above two conditions.</code></pre>\n</blockquote>\n<p>HardDiscuss LeetCode</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>/candycandy+1Peak </p>\n<p>/candy111candy_sum,peak_candy max(left,right) + 1rating2rating2candy_sum 2candy1</p>\n<p> bottom -&gt; peak -&gt; bottom -&gt; equal bottom -&gt; peak -&gt; equal /equal candy_sum</p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">candy</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> ratings<span class=\"token punctuation\">:</span> List<span class=\"token punctuation\">[</span>int<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> int<span class=\"token punctuation\">:</span>\n    length <span class=\"token operator\">=</span> len<span class=\"token punctuation\">(</span>ratings<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">if</span> length <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> <span class=\"token number\">0</span>\n\n    start <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n    sum_candy <span class=\"token operator\">=</span> <span class=\"token number\">1</span> <span class=\"token comment\" spellcheck=\"true\"># init previous round bottom sum =1, because -1 each round to correct bottom double count problem</span>\n    i <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n    <span class=\"token keyword\">while</span> i <span class=\"token operator\">&lt;</span> length<span class=\"token number\">-1</span><span class=\"token punctuation\">:</span> <span class=\"token comment\" spellcheck=\"true\"># cur = i, next = i+1</span>\n        <span class=\"token comment\" spellcheck=\"true\"># botton -> peak : peak not included</span>\n        <span class=\"token keyword\">while</span> i<span class=\"token operator\">&lt;</span>length<span class=\"token number\">-1</span> <span class=\"token operator\">and</span> ratings<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">&lt;</span> ratings<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n            i <span class=\"token operator\">+=</span> <span class=\"token number\">1</span>\n        left <span class=\"token operator\">=</span> i <span class=\"token operator\">-</span> start\n        start <span class=\"token operator\">=</span> i\n        <span class=\"token comment\" spellcheck=\"true\"># peak -> next bottom : peak not included</span>\n        <span class=\"token keyword\">while</span> i<span class=\"token operator\">&lt;</span>length<span class=\"token number\">-1</span> <span class=\"token operator\">and</span> ratings<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">></span> ratings<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n            i <span class=\"token operator\">+=</span> <span class=\"token number\">1</span>\n        right <span class=\"token operator\">=</span> i <span class=\"token operator\">-</span> start\n        start <span class=\"token operator\">=</span> i\n        <span class=\"token comment\" spellcheck=\"true\"># count peak_candy and sum_candy</span>\n        peak_candy <span class=\"token operator\">=</span> max<span class=\"token punctuation\">(</span>left<span class=\"token punctuation\">,</span> right<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token number\">1</span>\n        sum_candy <span class=\"token operator\">+=</span> <span class=\"token punctuation\">(</span>left<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token operator\">*</span>left<span class=\"token operator\">//</span><span class=\"token number\">2</span> <span class=\"token operator\">+</span> <span class=\"token punctuation\">(</span>right<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token operator\">*</span>right<span class=\"token operator\">//</span><span class=\"token number\">2</span> <span class=\"token operator\">+</span> peak_candy <span class=\"token operator\">-</span> <span class=\"token number\">1</span> <span class=\"token comment\" spellcheck=\"true\"># - 1 because left bottom included by previous round</span>\n        <span class=\"token comment\" spellcheck=\"true\"># handle equal </span>\n        <span class=\"token keyword\">while</span> i<span class=\"token operator\">&lt;</span>length<span class=\"token number\">-1</span> <span class=\"token operator\">and</span> ratings<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> ratings<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n            i <span class=\"token operator\">+=</span> <span class=\"token number\">1</span>\n            sum_candy <span class=\"token operator\">+=</span> <span class=\"token number\">1</span>\n        start <span class=\"token operator\">=</span> i\n\n    <span class=\"token keyword\">return</span> sum_candy</code></pre>\n<p>bottom -&gt; peak -&gt; bottom -&gt; equal bottom bottomsum_candybottomcandy1sum_candy1bottomrating[0]</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>candy1candycandycandy1ratingcandy1</p>\n<p>candycandy</p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">candy</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> ratings<span class=\"token punctuation\">:</span> List<span class=\"token punctuation\">[</span>int<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> int<span class=\"token punctuation\">:</span>\n    length <span class=\"token operator\">=</span> len<span class=\"token punctuation\">(</span>ratings<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">if</span> length <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> <span class=\"token number\">0</span>\n\n    candys <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token operator\">*</span>length\n    pre <span class=\"token operator\">=</span> ratings<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> length<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        cur <span class=\"token operator\">=</span> ratings<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">if</span> cur <span class=\"token operator\">></span> pre<span class=\"token punctuation\">:</span>\n            candys<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> candys<span class=\"token punctuation\">[</span>i<span class=\"token number\">-1</span><span class=\"token punctuation\">]</span><span class=\"token operator\">+</span><span class=\"token number\">1</span>\n        pre <span class=\"token operator\">=</span> cur\n\n    post <span class=\"token operator\">=</span> ratings<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">for</span> j <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span>length<span class=\"token number\">-2</span><span class=\"token punctuation\">,</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        cur <span class=\"token operator\">=</span> ratings<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">if</span> cur <span class=\"token operator\">></span> post <span class=\"token operator\">and</span> candys<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span> <span class=\"token operator\">&lt;=</span> candys<span class=\"token punctuation\">[</span>j<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n            candys<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> candys<span class=\"token punctuation\">[</span>j<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> <span class=\"token number\">1</span>\n        post <span class=\"token operator\">=</span> cur\n    <span class=\"token keyword\">return</span> sum<span class=\"token punctuation\">(</span>candys<span class=\"token punctuation\">)</span></code></pre>\n<h3 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h3><p>candy</p>\n<p></p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>There are <em>N</em> children standing in a line. Each child is assigned a rating value.</p>\n<p>You are giving candies to these children subjected to the following requirements:</p>\n<ul>\n<li>Each child must have at least one candy.</li>\n<li>Children with a higher rating get more candies than their neighbors.</li>\n</ul>\n<p>What is the minimum candies you must give?</p>\n<p><strong>Example 1:</strong></p>\n<pre><code>Input: [1,0,2]\nOutput: 5\nExplanation: You can allocate to the first, second and third child with 2, 1, 2 candies respectively.</code></pre>\n<p><strong>Example 2:</strong></p>\n<pre><code>Input: [1,2,2]\nOutput: 4\nExplanation: You can allocate to the first, second and third child with 1, 2, 1 candies respectively.\n             The third child gets 1 candy because it satisfies the above two conditions.</code></pre>\n</blockquote>\n<p>HardDiscuss LeetCode</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>/candycandy+1Peak </p>\n<p>/candy111candy_sum,peak_candy max(left,right) + 1rating2rating2candy_sum 2candy1</p>\n<p> bottom -&gt; peak -&gt; bottom -&gt; equal bottom -&gt; peak -&gt; equal /equal candy_sum</p>\n<pre><code class=\"python\">def candy(self, ratings: List[int]) -&gt; int:\n    length = len(ratings)\n    if length == 0:\n        return 0\n\n    start = 0\n    sum_candy = 1 # init previous round bottom sum =1, because -1 each round to correct bottom double count problem\n    i = 0\n    while i &lt; length-1: # cur = i, next = i+1\n        # botton -&gt; peak : peak not included\n        while i&lt;length-1 and ratings[i] &lt; ratings[i+1]:\n            i += 1\n        left = i - start\n        start = i\n        # peak -&gt; next bottom : peak not included\n        while i&lt;length-1 and ratings[i] &gt; ratings[i+1]:\n            i += 1\n        right = i - start\n        start = i\n        # count peak_candy and sum_candy\n        peak_candy = max(left, right) + 1\n        sum_candy += (left+1)*left//2 + (right+1)*right//2 + peak_candy - 1 # - 1 because left bottom included by previous round\n        # handle equal \n        while i&lt;length-1 and ratings[i] == ratings[i+1]:\n            i += 1\n            sum_candy += 1\n        start = i\n\n    return sum_candy</code></pre>\n<p>bottom -&gt; peak -&gt; bottom -&gt; equal bottom bottomsum_candybottomcandy1sum_candy1bottomrating[0]</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>candy1candycandycandy1ratingcandy1</p>\n<p>candycandy</p>\n<pre><code class=\"python\">def candy(self, ratings: List[int]) -&gt; int:\n    length = len(ratings)\n    if length == 0:\n        return 0\n\n    candys = [1]*length\n    pre = ratings[0]\n    for i in range(1, length):\n        cur = ratings[i]\n        if cur &gt; pre:\n            candys[i] = candys[i-1]+1\n        pre = cur\n\n    post = ratings[-1]\n    for j in range(length-2,-1,-1):\n        cur = ratings[j]\n        if cur &gt; post and candys[j] &lt;= candys[j+1]:\n            candys[j] = candys[j+1] + 1\n        post = cur\n    return sum(candys)</code></pre>\n<h3 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h3><p>candy</p>\n<p></p>\n"},{"title":"139 Word Break","toc":true,"mathjax":true,"top":false,"cover":true,"date":"2021-01-13T10:04:29.000Z","updated":"2021-01-14T08:29:29.193Z","_content":"\n> Given a **non-empty** string *s* and a dictionary *wordDict*containing a list of **non-empty** words, determine if *s* can be segmented into a space-separated sequence of one or more dictionary words.\n>\n> **Note:**\n>\n> - The same word in the dictionary may be reused multiple times in the segmentation.\n> - You may assume the dictionary does not contain duplicate words.\n>\n> **Example 1:**\n>\n> ```\n> Input: s = \"leetcode\", wordDict = [\"leet\", \"code\"]\n> Output: true\n> Explanation: Return true because \"leetcode\" can be segmented as \"leet code\".\n> ```\n>\n> **Example 2:**\n>\n> ```\n> Input: s = \"applepenapple\", wordDict = [\"apple\", \"pen\"]\n> Output: true\n> Explanation: Return true because \"applepenapple\" can be segmented as \"apple pen apple\".\n>              Note that you are allowed to reuse a dictionary word.\n> ```\n>\n> **Example 3:**\n>\n> ```\n> Input: s = \"catsandog\", wordDict = [\"cats\", \"dog\", \"sand\", \"and\", \"cat\"]\n> Output: false\n> ```\n\nMediumDFSTreeDFSTLEDFSDPDFSDP\n\n### DP\n\nDPDFSDFSDPDFSwordBreak True or False  substringwordDict\n\n$dp[i] = dp[i-j] \\cap (s[j:i] \\in wordDict), j \\in [0:i]$\n\nTrueTrue\n\n```python\ndef wordBreak(self, s: str, wordDict: List[str]) -> bool:\n    length = len(s)\n    if length == 0:\n        return False\n    set_words = set(wordDict)\n    set_words.update('')\n    dp = [True] + [False] * length # dp[i] mean s[ :i] can split in wordDict\n\n    for i in range(length+1):\n        for j in range(i):\n            if dp[j] and s[j:i] in set_words:\n                dp[i] = True\n                break\n\n    return dp[-1]\n```\n\n\n\n###  DFS TLE\n\nDFSsubstringsubstringwordDict\n\n```python\ndef wordBreak(self, s: str, wordDict: List[str]) -> bool:\n    if len(set(s)) > len(set(''.join(wordDict))):\n        return False\n    set_words = set(wordDict)\n    r = self.helper(s, set_words)\n    return r\n\ndef helper(self, s, set_words):\n    if s in set_words:\n        return True\n\n    for i in range(len(s),0,-1):\n        sub = s[ :i]\n        if sub in set_words:\n            if  self.helper(s[i: ], set_words):\n                return True\n\n    return False\n```\n\n### \n\n### Conclusion\n\nTreeDFSDFSDPDP","source":"_posts/139-Word-Break.md","raw":"---\ntitle: 139 Word Break\ntoc: true\nmathjax: true\ntop: false\ncover: true\ndate: 2021-01-13 18:04:29\nupdated:\ncategories: Algorithms\ntags:\n\t- Algorithms\n\t- LeetCode\n---\n\n> Given a **non-empty** string *s* and a dictionary *wordDict*containing a list of **non-empty** words, determine if *s* can be segmented into a space-separated sequence of one or more dictionary words.\n>\n> **Note:**\n>\n> - The same word in the dictionary may be reused multiple times in the segmentation.\n> - You may assume the dictionary does not contain duplicate words.\n>\n> **Example 1:**\n>\n> ```\n> Input: s = \"leetcode\", wordDict = [\"leet\", \"code\"]\n> Output: true\n> Explanation: Return true because \"leetcode\" can be segmented as \"leet code\".\n> ```\n>\n> **Example 2:**\n>\n> ```\n> Input: s = \"applepenapple\", wordDict = [\"apple\", \"pen\"]\n> Output: true\n> Explanation: Return true because \"applepenapple\" can be segmented as \"apple pen apple\".\n>              Note that you are allowed to reuse a dictionary word.\n> ```\n>\n> **Example 3:**\n>\n> ```\n> Input: s = \"catsandog\", wordDict = [\"cats\", \"dog\", \"sand\", \"and\", \"cat\"]\n> Output: false\n> ```\n\nMediumDFSTreeDFSTLEDFSDPDFSDP\n\n### DP\n\nDPDFSDFSDPDFSwordBreak True or False  substringwordDict\n\n$dp[i] = dp[i-j] \\cap (s[j:i] \\in wordDict), j \\in [0:i]$\n\nTrueTrue\n\n```python\ndef wordBreak(self, s: str, wordDict: List[str]) -> bool:\n    length = len(s)\n    if length == 0:\n        return False\n    set_words = set(wordDict)\n    set_words.update('')\n    dp = [True] + [False] * length # dp[i] mean s[ :i] can split in wordDict\n\n    for i in range(length+1):\n        for j in range(i):\n            if dp[j] and s[j:i] in set_words:\n                dp[i] = True\n                break\n\n    return dp[-1]\n```\n\n\n\n###  DFS TLE\n\nDFSsubstringsubstringwordDict\n\n```python\ndef wordBreak(self, s: str, wordDict: List[str]) -> bool:\n    if len(set(s)) > len(set(''.join(wordDict))):\n        return False\n    set_words = set(wordDict)\n    r = self.helper(s, set_words)\n    return r\n\ndef helper(self, s, set_words):\n    if s in set_words:\n        return True\n\n    for i in range(len(s),0,-1):\n        sub = s[ :i]\n        if sub in set_words:\n            if  self.helper(s[i: ], set_words):\n                return True\n\n    return False\n```\n\n### \n\n### Conclusion\n\nTreeDFSDFSDPDP","slug":"139-Word-Break","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"ckowlff4q0007ye28ellm242s","content":"<blockquote>\n<p>Given a <strong>non-empty</strong> string <em>s</em> and a dictionary <em>wordDict</em>containing a list of <strong>non-empty</strong> words, determine if <em>s</em> can be segmented into a space-separated sequence of one or more dictionary words.</p>\n<p><strong>Note:</strong></p>\n<ul>\n<li>The same word in the dictionary may be reused multiple times in the segmentation.</li>\n<li>You may assume the dictionary does not contain duplicate words.</li>\n</ul>\n<p><strong>Example 1:</strong></p>\n<pre><code>Input: s = &quot;leetcode&quot;, wordDict = [&quot;leet&quot;, &quot;code&quot;]\nOutput: true\nExplanation: Return true because &quot;leetcode&quot; can be segmented as &quot;leet code&quot;.</code></pre>\n<p><strong>Example 2:</strong></p>\n<pre><code>Input: s = &quot;applepenapple&quot;, wordDict = [&quot;apple&quot;, &quot;pen&quot;]\nOutput: true\nExplanation: Return true because &quot;applepenapple&quot; can be segmented as &quot;apple pen apple&quot;.\n             Note that you are allowed to reuse a dictionary word.</code></pre>\n<p><strong>Example 3:</strong></p>\n<pre><code>Input: s = &quot;catsandog&quot;, wordDict = [&quot;cats&quot;, &quot;dog&quot;, &quot;sand&quot;, &quot;and&quot;, &quot;cat&quot;]\nOutput: false</code></pre>\n</blockquote>\n<p>MediumDFSTreeDFSTLEDFSDPDFSDP</p>\n<h3 id=\"DP\"><a href=\"#DP\" class=\"headerlink\" title=\"DP\"></a>DP</h3><p>DPDFSDFSDPDFSwordBreak True or False  substringwordDict</p>\n<p>$dp[i] = dp[i-j] \\cap (s[j:i] \\in wordDict), j \\in [0:i]$</p>\n<p>TrueTrue</p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">wordBreak</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> s<span class=\"token punctuation\">:</span> str<span class=\"token punctuation\">,</span> wordDict<span class=\"token punctuation\">:</span> List<span class=\"token punctuation\">[</span>str<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> bool<span class=\"token punctuation\">:</span>\n    length <span class=\"token operator\">=</span> len<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">if</span> length <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> <span class=\"token boolean\">False</span>\n    set_words <span class=\"token operator\">=</span> set<span class=\"token punctuation\">(</span>wordDict<span class=\"token punctuation\">)</span>\n    set_words<span class=\"token punctuation\">.</span>update<span class=\"token punctuation\">(</span><span class=\"token string\">''</span><span class=\"token punctuation\">)</span>\n    dp <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> <span class=\"token punctuation\">[</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> length <span class=\"token comment\" spellcheck=\"true\"># dp[i] mean s[ :i] can split in wordDict</span>\n\n    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span>length<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">for</span> j <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span>i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">if</span> dp<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span> <span class=\"token operator\">and</span> s<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">:</span>i<span class=\"token punctuation\">]</span> <span class=\"token keyword\">in</span> set_words<span class=\"token punctuation\">:</span>\n                dp<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span>\n                <span class=\"token keyword\">break</span>\n\n    <span class=\"token keyword\">return</span> dp<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span></code></pre>\n<h3 id=\"-DFS-TLE\"><a href=\"#-DFS-TLE\" class=\"headerlink\" title=\" DFS TLE\"></a> DFS TLE</h3><p>DFSsubstringsubstringwordDict</p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">wordBreak</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> s<span class=\"token punctuation\">:</span> str<span class=\"token punctuation\">,</span> wordDict<span class=\"token punctuation\">:</span> List<span class=\"token punctuation\">[</span>str<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> bool<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">if</span> len<span class=\"token punctuation\">(</span>set<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">></span> len<span class=\"token punctuation\">(</span>set<span class=\"token punctuation\">(</span><span class=\"token string\">''</span><span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>wordDict<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> <span class=\"token boolean\">False</span>\n    set_words <span class=\"token operator\">=</span> set<span class=\"token punctuation\">(</span>wordDict<span class=\"token punctuation\">)</span>\n    r <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>helper<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">,</span> set_words<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> r\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">helper</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> s<span class=\"token punctuation\">,</span> set_words<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">if</span> s <span class=\"token keyword\">in</span> set_words<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> <span class=\"token boolean\">True</span>\n\n    <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span>len<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        sub <span class=\"token operator\">=</span> s<span class=\"token punctuation\">[</span> <span class=\"token punctuation\">:</span>i<span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">if</span> sub <span class=\"token keyword\">in</span> set_words<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">if</span>  self<span class=\"token punctuation\">.</span>helper<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">:</span> <span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> set_words<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n                <span class=\"token keyword\">return</span> <span class=\"token boolean\">True</span>\n\n    <span class=\"token keyword\">return</span> <span class=\"token boolean\">False</span></code></pre>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><h3 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h3><p>TreeDFSDFSDPDP</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>Given a <strong>non-empty</strong> string <em>s</em> and a dictionary <em>wordDict</em>containing a list of <strong>non-empty</strong> words, determine if <em>s</em> can be segmented into a space-separated sequence of one or more dictionary words.</p>\n<p><strong>Note:</strong></p>\n<ul>\n<li>The same word in the dictionary may be reused multiple times in the segmentation.</li>\n<li>You may assume the dictionary does not contain duplicate words.</li>\n</ul>\n<p><strong>Example 1:</strong></p>\n<pre><code>Input: s = &quot;leetcode&quot;, wordDict = [&quot;leet&quot;, &quot;code&quot;]\nOutput: true\nExplanation: Return true because &quot;leetcode&quot; can be segmented as &quot;leet code&quot;.</code></pre>\n<p><strong>Example 2:</strong></p>\n<pre><code>Input: s = &quot;applepenapple&quot;, wordDict = [&quot;apple&quot;, &quot;pen&quot;]\nOutput: true\nExplanation: Return true because &quot;applepenapple&quot; can be segmented as &quot;apple pen apple&quot;.\n             Note that you are allowed to reuse a dictionary word.</code></pre>\n<p><strong>Example 3:</strong></p>\n<pre><code>Input: s = &quot;catsandog&quot;, wordDict = [&quot;cats&quot;, &quot;dog&quot;, &quot;sand&quot;, &quot;and&quot;, &quot;cat&quot;]\nOutput: false</code></pre>\n</blockquote>\n<p>MediumDFSTreeDFSTLEDFSDPDFSDP</p>\n<h3 id=\"DP\"><a href=\"#DP\" class=\"headerlink\" title=\"DP\"></a>DP</h3><p>DPDFSDFSDPDFSwordBreak True or False  substringwordDict</p>\n<p>$dp[i] = dp[i-j] \\cap (s[j:i] \\in wordDict), j \\in [0:i]$</p>\n<p>TrueTrue</p>\n<pre><code class=\"python\">def wordBreak(self, s: str, wordDict: List[str]) -&gt; bool:\n    length = len(s)\n    if length == 0:\n        return False\n    set_words = set(wordDict)\n    set_words.update(&#39;&#39;)\n    dp = [True] + [False] * length # dp[i] mean s[ :i] can split in wordDict\n\n    for i in range(length+1):\n        for j in range(i):\n            if dp[j] and s[j:i] in set_words:\n                dp[i] = True\n                break\n\n    return dp[-1]</code></pre>\n<h3 id=\"-DFS-TLE\"><a href=\"#-DFS-TLE\" class=\"headerlink\" title=\" DFS TLE\"></a> DFS TLE</h3><p>DFSsubstringsubstringwordDict</p>\n<pre><code class=\"python\">def wordBreak(self, s: str, wordDict: List[str]) -&gt; bool:\n    if len(set(s)) &gt; len(set(&#39;&#39;.join(wordDict))):\n        return False\n    set_words = set(wordDict)\n    r = self.helper(s, set_words)\n    return r\n\ndef helper(self, s, set_words):\n    if s in set_words:\n        return True\n\n    for i in range(len(s),0,-1):\n        sub = s[ :i]\n        if sub in set_words:\n            if  self.helper(s[i: ], set_words):\n                return True\n\n    return False</code></pre>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><h3 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h3><p>TreeDFSDFSDPDP</p>\n"},{"title":"146 LRU Cache","toc":true,"mathjax":true,"top":false,"cover":true,"date":"2021-01-13T10:08:17.000Z","updated":"2021-01-21T07:23:17.970Z","_content":"\n> Design a data structure that follows the constraints of a **[Least Recently Used (LRU) cache](https://en.wikipedia.org/wiki/Cache_replacement_policies#LRU)**.\n>\n> Implement the `LRUCache` class:\n>\n> - `LRUCache(int capacity)` Initialize the LRU cache with **positive** size `capacity`.\n> - `int get(int key)` Return the value of the `key` if the key exists, otherwise return `-1`.\n> - `void put(int key, int value)` Update the value of the `key` if the `key` exists. Otherwise, add the `key-value` pair to the cache. If the number of keys exceeds the `capacity` from this operation, **evict** the least recently used key.\n>\n> **Follow up:**\n> Could you do `get` and `put` in `O(1)` time complexity?\n>\n>  \n>\n> **Example 1:**\n>\n> ```\n> Input\n> [\"LRUCache\", \"put\", \"put\", \"get\", \"put\", \"get\", \"put\", \"get\", \"get\", \"get\"]\n> [[2], [1, 1], [2, 2], [1], [3, 3], [2], [4, 4], [1], [3], [4]]\n> Output\n> [null, null, null, 1, null, -1, null, -1, 3, 4]\n> \n> Explanation\n> LRUCache lRUCache = new LRUCache(2);\n> lRUCache.put(1, 1); // cache is {1=1}\n> lRUCache.put(2, 2); // cache is {1=1, 2=2}\n> lRUCache.get(1);    // return 1\n> lRUCache.put(3, 3); // LRU key was 2, evicts key 2, cache is {1=1, 3=3}\n> lRUCache.get(2);    // returns -1 (not found)\n> lRUCache.put(4, 4); // LRU key was 1, evicts key 1, cache is {4=4, 3=3}\n> lRUCache.get(1);    // return -1 (not found)\n> lRUCache.get(3);    // return 3\n> lRUCache.get(4);    // return 4\n> ```\n>\n>  \n>\n> **Constraints:**\n>\n> - `1 <= capacity <= 3000`\n> - `0 <= key <= 3000`\n> - `0 <= value <= 104`\n> - At most `3 * 104` calls will be made to `get` and `put`.\n\nMeidumACDiscuss\n\n###  \n\nACnodeprenode get/put debugpop,append,getPreNodeget/putAC\n\n```python\nclass LRUCache:\n\n    def __init__(self, capacity: int):\n        self.key2prenode = {}\n        self.node2key = {}\n        self.root =  ListNode()\n        self.tail = self.root\n        self.size = 0\n        self.capacity = capacity\n\n    def pop(self):\n        if self.size < 1:\n            return\n        cur = self.root.next\n        post = cur.next\n        self.root.next = post\n        if cur in self.node2key:\n            key = self.node2key[cur]\n            self.key2prenode.pop(key)\n            self.node2key.pop(cur)\n\n        if post in self.node2key:\n            post_key = self.node2key[post]\n            self.key2prenode[post_key] = self.root\n\n        return\n\n    def append(self, key, value):\n        node = ListNode(value)\n        self.key2prenode[key] = self.tail\n        self.node2key[node] = key\n        self.tail.next = node\n        self.tail = node\n        return\n\n    def getPreNode(self, key):\n        if key in self.key2prenode:\n            return self.key2prenode[key]\n        return None\n    \n    def update(self, prenode):\n        if prenode == None or prenode.next == None:\n            return \n        cur = prenode.next\n        post = cur.next\n        if cur == self.tail:\n            return\n\n        tail_old = self.tail\n        self.tail.next = cur\n        cur.next = None\n        self.tail = cur\n        if cur in self.node2key:\n            key = self.node2key[cur]\n            self.key2prenode[key] = tail_old\n        prenode.next = post\n        if post in self.node2key:\n            post_key = self.node2key[post]\n            self.key2prenode[post_key] = prenode\n        return\n\n    def get(self, key: int) -> int:\n        pre = self.getPreNode(key)\n        if pre == None or pre.next == None:\n            return -1\n        else:\n            val = pre.next.val\n            self.update(pre)\n            return val\n        \n    def put(self, key: int, value: int) -> None:\n        pre = self.getPreNode(key)\n        if pre == None or pre.next == None:\n            if self.size == self.capacity:\n                self.pop()\n                self.append(key, value)\n            else:\n                self.append(key, value)\n                self.size += 1\n        else:\n            pre.next.val = value\n            self.update(pre)\n            \n        return\n```\n\npre node\n\n###  \n\nvaluekey+valuekey2Prenode , node2keyPythonpre\n\n```python\nclass BiListNode:\n    def __init__(self, key=None, value=None):\n        self.key = key\n        self.value = value\n        self.pre = None\n        self.next = None\n\nclass LRUCache_Bi:\n    def __init__(self, capacity) :\n        self.capacity = capacity\n        self.size = 0\n        self.hash = dict()\n        self.head = BiListNode()\n        self.tail = BiListNode()\n        self.head.pre, self.head.next = None, self.tail\n        self.tail.pre, self.tail.next = self.head, None\n\n    def get(self, key):\n        value = -1\n        if key in self.hash:\n            node = self.hash[key]\n            value = node.value\n            self.remove_node(node)\n            self.add_to_head(node)\n        return value\n    \n    def put(self, key, value):\n        if self.capacity == 0:\n            return\n        if key in self.hash:\n            node = self.hash[key]\n            self.remove_node(node)\n            self.add_to_head(node)\n            node.value = value\n            return\n        if self.size == self.capacity:\n            node = self.tail.pre\n            self.remove_node(node)\n\n        newNode = BiListNode(key, value)\n        self.add_to_head(newNode)\n        return\n\n    def add_to_head(self, node):\n        post = self.head.next\n        post.pre = node\n        node.next = post\n        self.head.next = node\n        node.pre = self.head\n        self.hash[node.key] = node\n        self.size += 1\n        return\n\n    def remove_node(self, node):\n        pre, post = node.pre, node.next\n        pre.next, post.pre = post, pre\n        self.hash.pop(node.key)\n        self.size -= 1\n        return\n```\n\nget/putadd_to_head , remove_node append, remove get/puttailnodeheadnodehashkey2node\n\n\n\n### Conclusion\n\nLeetCode\n\n","source":"_posts/146-LRU-Cache.md","raw":"---\ntitle: 146 LRU Cache\ntoc: true\nmathjax: true\ntop: false\ncover: true\ndate: 2021-01-13 18:08:17\nupdated:\ncategories:\ntags:\n---\n\n> Design a data structure that follows the constraints of a **[Least Recently Used (LRU) cache](https://en.wikipedia.org/wiki/Cache_replacement_policies#LRU)**.\n>\n> Implement the `LRUCache` class:\n>\n> - `LRUCache(int capacity)` Initialize the LRU cache with **positive** size `capacity`.\n> - `int get(int key)` Return the value of the `key` if the key exists, otherwise return `-1`.\n> - `void put(int key, int value)` Update the value of the `key` if the `key` exists. Otherwise, add the `key-value` pair to the cache. If the number of keys exceeds the `capacity` from this operation, **evict** the least recently used key.\n>\n> **Follow up:**\n> Could you do `get` and `put` in `O(1)` time complexity?\n>\n>  \n>\n> **Example 1:**\n>\n> ```\n> Input\n> [\"LRUCache\", \"put\", \"put\", \"get\", \"put\", \"get\", \"put\", \"get\", \"get\", \"get\"]\n> [[2], [1, 1], [2, 2], [1], [3, 3], [2], [4, 4], [1], [3], [4]]\n> Output\n> [null, null, null, 1, null, -1, null, -1, 3, 4]\n> \n> Explanation\n> LRUCache lRUCache = new LRUCache(2);\n> lRUCache.put(1, 1); // cache is {1=1}\n> lRUCache.put(2, 2); // cache is {1=1, 2=2}\n> lRUCache.get(1);    // return 1\n> lRUCache.put(3, 3); // LRU key was 2, evicts key 2, cache is {1=1, 3=3}\n> lRUCache.get(2);    // returns -1 (not found)\n> lRUCache.put(4, 4); // LRU key was 1, evicts key 1, cache is {4=4, 3=3}\n> lRUCache.get(1);    // return -1 (not found)\n> lRUCache.get(3);    // return 3\n> lRUCache.get(4);    // return 4\n> ```\n>\n>  \n>\n> **Constraints:**\n>\n> - `1 <= capacity <= 3000`\n> - `0 <= key <= 3000`\n> - `0 <= value <= 104`\n> - At most `3 * 104` calls will be made to `get` and `put`.\n\nMeidumACDiscuss\n\n###  \n\nACnodeprenode get/put debugpop,append,getPreNodeget/putAC\n\n```python\nclass LRUCache:\n\n    def __init__(self, capacity: int):\n        self.key2prenode = {}\n        self.node2key = {}\n        self.root =  ListNode()\n        self.tail = self.root\n        self.size = 0\n        self.capacity = capacity\n\n    def pop(self):\n        if self.size < 1:\n            return\n        cur = self.root.next\n        post = cur.next\n        self.root.next = post\n        if cur in self.node2key:\n            key = self.node2key[cur]\n            self.key2prenode.pop(key)\n            self.node2key.pop(cur)\n\n        if post in self.node2key:\n            post_key = self.node2key[post]\n            self.key2prenode[post_key] = self.root\n\n        return\n\n    def append(self, key, value):\n        node = ListNode(value)\n        self.key2prenode[key] = self.tail\n        self.node2key[node] = key\n        self.tail.next = node\n        self.tail = node\n        return\n\n    def getPreNode(self, key):\n        if key in self.key2prenode:\n            return self.key2prenode[key]\n        return None\n    \n    def update(self, prenode):\n        if prenode == None or prenode.next == None:\n            return \n        cur = prenode.next\n        post = cur.next\n        if cur == self.tail:\n            return\n\n        tail_old = self.tail\n        self.tail.next = cur\n        cur.next = None\n        self.tail = cur\n        if cur in self.node2key:\n            key = self.node2key[cur]\n            self.key2prenode[key] = tail_old\n        prenode.next = post\n        if post in self.node2key:\n            post_key = self.node2key[post]\n            self.key2prenode[post_key] = prenode\n        return\n\n    def get(self, key: int) -> int:\n        pre = self.getPreNode(key)\n        if pre == None or pre.next == None:\n            return -1\n        else:\n            val = pre.next.val\n            self.update(pre)\n            return val\n        \n    def put(self, key: int, value: int) -> None:\n        pre = self.getPreNode(key)\n        if pre == None or pre.next == None:\n            if self.size == self.capacity:\n                self.pop()\n                self.append(key, value)\n            else:\n                self.append(key, value)\n                self.size += 1\n        else:\n            pre.next.val = value\n            self.update(pre)\n            \n        return\n```\n\npre node\n\n###  \n\nvaluekey+valuekey2Prenode , node2keyPythonpre\n\n```python\nclass BiListNode:\n    def __init__(self, key=None, value=None):\n        self.key = key\n        self.value = value\n        self.pre = None\n        self.next = None\n\nclass LRUCache_Bi:\n    def __init__(self, capacity) :\n        self.capacity = capacity\n        self.size = 0\n        self.hash = dict()\n        self.head = BiListNode()\n        self.tail = BiListNode()\n        self.head.pre, self.head.next = None, self.tail\n        self.tail.pre, self.tail.next = self.head, None\n\n    def get(self, key):\n        value = -1\n        if key in self.hash:\n            node = self.hash[key]\n            value = node.value\n            self.remove_node(node)\n            self.add_to_head(node)\n        return value\n    \n    def put(self, key, value):\n        if self.capacity == 0:\n            return\n        if key in self.hash:\n            node = self.hash[key]\n            self.remove_node(node)\n            self.add_to_head(node)\n            node.value = value\n            return\n        if self.size == self.capacity:\n            node = self.tail.pre\n            self.remove_node(node)\n\n        newNode = BiListNode(key, value)\n        self.add_to_head(newNode)\n        return\n\n    def add_to_head(self, node):\n        post = self.head.next\n        post.pre = node\n        node.next = post\n        self.head.next = node\n        node.pre = self.head\n        self.hash[node.key] = node\n        self.size += 1\n        return\n\n    def remove_node(self, node):\n        pre, post = node.pre, node.next\n        pre.next, post.pre = post, pre\n        self.hash.pop(node.key)\n        self.size -= 1\n        return\n```\n\nget/putadd_to_head , remove_node append, remove get/puttailnodeheadnodehashkey2node\n\n\n\n### Conclusion\n\nLeetCode\n\n","slug":"146-LRU-Cache","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"ckowlff4r000bye28987c808r","content":"<blockquote>\n<p>Design a data structure that follows the constraints of a <strong><a href=\"https://en.wikipedia.org/wiki/Cache_replacement_policies#LRU\">Least Recently Used (LRU) cache</a></strong>.</p>\n<p>Implement the <code>LRUCache</code> class:</p>\n<ul>\n<li><code>LRUCache(int capacity)</code> Initialize the LRU cache with <strong>positive</strong> size <code>capacity</code>.</li>\n<li><code>int get(int key)</code> Return the value of the <code>key</code> if the key exists, otherwise return <code>-1</code>.</li>\n<li><code>void put(int key, int value)</code> Update the value of the <code>key</code> if the <code>key</code> exists. Otherwise, add the <code>key-value</code> pair to the cache. If the number of keys exceeds the <code>capacity</code> from this operation, <strong>evict</strong> the least recently used key.</li>\n</ul>\n<p><strong>Follow up:</strong><br>Could you do <code>get</code> and <code>put</code> in <code>O(1)</code> time complexity?</p>\n<p><strong>Example 1:</strong></p>\n<pre><code>Input\n[&quot;LRUCache&quot;, &quot;put&quot;, &quot;put&quot;, &quot;get&quot;, &quot;put&quot;, &quot;get&quot;, &quot;put&quot;, &quot;get&quot;, &quot;get&quot;, &quot;get&quot;]\n[[2], [1, 1], [2, 2], [1], [3, 3], [2], [4, 4], [1], [3], [4]]\nOutput\n[null, null, null, 1, null, -1, null, -1, 3, 4]\n\nExplanation\nLRUCache lRUCache = new LRUCache(2);\nlRUCache.put(1, 1); // cache is &#123;1=1&#125;\nlRUCache.put(2, 2); // cache is &#123;1=1, 2=2&#125;\nlRUCache.get(1);    // return 1\nlRUCache.put(3, 3); // LRU key was 2, evicts key 2, cache is &#123;1=1, 3=3&#125;\nlRUCache.get(2);    // returns -1 (not found)\nlRUCache.put(4, 4); // LRU key was 1, evicts key 1, cache is &#123;4=4, 3=3&#125;\nlRUCache.get(1);    // return -1 (not found)\nlRUCache.get(3);    // return 3\nlRUCache.get(4);    // return 4</code></pre>\n<p><strong>Constraints:</strong></p>\n<ul>\n<li><code>1 &lt;= capacity &lt;= 3000</code></li>\n<li><code>0 &lt;= key &lt;= 3000</code></li>\n<li><code>0 &lt;= value &lt;= 104</code></li>\n<li>At most <code>3 * 104</code> calls will be made to <code>get</code> and <code>put</code>.</li>\n</ul>\n</blockquote>\n<p>MeidumACDiscuss</p>\n<h3 id=\"-\"><a href=\"#-\" class=\"headerlink\" title=\" \"></a> </h3><p>ACnodeprenode get/put debugpop,append,getPreNodeget/putAC</p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">LRUCache</span><span class=\"token punctuation\">:</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> capacity<span class=\"token punctuation\">:</span> int<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>key2prenode <span class=\"token operator\">=</span> <span class=\"token operator\">&amp;</span><span class=\"token comment\" spellcheck=\"true\">#123;&amp;#125;</span>\n        self<span class=\"token punctuation\">.</span>node2key <span class=\"token operator\">=</span> <span class=\"token operator\">&amp;</span><span class=\"token comment\" spellcheck=\"true\">#123;&amp;#125;</span>\n        self<span class=\"token punctuation\">.</span>root <span class=\"token operator\">=</span>  ListNode<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>tail <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>root\n        self<span class=\"token punctuation\">.</span>size <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n        self<span class=\"token punctuation\">.</span>capacity <span class=\"token operator\">=</span> capacity\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">pop</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> self<span class=\"token punctuation\">.</span>size <span class=\"token operator\">&lt;</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span>\n        cur <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>root<span class=\"token punctuation\">.</span>next\n        post <span class=\"token operator\">=</span> cur<span class=\"token punctuation\">.</span>next\n        self<span class=\"token punctuation\">.</span>root<span class=\"token punctuation\">.</span>next <span class=\"token operator\">=</span> post\n        <span class=\"token keyword\">if</span> cur <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>node2key<span class=\"token punctuation\">:</span>\n            key <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>node2key<span class=\"token punctuation\">[</span>cur<span class=\"token punctuation\">]</span>\n            self<span class=\"token punctuation\">.</span>key2prenode<span class=\"token punctuation\">.</span>pop<span class=\"token punctuation\">(</span>key<span class=\"token punctuation\">)</span>\n            self<span class=\"token punctuation\">.</span>node2key<span class=\"token punctuation\">.</span>pop<span class=\"token punctuation\">(</span>cur<span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">if</span> post <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>node2key<span class=\"token punctuation\">:</span>\n            post_key <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>node2key<span class=\"token punctuation\">[</span>post<span class=\"token punctuation\">]</span>\n            self<span class=\"token punctuation\">.</span>key2prenode<span class=\"token punctuation\">[</span>post_key<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>root\n\n        <span class=\"token keyword\">return</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">append</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> key<span class=\"token punctuation\">,</span> value<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        node <span class=\"token operator\">=</span> ListNode<span class=\"token punctuation\">(</span>value<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>key2prenode<span class=\"token punctuation\">[</span>key<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>tail\n        self<span class=\"token punctuation\">.</span>node2key<span class=\"token punctuation\">[</span>node<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> key\n        self<span class=\"token punctuation\">.</span>tail<span class=\"token punctuation\">.</span>next <span class=\"token operator\">=</span> node\n        self<span class=\"token punctuation\">.</span>tail <span class=\"token operator\">=</span> node\n        <span class=\"token keyword\">return</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">getPreNode</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> key<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> key <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>key2prenode<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>key2prenode<span class=\"token punctuation\">[</span>key<span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">return</span> None\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">update</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> prenode<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> prenode <span class=\"token operator\">==</span> None <span class=\"token operator\">or</span> prenode<span class=\"token punctuation\">.</span>next <span class=\"token operator\">==</span> None<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span> \n        cur <span class=\"token operator\">=</span> prenode<span class=\"token punctuation\">.</span>next\n        post <span class=\"token operator\">=</span> cur<span class=\"token punctuation\">.</span>next\n        <span class=\"token keyword\">if</span> cur <span class=\"token operator\">==</span> self<span class=\"token punctuation\">.</span>tail<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span>\n\n        tail_old <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>tail\n        self<span class=\"token punctuation\">.</span>tail<span class=\"token punctuation\">.</span>next <span class=\"token operator\">=</span> cur\n        cur<span class=\"token punctuation\">.</span>next <span class=\"token operator\">=</span> None\n        self<span class=\"token punctuation\">.</span>tail <span class=\"token operator\">=</span> cur\n        <span class=\"token keyword\">if</span> cur <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>node2key<span class=\"token punctuation\">:</span>\n            key <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>node2key<span class=\"token punctuation\">[</span>cur<span class=\"token punctuation\">]</span>\n            self<span class=\"token punctuation\">.</span>key2prenode<span class=\"token punctuation\">[</span>key<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> tail_old\n        prenode<span class=\"token punctuation\">.</span>next <span class=\"token operator\">=</span> post\n        <span class=\"token keyword\">if</span> post <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>node2key<span class=\"token punctuation\">:</span>\n            post_key <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>node2key<span class=\"token punctuation\">[</span>post<span class=\"token punctuation\">]</span>\n            self<span class=\"token punctuation\">.</span>key2prenode<span class=\"token punctuation\">[</span>post_key<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> prenode\n        <span class=\"token keyword\">return</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">get</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> key<span class=\"token punctuation\">:</span> int<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> int<span class=\"token punctuation\">:</span>\n        pre <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>getPreNode<span class=\"token punctuation\">(</span>key<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> pre <span class=\"token operator\">==</span> None <span class=\"token operator\">or</span> pre<span class=\"token punctuation\">.</span>next <span class=\"token operator\">==</span> None<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span>\n        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n            val <span class=\"token operator\">=</span> pre<span class=\"token punctuation\">.</span>next<span class=\"token punctuation\">.</span>val\n            self<span class=\"token punctuation\">.</span>update<span class=\"token punctuation\">(</span>pre<span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">return</span> val\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">put</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> key<span class=\"token punctuation\">:</span> int<span class=\"token punctuation\">,</span> value<span class=\"token punctuation\">:</span> int<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> None<span class=\"token punctuation\">:</span>\n        pre <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>getPreNode<span class=\"token punctuation\">(</span>key<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> pre <span class=\"token operator\">==</span> None <span class=\"token operator\">or</span> pre<span class=\"token punctuation\">.</span>next <span class=\"token operator\">==</span> None<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">if</span> self<span class=\"token punctuation\">.</span>size <span class=\"token operator\">==</span> self<span class=\"token punctuation\">.</span>capacity<span class=\"token punctuation\">:</span>\n                self<span class=\"token punctuation\">.</span>pop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n                self<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>key<span class=\"token punctuation\">,</span> value<span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n                self<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>key<span class=\"token punctuation\">,</span> value<span class=\"token punctuation\">)</span>\n                self<span class=\"token punctuation\">.</span>size <span class=\"token operator\">+=</span> <span class=\"token number\">1</span>\n        <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n            pre<span class=\"token punctuation\">.</span>next<span class=\"token punctuation\">.</span>val <span class=\"token operator\">=</span> value\n            self<span class=\"token punctuation\">.</span>update<span class=\"token punctuation\">(</span>pre<span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">return</span></code></pre>\n<p>pre node</p>\n<h3 id=\"-\"><a href=\"#-\" class=\"headerlink\" title=\" \"></a> </h3><p>valuekey+valuekey2Prenode , node2keyPythonpre</p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">BiListNode</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> key<span class=\"token operator\">=</span>None<span class=\"token punctuation\">,</span> value<span class=\"token operator\">=</span>None<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>key <span class=\"token operator\">=</span> key\n        self<span class=\"token punctuation\">.</span>value <span class=\"token operator\">=</span> value\n        self<span class=\"token punctuation\">.</span>pre <span class=\"token operator\">=</span> None\n        self<span class=\"token punctuation\">.</span>next <span class=\"token operator\">=</span> None\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">LRUCache_Bi</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> capacity<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>capacity <span class=\"token operator\">=</span> capacity\n        self<span class=\"token punctuation\">.</span>size <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n        self<span class=\"token punctuation\">.</span>hash <span class=\"token operator\">=</span> dict<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>head <span class=\"token operator\">=</span> BiListNode<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>tail <span class=\"token operator\">=</span> BiListNode<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">.</span>pre<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">.</span>next <span class=\"token operator\">=</span> None<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>tail\n        self<span class=\"token punctuation\">.</span>tail<span class=\"token punctuation\">.</span>pre<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>tail<span class=\"token punctuation\">.</span>next <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">,</span> None\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">get</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> key<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        value <span class=\"token operator\">=</span> <span class=\"token operator\">-</span><span class=\"token number\">1</span>\n        <span class=\"token keyword\">if</span> key <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>hash<span class=\"token punctuation\">:</span>\n            node <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>hash<span class=\"token punctuation\">[</span>key<span class=\"token punctuation\">]</span>\n            value <span class=\"token operator\">=</span> node<span class=\"token punctuation\">.</span>value\n            self<span class=\"token punctuation\">.</span>remove_node<span class=\"token punctuation\">(</span>node<span class=\"token punctuation\">)</span>\n            self<span class=\"token punctuation\">.</span>add_to_head<span class=\"token punctuation\">(</span>node<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> value\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">put</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> key<span class=\"token punctuation\">,</span> value<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> self<span class=\"token punctuation\">.</span>capacity <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span>\n        <span class=\"token keyword\">if</span> key <span class=\"token keyword\">in</span> self<span class=\"token punctuation\">.</span>hash<span class=\"token punctuation\">:</span>\n            node <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>hash<span class=\"token punctuation\">[</span>key<span class=\"token punctuation\">]</span>\n            self<span class=\"token punctuation\">.</span>remove_node<span class=\"token punctuation\">(</span>node<span class=\"token punctuation\">)</span>\n            self<span class=\"token punctuation\">.</span>add_to_head<span class=\"token punctuation\">(</span>node<span class=\"token punctuation\">)</span>\n            node<span class=\"token punctuation\">.</span>value <span class=\"token operator\">=</span> value\n            <span class=\"token keyword\">return</span>\n        <span class=\"token keyword\">if</span> self<span class=\"token punctuation\">.</span>size <span class=\"token operator\">==</span> self<span class=\"token punctuation\">.</span>capacity<span class=\"token punctuation\">:</span>\n            node <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>tail<span class=\"token punctuation\">.</span>pre\n            self<span class=\"token punctuation\">.</span>remove_node<span class=\"token punctuation\">(</span>node<span class=\"token punctuation\">)</span>\n\n        newNode <span class=\"token operator\">=</span> BiListNode<span class=\"token punctuation\">(</span>key<span class=\"token punctuation\">,</span> value<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>add_to_head<span class=\"token punctuation\">(</span>newNode<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">add_to_head</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> node<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        post <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">.</span>next\n        post<span class=\"token punctuation\">.</span>pre <span class=\"token operator\">=</span> node\n        node<span class=\"token punctuation\">.</span>next <span class=\"token operator\">=</span> post\n        self<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">.</span>next <span class=\"token operator\">=</span> node\n        node<span class=\"token punctuation\">.</span>pre <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>head\n        self<span class=\"token punctuation\">.</span>hash<span class=\"token punctuation\">[</span>node<span class=\"token punctuation\">.</span>key<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> node\n        self<span class=\"token punctuation\">.</span>size <span class=\"token operator\">+=</span> <span class=\"token number\">1</span>\n        <span class=\"token keyword\">return</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">remove_node</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> node<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        pre<span class=\"token punctuation\">,</span> post <span class=\"token operator\">=</span> node<span class=\"token punctuation\">.</span>pre<span class=\"token punctuation\">,</span> node<span class=\"token punctuation\">.</span>next\n        pre<span class=\"token punctuation\">.</span>next<span class=\"token punctuation\">,</span> post<span class=\"token punctuation\">.</span>pre <span class=\"token operator\">=</span> post<span class=\"token punctuation\">,</span> pre\n        self<span class=\"token punctuation\">.</span>hash<span class=\"token punctuation\">.</span>pop<span class=\"token punctuation\">(</span>node<span class=\"token punctuation\">.</span>key<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>size <span class=\"token operator\">-=</span> <span class=\"token number\">1</span>\n        <span class=\"token keyword\">return</span></code></pre>\n<p>get/putadd_to_head , remove_node append, remove get/puttailnodeheadnodehashkey2node</p>\n<h3 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h3><p>LeetCode</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>Design a data structure that follows the constraints of a <strong><a href=\"https://en.wikipedia.org/wiki/Cache_replacement_policies#LRU\">Least Recently Used (LRU) cache</a></strong>.</p>\n<p>Implement the <code>LRUCache</code> class:</p>\n<ul>\n<li><code>LRUCache(int capacity)</code> Initialize the LRU cache with <strong>positive</strong> size <code>capacity</code>.</li>\n<li><code>int get(int key)</code> Return the value of the <code>key</code> if the key exists, otherwise return <code>-1</code>.</li>\n<li><code>void put(int key, int value)</code> Update the value of the <code>key</code> if the <code>key</code> exists. Otherwise, add the <code>key-value</code> pair to the cache. If the number of keys exceeds the <code>capacity</code> from this operation, <strong>evict</strong> the least recently used key.</li>\n</ul>\n<p><strong>Follow up:</strong><br>Could you do <code>get</code> and <code>put</code> in <code>O(1)</code> time complexity?</p>\n<p><strong>Example 1:</strong></p>\n<pre><code>Input\n[&quot;LRUCache&quot;, &quot;put&quot;, &quot;put&quot;, &quot;get&quot;, &quot;put&quot;, &quot;get&quot;, &quot;put&quot;, &quot;get&quot;, &quot;get&quot;, &quot;get&quot;]\n[[2], [1, 1], [2, 2], [1], [3, 3], [2], [4, 4], [1], [3], [4]]\nOutput\n[null, null, null, 1, null, -1, null, -1, 3, 4]\n\nExplanation\nLRUCache lRUCache = new LRUCache(2);\nlRUCache.put(1, 1); // cache is &#123;1=1&#125;\nlRUCache.put(2, 2); // cache is &#123;1=1, 2=2&#125;\nlRUCache.get(1);    // return 1\nlRUCache.put(3, 3); // LRU key was 2, evicts key 2, cache is &#123;1=1, 3=3&#125;\nlRUCache.get(2);    // returns -1 (not found)\nlRUCache.put(4, 4); // LRU key was 1, evicts key 1, cache is &#123;4=4, 3=3&#125;\nlRUCache.get(1);    // return -1 (not found)\nlRUCache.get(3);    // return 3\nlRUCache.get(4);    // return 4</code></pre>\n<p><strong>Constraints:</strong></p>\n<ul>\n<li><code>1 &lt;= capacity &lt;= 3000</code></li>\n<li><code>0 &lt;= key &lt;= 3000</code></li>\n<li><code>0 &lt;= value &lt;= 104</code></li>\n<li>At most <code>3 * 104</code> calls will be made to <code>get</code> and <code>put</code>.</li>\n</ul>\n</blockquote>\n<p>MeidumACDiscuss</p>\n<h3 id=\"-\"><a href=\"#-\" class=\"headerlink\" title=\" \"></a> </h3><p>ACnodeprenode get/put debugpop,append,getPreNodeget/putAC</p>\n<pre><code class=\"python\">class LRUCache:\n\n    def __init__(self, capacity: int):\n        self.key2prenode = &#123;&#125;\n        self.node2key = &#123;&#125;\n        self.root =  ListNode()\n        self.tail = self.root\n        self.size = 0\n        self.capacity = capacity\n\n    def pop(self):\n        if self.size &lt; 1:\n            return\n        cur = self.root.next\n        post = cur.next\n        self.root.next = post\n        if cur in self.node2key:\n            key = self.node2key[cur]\n            self.key2prenode.pop(key)\n            self.node2key.pop(cur)\n\n        if post in self.node2key:\n            post_key = self.node2key[post]\n            self.key2prenode[post_key] = self.root\n\n        return\n\n    def append(self, key, value):\n        node = ListNode(value)\n        self.key2prenode[key] = self.tail\n        self.node2key[node] = key\n        self.tail.next = node\n        self.tail = node\n        return\n\n    def getPreNode(self, key):\n        if key in self.key2prenode:\n            return self.key2prenode[key]\n        return None\n\n    def update(self, prenode):\n        if prenode == None or prenode.next == None:\n            return \n        cur = prenode.next\n        post = cur.next\n        if cur == self.tail:\n            return\n\n        tail_old = self.tail\n        self.tail.next = cur\n        cur.next = None\n        self.tail = cur\n        if cur in self.node2key:\n            key = self.node2key[cur]\n            self.key2prenode[key] = tail_old\n        prenode.next = post\n        if post in self.node2key:\n            post_key = self.node2key[post]\n            self.key2prenode[post_key] = prenode\n        return\n\n    def get(self, key: int) -&gt; int:\n        pre = self.getPreNode(key)\n        if pre == None or pre.next == None:\n            return -1\n        else:\n            val = pre.next.val\n            self.update(pre)\n            return val\n\n    def put(self, key: int, value: int) -&gt; None:\n        pre = self.getPreNode(key)\n        if pre == None or pre.next == None:\n            if self.size == self.capacity:\n                self.pop()\n                self.append(key, value)\n            else:\n                self.append(key, value)\n                self.size += 1\n        else:\n            pre.next.val = value\n            self.update(pre)\n\n        return</code></pre>\n<p>pre node</p>\n<h3 id=\"-\"><a href=\"#-\" class=\"headerlink\" title=\" \"></a> </h3><p>valuekey+valuekey2Prenode , node2keyPythonpre</p>\n<pre><code class=\"python\">class BiListNode:\n    def __init__(self, key=None, value=None):\n        self.key = key\n        self.value = value\n        self.pre = None\n        self.next = None\n\nclass LRUCache_Bi:\n    def __init__(self, capacity) :\n        self.capacity = capacity\n        self.size = 0\n        self.hash = dict()\n        self.head = BiListNode()\n        self.tail = BiListNode()\n        self.head.pre, self.head.next = None, self.tail\n        self.tail.pre, self.tail.next = self.head, None\n\n    def get(self, key):\n        value = -1\n        if key in self.hash:\n            node = self.hash[key]\n            value = node.value\n            self.remove_node(node)\n            self.add_to_head(node)\n        return value\n\n    def put(self, key, value):\n        if self.capacity == 0:\n            return\n        if key in self.hash:\n            node = self.hash[key]\n            self.remove_node(node)\n            self.add_to_head(node)\n            node.value = value\n            return\n        if self.size == self.capacity:\n            node = self.tail.pre\n            self.remove_node(node)\n\n        newNode = BiListNode(key, value)\n        self.add_to_head(newNode)\n        return\n\n    def add_to_head(self, node):\n        post = self.head.next\n        post.pre = node\n        node.next = post\n        self.head.next = node\n        node.pre = self.head\n        self.hash[node.key] = node\n        self.size += 1\n        return\n\n    def remove_node(self, node):\n        pre, post = node.pre, node.next\n        pre.next, post.pre = post, pre\n        self.hash.pop(node.key)\n        self.size -= 1\n        return</code></pre>\n<p>get/putadd_to_head , remove_node append, remove get/puttailnodeheadnodehashkey2node</p>\n<h3 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h3><p>LeetCode</p>\n"},{"title":"147/148 merge sort","toc":true,"mathjax":true,"top":false,"cover":true,"date":"2021-01-21T07:24:50.000Z","updated":"2021-01-21T08:28:05.905Z","_content":"\n> Given the `head` of a linked list, return *the list after sorting it in **ascending order***.\n>\n> **Follow up:** Can you sort the linked list in `O(n logn)` time and `O(1)` memory (i.e. constant space)?\n>\n>  \n>\n> **Example 1:**\n>\n> ![img](https://assets.leetcode.com/uploads/2020/09/14/sort_list_1.jpg)\n>\n> ```\n> Input: head = [4,2,1,3]\n> Output: [1,2,3,4]\n> ```\n>\n> **Example 2:**\n>\n> ![img](https://assets.leetcode.com/uploads/2020/09/14/sort_list_2.jpg)\n>\n> ```\n> Input: head = [-1,5,3,4,0]\n> Output: [-1,0,3,4,5]\n> ```\n>\n> **Example 3:**\n>\n> ```\n> Input: head = []\n> Output: []\n> ```\n>\n>  \n>\n> **Constraints:**\n>\n> - The number of nodes in the list is in the range `[0, 5 * 104]`.\n> - `-105 <= Node.val <= 105`\n\n147AC148OJO(nlogn)O(1)\n\n### \n\n2O(nlogn)\n\n2\n\n```python\nclass Solution:\n    def sortList(self, head: ListNode) -> ListNode:\n        if head == None or head.next == None:\n            return head\n        mid, tail = head, head.next\n        while tail and tail.next:\n            tail = tail.next.next\n            mid = mid.next\n        start = mid.next\n        mid.next = None\n        left, right = self.sortList(head), self.sortList(start)\n        return self.mergeSort(left, right)\n\n    \n    def mergeSort(self, l1, l2):\n        root = ListNode()\n        tail = root\n        while l1 and l2:\n            if l1.val < l2.val:\n                tail.next = l1\n                l1 = l1.next\n            else:\n                tail.next = l2\n                l2 = l2.next\n            tail = tail.next\n        tail.next = l1 or l2\n        return root.next\n```\n\n### \n\nsizesize=12O(1)size2mergetailtailmergetail.next = LinkListhead\n\n```python\nclass Solution:\n    # buttom up merget\n    def getSize(self, head):\n        count = 0\n        while head:\n            count += 1\n            head = head.next\n        return count\n\n    def splitLink(self, head, size):\n        cur = head\n        for _ in range(size):\n            if not cur:\n                break\n            cur = cur.next\n        if not cur:\n            return None\n        next_start = cur.next\n        cur.next = None\n        return next_start\n\n    def mergeSort_bottomup(self, l1, l2, pre_tail):\n        cur = pre_tail\n        while l1 and l2:\n            if l1.val<l2.val:\n                cur.next = l1\n                l1 = l1.next\n            else:\n                cur.next = l2\n                l2 = l2.next\n            cur = cur.next\n        cur.next = l1 or l2\n        while cur.next:\n            cur = cur.next\n        return cur\n\n    # bottom up sort\n    def sortList(self, head: ListNode) -> ListNode:\n        if head == None or head.next == None:\n            return head\n\n        length = self.getSize(head)\n        root = ListNode()\n        root.next = head\n        # pre_tail = None\n        start = None\n        size = 1\n        while size < length:\n            pre_tail = root\n            start = pre_tail.next\n            while start:\n                left = start\n                right = self.splitLink(left, size)\n                start = self.splitLink(right, size)\n                pre_tail = self.mergeSort_bottomup(left, right,pre_tail)\n            size *= 2\n        return root.next\n```\n\n\n\n### Conclusion\n\nO(1)TLE","source":"_posts/147-148-merge-sort.md","raw":"---\ntitle: 147/148 merge sort\ntoc: true\nmathjax: true\ntop: false\ncover: true\ndate: 2021-01-21 15:24:50\nupdated:\ncategories: Algorithms\ntags:\n\t- Algorithms\n\t- LeetCode\n---\n\n> Given the `head` of a linked list, return *the list after sorting it in **ascending order***.\n>\n> **Follow up:** Can you sort the linked list in `O(n logn)` time and `O(1)` memory (i.e. constant space)?\n>\n>  \n>\n> **Example 1:**\n>\n> ![img](https://assets.leetcode.com/uploads/2020/09/14/sort_list_1.jpg)\n>\n> ```\n> Input: head = [4,2,1,3]\n> Output: [1,2,3,4]\n> ```\n>\n> **Example 2:**\n>\n> ![img](https://assets.leetcode.com/uploads/2020/09/14/sort_list_2.jpg)\n>\n> ```\n> Input: head = [-1,5,3,4,0]\n> Output: [-1,0,3,4,5]\n> ```\n>\n> **Example 3:**\n>\n> ```\n> Input: head = []\n> Output: []\n> ```\n>\n>  \n>\n> **Constraints:**\n>\n> - The number of nodes in the list is in the range `[0, 5 * 104]`.\n> - `-105 <= Node.val <= 105`\n\n147AC148OJO(nlogn)O(1)\n\n### \n\n2O(nlogn)\n\n2\n\n```python\nclass Solution:\n    def sortList(self, head: ListNode) -> ListNode:\n        if head == None or head.next == None:\n            return head\n        mid, tail = head, head.next\n        while tail and tail.next:\n            tail = tail.next.next\n            mid = mid.next\n        start = mid.next\n        mid.next = None\n        left, right = self.sortList(head), self.sortList(start)\n        return self.mergeSort(left, right)\n\n    \n    def mergeSort(self, l1, l2):\n        root = ListNode()\n        tail = root\n        while l1 and l2:\n            if l1.val < l2.val:\n                tail.next = l1\n                l1 = l1.next\n            else:\n                tail.next = l2\n                l2 = l2.next\n            tail = tail.next\n        tail.next = l1 or l2\n        return root.next\n```\n\n### \n\nsizesize=12O(1)size2mergetailtailmergetail.next = LinkListhead\n\n```python\nclass Solution:\n    # buttom up merget\n    def getSize(self, head):\n        count = 0\n        while head:\n            count += 1\n            head = head.next\n        return count\n\n    def splitLink(self, head, size):\n        cur = head\n        for _ in range(size):\n            if not cur:\n                break\n            cur = cur.next\n        if not cur:\n            return None\n        next_start = cur.next\n        cur.next = None\n        return next_start\n\n    def mergeSort_bottomup(self, l1, l2, pre_tail):\n        cur = pre_tail\n        while l1 and l2:\n            if l1.val<l2.val:\n                cur.next = l1\n                l1 = l1.next\n            else:\n                cur.next = l2\n                l2 = l2.next\n            cur = cur.next\n        cur.next = l1 or l2\n        while cur.next:\n            cur = cur.next\n        return cur\n\n    # bottom up sort\n    def sortList(self, head: ListNode) -> ListNode:\n        if head == None or head.next == None:\n            return head\n\n        length = self.getSize(head)\n        root = ListNode()\n        root.next = head\n        # pre_tail = None\n        start = None\n        size = 1\n        while size < length:\n            pre_tail = root\n            start = pre_tail.next\n            while start:\n                left = start\n                right = self.splitLink(left, size)\n                start = self.splitLink(right, size)\n                pre_tail = self.mergeSort_bottomup(left, right,pre_tail)\n            size *= 2\n        return root.next\n```\n\n\n\n### Conclusion\n\nO(1)TLE","slug":"147-148-merge-sort","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"ckowlff4s000eye28dd924rjd","content":"<blockquote>\n<p>Given the <code>head</code> of a linked list, return <em>the list after sorting it in <strong>ascending order</strong></em>.</p>\n<p><strong>Follow up:</strong> Can you sort the linked list in <code>O(n logn)</code> time and <code>O(1)</code> memory (i.e. constant space)?</p>\n<p><strong>Example 1:</strong></p>\n<p><img src=\"https://assets.leetcode.com/uploads/2020/09/14/sort_list_1.jpg\" alt=\"img\"></p>\n<pre><code>Input: head = [4,2,1,3]\nOutput: [1,2,3,4]</code></pre>\n<p><strong>Example 2:</strong></p>\n<p><img src=\"https://assets.leetcode.com/uploads/2020/09/14/sort_list_2.jpg\" alt=\"img\"></p>\n<pre><code>Input: head = [-1,5,3,4,0]\nOutput: [-1,0,3,4,5]</code></pre>\n<p><strong>Example 3:</strong></p>\n<pre><code>Input: head = []\nOutput: []</code></pre>\n<p><strong>Constraints:</strong></p>\n<ul>\n<li>The number of nodes in the list is in the range <code>[0, 5 * 104]</code>.</li>\n<li><code>-105 &lt;= Node.val &lt;= 105</code></li>\n</ul>\n</blockquote>\n<p>147AC148OJO(nlogn)O(1)</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>2O(nlogn)</p>\n<p>2</p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">Solution</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">sortList</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> head<span class=\"token punctuation\">:</span> ListNode<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> ListNode<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> head <span class=\"token operator\">==</span> None <span class=\"token operator\">or</span> head<span class=\"token punctuation\">.</span>next <span class=\"token operator\">==</span> None<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span> head\n        mid<span class=\"token punctuation\">,</span> tail <span class=\"token operator\">=</span> head<span class=\"token punctuation\">,</span> head<span class=\"token punctuation\">.</span>next\n        <span class=\"token keyword\">while</span> tail <span class=\"token operator\">and</span> tail<span class=\"token punctuation\">.</span>next<span class=\"token punctuation\">:</span>\n            tail <span class=\"token operator\">=</span> tail<span class=\"token punctuation\">.</span>next<span class=\"token punctuation\">.</span>next\n            mid <span class=\"token operator\">=</span> mid<span class=\"token punctuation\">.</span>next\n        start <span class=\"token operator\">=</span> mid<span class=\"token punctuation\">.</span>next\n        mid<span class=\"token punctuation\">.</span>next <span class=\"token operator\">=</span> None\n        left<span class=\"token punctuation\">,</span> right <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>sortList<span class=\"token punctuation\">(</span>head<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>sortList<span class=\"token punctuation\">(</span>start<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>mergeSort<span class=\"token punctuation\">(</span>left<span class=\"token punctuation\">,</span> right<span class=\"token punctuation\">)</span>\n\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">mergeSort</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> l1<span class=\"token punctuation\">,</span> l2<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        root <span class=\"token operator\">=</span> ListNode<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        tail <span class=\"token operator\">=</span> root\n        <span class=\"token keyword\">while</span> l1 <span class=\"token operator\">and</span> l2<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">if</span> l1<span class=\"token punctuation\">.</span>val <span class=\"token operator\">&lt;</span> l2<span class=\"token punctuation\">.</span>val<span class=\"token punctuation\">:</span>\n                tail<span class=\"token punctuation\">.</span>next <span class=\"token operator\">=</span> l1\n                l1 <span class=\"token operator\">=</span> l1<span class=\"token punctuation\">.</span>next\n            <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n                tail<span class=\"token punctuation\">.</span>next <span class=\"token operator\">=</span> l2\n                l2 <span class=\"token operator\">=</span> l2<span class=\"token punctuation\">.</span>next\n            tail <span class=\"token operator\">=</span> tail<span class=\"token punctuation\">.</span>next\n        tail<span class=\"token punctuation\">.</span>next <span class=\"token operator\">=</span> l1 <span class=\"token operator\">or</span> l2\n        <span class=\"token keyword\">return</span> root<span class=\"token punctuation\">.</span>next</code></pre>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>sizesize=12O(1)size2mergetailtailmergetail.next = LinkListhead</p>\n<pre class=\" language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">Solution</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\" spellcheck=\"true\"># buttom up merget</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">getSize</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> head<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        count <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n        <span class=\"token keyword\">while</span> head<span class=\"token punctuation\">:</span>\n            count <span class=\"token operator\">+=</span> <span class=\"token number\">1</span>\n            head <span class=\"token operator\">=</span> head<span class=\"token punctuation\">.</span>next\n        <span class=\"token keyword\">return</span> count\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">splitLink</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> head<span class=\"token punctuation\">,</span> size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        cur <span class=\"token operator\">=</span> head\n        <span class=\"token keyword\">for</span> _ <span class=\"token keyword\">in</span> range<span class=\"token punctuation\">(</span>size<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">if</span> <span class=\"token operator\">not</span> cur<span class=\"token punctuation\">:</span>\n                <span class=\"token keyword\">break</span>\n            cur <span class=\"token operator\">=</span> cur<span class=\"token punctuation\">.</span>next\n        <span class=\"token keyword\">if</span> <span class=\"token operator\">not</span> cur<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span> None\n        next_start <span class=\"token operator\">=</span> cur<span class=\"token punctuation\">.</span>next\n        cur<span class=\"token punctuation\">.</span>next <span class=\"token operator\">=</span> None\n        <span class=\"token keyword\">return</span> next_start\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">mergeSort_bottomup</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> l1<span class=\"token punctuation\">,</span> l2<span class=\"token punctuation\">,</span> pre_tail<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        cur <span class=\"token operator\">=</span> pre_tail\n        <span class=\"token keyword\">while</span> l1 <span class=\"token operator\">and</span> l2<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">if</span> l1<span class=\"token punctuation\">.</span>val<span class=\"token operator\">&lt;</span>l2<span class=\"token punctuation\">.</span>val<span class=\"token punctuation\">:</span>\n                cur<span class=\"token punctuation\">.</span>next <span class=\"token operator\">=</span> l1\n                l1 <span class=\"token operator\">=</span> l1<span class=\"token punctuation\">.</span>next\n            <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n                cur<span class=\"token punctuation\">.</span>next <span class=\"token operator\">=</span> l2\n                l2 <span class=\"token operator\">=</span> l2<span class=\"token punctuation\">.</span>next\n            cur <span class=\"token operator\">=</span> cur<span class=\"token punctuation\">.</span>next\n        cur<span class=\"token punctuation\">.</span>next <span class=\"token operator\">=</span> l1 <span class=\"token operator\">or</span> l2\n        <span class=\"token keyword\">while</span> cur<span class=\"token punctuation\">.</span>next<span class=\"token punctuation\">:</span>\n            cur <span class=\"token operator\">=</span> cur<span class=\"token punctuation\">.</span>next\n        <span class=\"token keyword\">return</span> cur\n\n    <span class=\"token comment\" spellcheck=\"true\"># bottom up sort</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">sortList</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> head<span class=\"token punctuation\">:</span> ListNode<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> ListNode<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> head <span class=\"token operator\">==</span> None <span class=\"token operator\">or</span> head<span class=\"token punctuation\">.</span>next <span class=\"token operator\">==</span> None<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span> head\n\n        length <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>getSize<span class=\"token punctuation\">(</span>head<span class=\"token punctuation\">)</span>\n        root <span class=\"token operator\">=</span> ListNode<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        root<span class=\"token punctuation\">.</span>next <span class=\"token operator\">=</span> head\n        <span class=\"token comment\" spellcheck=\"true\"># pre_tail = None</span>\n        start <span class=\"token operator\">=</span> None\n        size <span class=\"token operator\">=</span> <span class=\"token number\">1</span>\n        <span class=\"token keyword\">while</span> size <span class=\"token operator\">&lt;</span> length<span class=\"token punctuation\">:</span>\n            pre_tail <span class=\"token operator\">=</span> root\n            start <span class=\"token operator\">=</span> pre_tail<span class=\"token punctuation\">.</span>next\n            <span class=\"token keyword\">while</span> start<span class=\"token punctuation\">:</span>\n                left <span class=\"token operator\">=</span> start\n                right <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>splitLink<span class=\"token punctuation\">(</span>left<span class=\"token punctuation\">,</span> size<span class=\"token punctuation\">)</span>\n                start <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>splitLink<span class=\"token punctuation\">(</span>right<span class=\"token punctuation\">,</span> size<span class=\"token punctuation\">)</span>\n                pre_tail <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>mergeSort_bottomup<span class=\"token punctuation\">(</span>left<span class=\"token punctuation\">,</span> right<span class=\"token punctuation\">,</span>pre_tail<span class=\"token punctuation\">)</span>\n            size <span class=\"token operator\">*=</span> <span class=\"token number\">2</span>\n        <span class=\"token keyword\">return</span> root<span class=\"token punctuation\">.</span>next</code></pre>\n<h3 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h3><p>O(1)TLE</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>Given the <code>head</code> of a linked list, return <em>the list after sorting it in <strong>ascending order</strong></em>.</p>\n<p><strong>Follow up:</strong> Can you sort the linked list in <code>O(n logn)</code> time and <code>O(1)</code> memory (i.e. constant space)?</p>\n<p><strong>Example 1:</strong></p>\n<p><img src=\"https://assets.leetcode.com/uploads/2020/09/14/sort_list_1.jpg\" alt=\"img\"></p>\n<pre><code>Input: head = [4,2,1,3]\nOutput: [1,2,3,4]</code></pre>\n<p><strong>Example 2:</strong></p>\n<p><img src=\"https://assets.leetcode.com/uploads/2020/09/14/sort_list_2.jpg\" alt=\"img\"></p>\n<pre><code>Input: head = [-1,5,3,4,0]\nOutput: [-1,0,3,4,5]</code></pre>\n<p><strong>Example 3:</strong></p>\n<pre><code>Input: head = []\nOutput: []</code></pre>\n<p><strong>Constraints:</strong></p>\n<ul>\n<li>The number of nodes in the list is in the range <code>[0, 5 * 104]</code>.</li>\n<li><code>-105 &lt;= Node.val &lt;= 105</code></li>\n</ul>\n</blockquote>\n<p>147AC148OJO(nlogn)O(1)</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>2O(nlogn)</p>\n<p>2</p>\n<pre><code class=\"python\">class Solution:\n    def sortList(self, head: ListNode) -&gt; ListNode:\n        if head == None or head.next == None:\n            return head\n        mid, tail = head, head.next\n        while tail and tail.next:\n            tail = tail.next.next\n            mid = mid.next\n        start = mid.next\n        mid.next = None\n        left, right = self.sortList(head), self.sortList(start)\n        return self.mergeSort(left, right)\n\n\n    def mergeSort(self, l1, l2):\n        root = ListNode()\n        tail = root\n        while l1 and l2:\n            if l1.val &lt; l2.val:\n                tail.next = l1\n                l1 = l1.next\n            else:\n                tail.next = l2\n                l2 = l2.next\n            tail = tail.next\n        tail.next = l1 or l2\n        return root.next</code></pre>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>sizesize=12O(1)size2mergetailtailmergetail.next = LinkListhead</p>\n<pre><code class=\"python\">class Solution:\n    # buttom up merget\n    def getSize(self, head):\n        count = 0\n        while head:\n            count += 1\n            head = head.next\n        return count\n\n    def splitLink(self, head, size):\n        cur = head\n        for _ in range(size):\n            if not cur:\n                break\n            cur = cur.next\n        if not cur:\n            return None\n        next_start = cur.next\n        cur.next = None\n        return next_start\n\n    def mergeSort_bottomup(self, l1, l2, pre_tail):\n        cur = pre_tail\n        while l1 and l2:\n            if l1.val&lt;l2.val:\n                cur.next = l1\n                l1 = l1.next\n            else:\n                cur.next = l2\n                l2 = l2.next\n            cur = cur.next\n        cur.next = l1 or l2\n        while cur.next:\n            cur = cur.next\n        return cur\n\n    # bottom up sort\n    def sortList(self, head: ListNode) -&gt; ListNode:\n        if head == None or head.next == None:\n            return head\n\n        length = self.getSize(head)\n        root = ListNode()\n        root.next = head\n        # pre_tail = None\n        start = None\n        size = 1\n        while size &lt; length:\n            pre_tail = root\n            start = pre_tail.next\n            while start:\n                left = start\n                right = self.splitLink(left, size)\n                start = self.splitLink(right, size)\n                pre_tail = self.mergeSort_bottomup(left, right,pre_tail)\n            size *= 2\n        return root.next</code></pre>\n<h3 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h3><p>O(1)TLE</p>\n"},{"title":"","toc":true,"mathjax":true,"top":false,"cover":true,"date":"2021-03-18T02:46:45.000Z","updated":"2021-05-20T07:32:04.510Z","_content":"\n\n\n\n\n  \n\nBTC\n\n2\n\n2****\n\n\n\nP.H.D996","source":"_posts/.md","raw":"---\ntitle: \ntoc: true\nmathjax: true\ntop: false\ncover: true\ndate: 2021-03-18 10:46:45\nupdated:\ncategories: \ntags:\n\t- \n---\n\n\n\n\n\n  \n\nBTC\n\n2\n\n2****\n\n\n\nP.H.D996","slug":"","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"ckowlff4u000iye288xs01w1p","content":"<p></p>\n<p></p>\n<p>  </p>\n<p>BTC</p>\n<p>2</p>\n<p>2<strong></strong></p>\n<p></p>\n<p>P.H.D996</p>\n","site":{"data":{}},"excerpt":"","more":"<p></p>\n<p></p>\n<p>  </p>\n<p>BTC</p>\n<p>2</p>\n<p>2<strong></strong></p>\n<p></p>\n<p>P.H.D996</p>\n"},{"title":"","toc":true,"mathjax":true,"top":false,"cover":true,"date":"2021-03-19T03:02:29.000Z","updated":"2021-03-19T03:06:50.320Z","_content":"\n> \n>\n> From : https://yonglezh.github.io/2017/01/21/doublethink/\n\n\n\n20111984\n\n\n\n###  - \n\n\n\n\n\n\n\n\n\nWikipedia1984\n\n> Doublethink is the act of simultaneously accepting two mutually contradictory beliefs as correct, often **in distinct social contexts**.\n\n****\n\nThe Oxford Companion to the English Language\n\n> The term is widely used to describe a capacity to engage in one line of thought in one situation (at work, in a certain group, in business, etc.) and another line in another situation (at home, in another group, in private life), without necessarily sensing any conflict between the two.\n\n\n\n### \n\n1984\n\n> \n\n\n\n1. \n2. \n3. \n4.  \n\n1234\n\n### \n\n123\n\n1984\n\n1234\n\n341984\n\n### \n\n1. (crimestop)\n\n   > (crimestop)(crimestop)\n\n   \n\n   \n\n   \n\n2. (blackwhite)\n\n   > \n\n   \n\n   \n\n### \n\n\n\n\n\n\n\n\n\n\n\n### \n\n\n\n> When you are studying any matter, or considering any philosophy, ask yourself only what are the facts and what is the truth that the facts bear out. Never let yourself be diverted either by what you wish to believe, or by what you think would have beneficent social effects if it were believed. But look only, and solely, at what are the facts.  Bertrand Russell - Message to Future Generations\n\n###  VS. \n\n\n\n\n\n\n\n![alt text](https://upload.wikimedia.org/wikipedia/commons/d/da/Set_intersection.svg)\n\n1. A\n2. B\n3. AB+++\n4. A-AB(-)+( - )++\n5. B-AB + -  - \n\n4\n\n\n\n5\n\n3","source":"_posts/.md","raw":"---\ntitle: \ntoc: true\nmathjax: true\ntop: false\ncover: true\ndate: 2021-03-19 11:02:29\nupdated:\ncategories: \ntags:\n\t- \n\t- 1984\n---\n\n> \n>\n> From : https://yonglezh.github.io/2017/01/21/doublethink/\n\n\n\n20111984\n\n\n\n###  - \n\n\n\n\n\n\n\n\n\nWikipedia1984\n\n> Doublethink is the act of simultaneously accepting two mutually contradictory beliefs as correct, often **in distinct social contexts**.\n\n****\n\nThe Oxford Companion to the English Language\n\n> The term is widely used to describe a capacity to engage in one line of thought in one situation (at work, in a certain group, in business, etc.) and another line in another situation (at home, in another group, in private life), without necessarily sensing any conflict between the two.\n\n\n\n### \n\n1984\n\n> \n\n\n\n1. \n2. \n3. \n4.  \n\n1234\n\n### \n\n123\n\n1984\n\n1234\n\n341984\n\n### \n\n1. (crimestop)\n\n   > (crimestop)(crimestop)\n\n   \n\n   \n\n   \n\n2. (blackwhite)\n\n   > \n\n   \n\n   \n\n### \n\n\n\n\n\n\n\n\n\n\n\n### \n\n\n\n> When you are studying any matter, or considering any philosophy, ask yourself only what are the facts and what is the truth that the facts bear out. Never let yourself be diverted either by what you wish to believe, or by what you think would have beneficent social effects if it were believed. But look only, and solely, at what are the facts.  Bertrand Russell - Message to Future Generations\n\n###  VS. \n\n\n\n\n\n\n\n![alt text](https://upload.wikimedia.org/wikipedia/commons/d/da/Set_intersection.svg)\n\n1. A\n2. B\n3. AB+++\n4. A-AB(-)+( - )++\n5. B-AB + -  - \n\n4\n\n\n\n5\n\n3","slug":"","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"ckowlff4u000lye28c1bi3rap","content":"<blockquote>\n<p></p>\n<p>From : <a href=\"https://yonglezh.github.io/2017/01/21/doublethink/\">https://yonglezh.github.io/2017/01/21/doublethink/</a></p>\n</blockquote>\n<p>20111984</p>\n<p></p>\n<h3 id=\"-\"><a href=\"#-\" class=\"headerlink\" title=\" - \"></a> - </h3><p></p>\n<p></p>\n<p></p>\n<p></p>\n<p>Wikipedia1984</p>\n<blockquote>\n<p>Doublethink is the act of simultaneously accepting two mutually contradictory beliefs as correct, often <strong>in distinct social contexts</strong>.</p>\n</blockquote>\n<p><strong></strong></p>\n<p>The Oxford Companion to the English Language</p>\n<blockquote>\n<p>The term is widely used to describe a capacity to engage in one line of thought in one situation (at work, in a certain group, in business, etc.) and another line in another situation (at home, in another group, in private life), without necessarily sensing any conflict between the two.</p>\n</blockquote>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>1984</p>\n<blockquote>\n<p></p>\n</blockquote>\n<p></p>\n<ol>\n<li></li>\n<li></li>\n<li></li>\n<li> </li>\n</ol>\n<p>1234</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>123</p>\n<p>1984</p>\n<p>1234</p>\n<p>341984</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ol>\n<li><p>(crimestop)</p>\n<blockquote>\n<p>(crimestop)(crimestop)</p>\n</blockquote>\n<p></p>\n<p></p>\n<p></p>\n</li>\n<li><p>(blackwhite)</p>\n<blockquote>\n<p></p>\n</blockquote>\n<p></p>\n<p></p>\n</li>\n</ol>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<p></p>\n<p></p>\n<p></p>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<blockquote>\n<p>When you are studying any matter, or considering any philosophy, ask yourself only what are the facts and what is the truth that the facts bear out. Never let yourself be diverted either by what you wish to believe, or by what you think would have beneficent social effects if it were believed. But look only, and solely, at what are the facts.  Bertrand Russell - Message to Future Generations</p>\n</blockquote>\n<h3 id=\"-VS-\"><a href=\"#-VS-\" class=\"headerlink\" title=\" VS. \"></a> VS. </h3><p></p>\n<p></p>\n<p></p>\n<p><img src=\"https://upload.wikimedia.org/wikipedia/commons/d/da/Set_intersection.svg\" alt=\"alt text\"></p>\n<ol>\n<li>A</li>\n<li>B</li>\n<li>AB+++</li>\n<li>A-AB(-)+( - )++</li>\n<li>B-AB + -  - </li>\n</ol>\n<p>4</p>\n<p></p>\n<p>5</p>\n<p>3</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p></p>\n<p>From : <a href=\"https://yonglezh.github.io/2017/01/21/doublethink/\">https://yonglezh.github.io/2017/01/21/doublethink/</a></p>\n</blockquote>\n<p>20111984</p>\n<p></p>\n<h3 id=\"-\"><a href=\"#-\" class=\"headerlink\" title=\" - \"></a> - </h3><p></p>\n<p></p>\n<p></p>\n<p></p>\n<p>Wikipedia1984</p>\n<blockquote>\n<p>Doublethink is the act of simultaneously accepting two mutually contradictory beliefs as correct, often <strong>in distinct social contexts</strong>.</p>\n</blockquote>\n<p><strong></strong></p>\n<p>The Oxford Companion to the English Language</p>\n<blockquote>\n<p>The term is widely used to describe a capacity to engage in one line of thought in one situation (at work, in a certain group, in business, etc.) and another line in another situation (at home, in another group, in private life), without necessarily sensing any conflict between the two.</p>\n</blockquote>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>1984</p>\n<blockquote>\n<p></p>\n</blockquote>\n<p></p>\n<ol>\n<li></li>\n<li></li>\n<li></li>\n<li> </li>\n</ol>\n<p>1234</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>123</p>\n<p>1984</p>\n<p>1234</p>\n<p>341984</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ol>\n<li><p>(crimestop)</p>\n<blockquote>\n<p>(crimestop)(crimestop)</p>\n</blockquote>\n<p></p>\n<p></p>\n<p></p>\n</li>\n<li><p>(blackwhite)</p>\n<blockquote>\n<p></p>\n</blockquote>\n<p></p>\n<p></p>\n</li>\n</ol>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<p></p>\n<p></p>\n<p></p>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<blockquote>\n<p>When you are studying any matter, or considering any philosophy, ask yourself only what are the facts and what is the truth that the facts bear out. Never let yourself be diverted either by what you wish to believe, or by what you think would have beneficent social effects if it were believed. But look only, and solely, at what are the facts.  Bertrand Russell - Message to Future Generations</p>\n</blockquote>\n<h3 id=\"-VS-\"><a href=\"#-VS-\" class=\"headerlink\" title=\" VS. \"></a> VS. </h3><p></p>\n<p></p>\n<p></p>\n<p><img src=\"https://upload.wikimedia.org/wikipedia/commons/d/da/Set_intersection.svg\" alt=\"alt text\"></p>\n<ol>\n<li>A</li>\n<li>B</li>\n<li>AB+++</li>\n<li>A-AB(-)+( - )++</li>\n<li>B-AB + -  - </li>\n</ol>\n<p>4</p>\n<p></p>\n<p>5</p>\n<p>3</p>\n"},{"title":"","toc":true,"mathjax":true,"top":false,"cover":true,"date":"2021-03-15T10:51:14.000Z","updated":"2021-05-20T07:48:13.153Z","_content":"\n>  Maybe I'm a Reprobate\n\n\n\n\n\n\n\n\n\n> Nick Carraway \n>\n> \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\n\n\n****\n\n  \n\n\n\n \n\n\n\n\n\n\n\n\n\n> \n>\n> \n>\n> \n>\n> \n\n\n\n> \n\n\n\n\n\n\n\n","source":"_posts/.md","raw":"---\ntitle: \ntoc: true\nmathjax: true\ntop: false\ncover: true\ndate: 2021-03-15 18:51:14\nupdated:\ncategories: \ntags:\n\t- \n\t- \t\n\t- \n\t- \n---\n\n>  Maybe I'm a Reprobate\n\n\n\n\n\n\n\n\n\n> Nick Carraway \n>\n> \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\n\n\n****\n\n  \n\n\n\n \n\n\n\n\n\n\n\n\n\n> \n>\n> \n>\n> \n>\n> \n\n\n\n> \n\n\n\n\n\n\n\n","slug":"","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"ckowlff4x000nye2839rj25e2","content":"<blockquote>\n<p> Maybe Im a Reprobate</p>\n</blockquote>\n<p></p>\n<p></p>\n<p></p>\n<p></p>\n<blockquote>\n<p>Nick Carraway </p>\n<p>                                                                            </p>\n</blockquote>\n<p></p>\n<p><strong></strong></p>\n<p>  </p>\n<p></p>\n<p> </p>\n<p></p>\n<p></p>\n<p></p>\n<p></p>\n<blockquote>\n<p></p>\n<p></p>\n<p></p>\n<p></p>\n</blockquote>\n<p></p>\n<blockquote>\n<p></p>\n</blockquote>\n<p></p>\n<p></p>\n<p></p>\n<p></p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p> Maybe Im a Reprobate</p>\n</blockquote>\n<p></p>\n<p></p>\n<p></p>\n<p></p>\n<blockquote>\n<p>Nick Carraway </p>\n<p>                                                                            </p>\n</blockquote>\n<p></p>\n<p><strong></strong></p>\n<p>  </p>\n<p></p>\n<p> </p>\n<p></p>\n<p></p>\n<p></p>\n<p></p>\n<blockquote>\n<p></p>\n<p></p>\n<p></p>\n<p></p>\n</blockquote>\n<p></p>\n<blockquote>\n<p></p>\n</blockquote>\n<p></p>\n<p></p>\n<p></p>\n<p></p>\n"},{"title":"()","toc":true,"mathjax":true,"top":false,"cover":true,"date":"2021-03-10T03:08:08.000Z","updated":"2021-03-10T03:10:56.692Z","_content":"\n> \n>\n> From https://zhuanlan.zhihu.com/p/351560331\n\n Leetcode 123[](https://link.zhihu.com/?target=https%3A//www.youtube.com/watch%3Fv%3D4ALB5m_Idkk) 20 \n\n\n\n## \n\n Leetcode \n\n[](https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/maximum-subarray/)\n\n[](https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/maximum-subarray/solution/zui-da-zi-xu-he-by-leetcode-solution/)\n\n> ... 1977 Michael Shamos  Shamos 3Shamos  O(*n*log*n)* Shamos  Jay Kadane 4 *O*(*n*) \n\n Michael Shamos  Jon Bentley \n\n[](https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/linked-list-cycle/)\n\n Floyd \n\n[](https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/majority-element/)\n\n Boyer-Moore [](https://link.zhihu.com/?target=https%3A//www.cs.ou.edu/~rlpage/dmtools/mjrty.pdf)\n\n[](https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/find-the-duplicate-number/)\n\n O(N) [](https://link.zhihu.com/?target=https%3A//keithschwarz.com/interesting/code/%3Fdir%3Dfind-duplicate)\n\n> This problem (reportedly) took CS legend Don Knuth twenty-four hours to solve and I have only met one person (Keith Amling) who could solve it in less time than this.\n\nDon Knuth  24 \n\n Leetcode invisible  Leetcode  Google Kickstart  ** | **\n\n## \n\n Leetcode  900    minmax  XXX   XXX  ****\n\n## \n\n[Lee215](https://link.zhihu.com/?target=https%3A//leetcode.com/lee215/)  Leetcode  reputation [cuiaoxiang](https://link.zhihu.com/?target=https%3A//leetcode.com/cuiaoxiang/)  Leetcode  20 [ Lee215 ](https://link.zhihu.com/?target=https%3A//www.youtube.com/watch%3Fv%3DZIhhoFQp8H4%26t%3D1030s) cuiaoxiang  30  30  cuiaoxiang \n\n## \n\nWilliam Leetcode  12  120 [](https://link.zhihu.com/?target=https%3A//www.youtube.com/watch%3Fv%3D-tNMxwWSN_M%26t%3D0s)\n\n## \n\n\n\n\"If you are not enjoying it, you are doing it wrong.\"","source":"_posts/-.md","raw":"---\ntitle: ()\ntoc: true\nmathjax: true\ntop: false\ncover: true\ndate: 2021-03-10 11:08:08\nupdated:\ncategories: Algorithms\ntags:\n\t- Algorithms\n\t- LeetCode\n---\n\n> \n>\n> From https://zhuanlan.zhihu.com/p/351560331\n\n Leetcode 123[](https://link.zhihu.com/?target=https%3A//www.youtube.com/watch%3Fv%3D4ALB5m_Idkk) 20 \n\n\n\n## \n\n Leetcode \n\n[](https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/maximum-subarray/)\n\n[](https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/maximum-subarray/solution/zui-da-zi-xu-he-by-leetcode-solution/)\n\n> ... 1977 Michael Shamos  Shamos 3Shamos  O(*n*log*n)* Shamos  Jay Kadane 4 *O*(*n*) \n\n Michael Shamos  Jon Bentley \n\n[](https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/linked-list-cycle/)\n\n Floyd \n\n[](https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/majority-element/)\n\n Boyer-Moore [](https://link.zhihu.com/?target=https%3A//www.cs.ou.edu/~rlpage/dmtools/mjrty.pdf)\n\n[](https://link.zhihu.com/?target=https%3A//leetcode-cn.com/problems/find-the-duplicate-number/)\n\n O(N) [](https://link.zhihu.com/?target=https%3A//keithschwarz.com/interesting/code/%3Fdir%3Dfind-duplicate)\n\n> This problem (reportedly) took CS legend Don Knuth twenty-four hours to solve and I have only met one person (Keith Amling) who could solve it in less time than this.\n\nDon Knuth  24 \n\n Leetcode invisible  Leetcode  Google Kickstart  ** | **\n\n## \n\n Leetcode  900    minmax  XXX   XXX  ****\n\n## \n\n[Lee215](https://link.zhihu.com/?target=https%3A//leetcode.com/lee215/)  Leetcode  reputation [cuiaoxiang](https://link.zhihu.com/?target=https%3A//leetcode.com/cuiaoxiang/)  Leetcode  20 [ Lee215 ](https://link.zhihu.com/?target=https%3A//www.youtube.com/watch%3Fv%3DZIhhoFQp8H4%26t%3D1030s) cuiaoxiang  30  30  cuiaoxiang \n\n## \n\nWilliam Leetcode  12  120 [](https://link.zhihu.com/?target=https%3A//www.youtube.com/watch%3Fv%3D-tNMxwWSN_M%26t%3D0s)\n\n## \n\n\n\n\"If you are not enjoying it, you are doing it wrong.\"","slug":"-","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"ckowlff560018ye28068hhosu","content":"<blockquote>\n<p></p>\n<p>From <a href=\"https://zhuanlan.zhihu.com/p/351560331\">https://zhuanlan.zhihu.com/p/351560331</a></p>\n</blockquote>\n<p> Leetcode 123<a href=\"https://link.zhihu.com/?target=https://www.youtube.com/watch?v=4ALB5m_Idkk\"></a> 20 </p>\n<p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> Leetcode </p>\n<p><a href=\"https://link.zhihu.com/?target=https://leetcode-cn.com/problems/maximum-subarray/\"></a></p>\n<p><a href=\"https://link.zhihu.com/?target=https://leetcode-cn.com/problems/maximum-subarray/solution/zui-da-zi-xu-he-by-leetcode-solution/\"></a></p>\n<blockquote>\n<p> 1977 Michael Shamos  Shamos 3Shamos  O(<em>n</em>log<em>n)</em> Shamos  Jay Kadane 4 <em>O</em>(<em>n</em>) </p>\n</blockquote>\n<p> Michael Shamos  Jon Bentley </p>\n<p><a href=\"https://link.zhihu.com/?target=https://leetcode-cn.com/problems/linked-list-cycle/\"></a></p>\n<p> Floyd </p>\n<p><a href=\"https://link.zhihu.com/?target=https://leetcode-cn.com/problems/majority-element/\"></a></p>\n<p> Boyer-Moore <a href=\"https://link.zhihu.com/?target=https://www.cs.ou.edu/~rlpage/dmtools/mjrty.pdf\"></a></p>\n<p><a href=\"https://link.zhihu.com/?target=https://leetcode-cn.com/problems/find-the-duplicate-number/\"></a></p>\n<p> O(N) <a href=\"https://link.zhihu.com/?target=https://keithschwarz.com/interesting/code/?dir=find-duplicate\"></a></p>\n<blockquote>\n<p>This problem (reportedly) took CS legend Don Knuth twenty-four hours to solve and I have only met one person (Keith Amling) who could solve it in less time than this.</p>\n</blockquote>\n<p>Don Knuth  24 </p>\n<p> Leetcode invisible  Leetcode  Google Kickstart  <strong> | </strong></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> Leetcode  900    minmax  XXX   XXX  <strong></strong></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><a href=\"https://link.zhihu.com/?target=https://leetcode.com/lee215/\">Lee215</a>  Leetcode  reputation <a href=\"https://link.zhihu.com/?target=https://leetcode.com/cuiaoxiang/\">cuiaoxiang</a>  Leetcode  20 <a href=\"https://link.zhihu.com/?target=https://www.youtube.com/watch?v=ZIhhoFQp8H4&t=1030s\"> Lee215 </a> cuiaoxiang  30  30  cuiaoxiang </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>William Leetcode  12  120 <a href=\"https://link.zhihu.com/?target=https://www.youtube.com/watch?v=-tNMxwWSN_M&t=0s\"></a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<p>If you are not enjoying it, you are doing it wrong.</p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p></p>\n<p>From <a href=\"https://zhuanlan.zhihu.com/p/351560331\">https://zhuanlan.zhihu.com/p/351560331</a></p>\n</blockquote>\n<p> Leetcode 123<a href=\"https://link.zhihu.com/?target=https://www.youtube.com/watch?v=4ALB5m_Idkk\"></a> 20 </p>\n<p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> Leetcode </p>\n<p><a href=\"https://link.zhihu.com/?target=https://leetcode-cn.com/problems/maximum-subarray/\"></a></p>\n<p><a href=\"https://link.zhihu.com/?target=https://leetcode-cn.com/problems/maximum-subarray/solution/zui-da-zi-xu-he-by-leetcode-solution/\"></a></p>\n<blockquote>\n<p> 1977 Michael Shamos  Shamos 3Shamos  O(<em>n</em>log<em>n)</em> Shamos  Jay Kadane 4 <em>O</em>(<em>n</em>) </p>\n</blockquote>\n<p> Michael Shamos  Jon Bentley </p>\n<p><a href=\"https://link.zhihu.com/?target=https://leetcode-cn.com/problems/linked-list-cycle/\"></a></p>\n<p> Floyd </p>\n<p><a href=\"https://link.zhihu.com/?target=https://leetcode-cn.com/problems/majority-element/\"></a></p>\n<p> Boyer-Moore <a href=\"https://link.zhihu.com/?target=https://www.cs.ou.edu/~rlpage/dmtools/mjrty.pdf\"></a></p>\n<p><a href=\"https://link.zhihu.com/?target=https://leetcode-cn.com/problems/find-the-duplicate-number/\"></a></p>\n<p> O(N) <a href=\"https://link.zhihu.com/?target=https://keithschwarz.com/interesting/code/?dir=find-duplicate\"></a></p>\n<blockquote>\n<p>This problem (reportedly) took CS legend Don Knuth twenty-four hours to solve and I have only met one person (Keith Amling) who could solve it in less time than this.</p>\n</blockquote>\n<p>Don Knuth  24 </p>\n<p> Leetcode invisible  Leetcode  Google Kickstart  <strong> | </strong></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p> Leetcode  900    minmax  XXX   XXX  <strong></strong></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><a href=\"https://link.zhihu.com/?target=https://leetcode.com/lee215/\">Lee215</a>  Leetcode  reputation <a href=\"https://link.zhihu.com/?target=https://leetcode.com/cuiaoxiang/\">cuiaoxiang</a>  Leetcode  20 <a href=\"https://link.zhihu.com/?target=https://www.youtube.com/watch?v=ZIhhoFQp8H4&t=1030s\"> Lee215 </a> cuiaoxiang  30  30  cuiaoxiang </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>William Leetcode  12  120 <a href=\"https://link.zhihu.com/?target=https://www.youtube.com/watch?v=-tNMxwWSN_M&t=0s\"></a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<p>If you are not enjoying it, you are doing it wrong.</p>\n"},{"title":"","toc":true,"mathjax":true,"top":false,"cover":true,"date":"2021-03-02T10:50:09.000Z","updated":"2021-04-02T02:53:21.397Z","_content":"\nblog\n\n> Desultory :  going constantly from one subject to another in a halfhearted way \n\n\n\n> \n>\n> \n\n[](https://yonglezh.github.io/2017/01/21/doublethink/)4\n\n>1. \n>2. \n>3. \n>4.  \n\n34\n\n\n\nOJOJ4API AC\n\n\n\n\n\n[](https://mp.weixin.qq.com/s/EjPk_1csVjxQFr9PWJABxQ)****\n\n> 52010\n>\n> \n>\n> ****\n\n\n\n \n\n43Blue1Brown\n\n> \n>\n> \n\n\n\n\n\n\n\n \n\nHR\n\noffer\n\n****","source":"_posts/.md","raw":"---\ntitle: \ntoc: true\nmathjax: true\ntop: false\ncover: true\ndate: 2021-03-02 18:50:09\nupdated:\ncategories: \ntags:\n\t- \n\t- \n\t- \n---\n\nblog\n\n> Desultory :  going constantly from one subject to another in a halfhearted way \n\n\n\n> \n>\n> \n\n[](https://yonglezh.github.io/2017/01/21/doublethink/)4\n\n>1. \n>2. \n>3. \n>4.  \n\n34\n\n\n\nOJOJ4API AC\n\n\n\n\n\n[](https://mp.weixin.qq.com/s/EjPk_1csVjxQFr9PWJABxQ)****\n\n> 52010\n>\n> \n>\n> ****\n\n\n\n \n\n43Blue1Brown\n\n> \n>\n> \n\n\n\n\n\n\n\n \n\nHR\n\noffer\n\n****","slug":"","published":1,"comments":1,"layout":"post","photos":[],"link":"","_id":"ckowlff59001bye28ctkqepy1","content":"<p>blog</p>\n<blockquote>\n<p>Desultory :  going constantly from one subject to another in a halfhearted way </p>\n</blockquote>\n<p></p>\n<blockquote>\n<p></p>\n<p></p>\n</blockquote>\n<p><a href=\"https://yonglezh.github.io/2017/01/21/doublethink/\"></a>4</p>\n<blockquote>\n<ol>\n<li></li>\n<li></li>\n<li></li>\n<li> </li>\n</ol>\n</blockquote>\n<p>34</p>\n<p></p>\n<p>OJOJ4API AC</p>\n<p></p>\n<p></p>\n<p><a href=\"https://mp.weixin.qq.com/s/EjPk_1csVjxQFr9PWJABxQ\"></a><strong></strong></p>\n<blockquote>\n<p>52010</p>\n<p></p>\n<p><strong></strong></p>\n</blockquote>\n<p></p>\n<p> </p>\n<p>43Blue1Brown</p>\n<blockquote>\n<p></p>\n<p></p>\n</blockquote>\n<p></p>\n<p></p>\n<p></p>\n<p> </p>\n<p>HR</p>\n<p>offer</p>\n<p><strong></strong></p>\n","site":{"data":{}},"excerpt":"","more":"<p>blog</p>\n<blockquote>\n<p>Desultory :  going constantly from one subject to another in a halfhearted way </p>\n</blockquote>\n<p></p>\n<blockquote>\n<p></p>\n<p></p>\n</blockquote>\n<p><a href=\"https://yonglezh.github.io/2017/01/21/doublethink/\"></a>4</p>\n<blockquote>\n<ol>\n<li></li>\n<li></li>\n<li></li>\n<li> </li>\n</ol>\n</blockquote>\n<p>34</p>\n<p></p>\n<p>OJOJ4API AC</p>\n<p></p>\n<p></p>\n<p><a href=\"https://mp.weixin.qq.com/s/EjPk_1csVjxQFr9PWJABxQ\"></a><strong></strong></p>\n<blockquote>\n<p>52010</p>\n<p></p>\n<p><strong></strong></p>\n</blockquote>\n<p></p>\n<p> </p>\n<p>43Blue1Brown</p>\n<blockquote>\n<p></p>\n<p></p>\n</blockquote>\n<p></p>\n<p></p>\n<p></p>\n<p> </p>\n<p>HR</p>\n<p>offer</p>\n<p><strong></strong></p>\n"}],"PostAsset":[{"_id":"source/_posts/my-first-blog/Euphonium_Movie_2nd_KV.jpg","slug":"Euphonium_Movie_2nd_KV.jpg","post":"ckg7qjivj00037j28eqt5h8o6","modified":0,"renderable":0},{"_id":"source/_posts/my-first-blog/Euphonium_Movie_Finale_KV2.jpg","slug":"Euphonium_Movie_Finale_KV2.jpg","post":"ckg7qjivj00037j28eqt5h8o6","modified":0,"renderable":0},{"_id":"source/_posts/my-first-blog/relife-1.png","slug":"relife-1.png","post":"ckg7qjivj00037j28eqt5h8o6","modified":0,"renderable":0},{"_id":"source/_posts/my-first-blog/relife-2.jpg","slug":"relife-2.jpg","post":"ckg7qjivj00037j28eqt5h8o6","modified":0,"renderable":0},{"_id":"source/_posts//2020-07-31.jpg","slug":"2020-07-31.jpg","post":"ckgt6w3by0000wx280fap2hbl","modified":0,"renderable":0},{"_id":"source/_posts//IMG_9373.jpeg","slug":"IMG_9373.jpeg","post":"ckgt6w3by0000wx280fap2hbl","modified":0,"renderable":0},{"_id":"source/_posts/LeetCode-33-Search-in-Rotated-Sorted-Array/img1.png","slug":"img1.png","post":"ckhlu9lv60000w328appuchpc","modified":0,"renderable":0},{"_id":"source/_posts/LeetCode-33-Search-in-Rotated-Sorted-Array/img2.jpg","slug":"img2.jpg","post":"ckhlu9lv60000w328appuchpc","modified":0,"renderable":0},{"_id":"source/_posts/LeetCode-33-Search-in-Rotated-Sorted-Array/img3.jpg","slug":"img3.jpg","post":"ckhlu9lv60000w328appuchpc","modified":0,"renderable":0},{"_id":"source/_posts/LeetCode-33-Search-in-Rotated-Sorted-Array/img6.jpg","slug":"img6.jpg","post":"ckhlu9lv60000w328appuchpc","modified":0,"renderable":0},{"_id":"source/_posts/LeetCode-33-Search-in-Rotated-Sorted-Array/img7.jpg","slug":"img7.jpg","post":"ckhlu9lv60000w328appuchpc","modified":0,"renderable":0},{"_id":"source/_posts/LeetCode-33-Search-in-Rotated-Sorted-Array/img8.jpg","slug":"img8.jpg","post":"ckhlu9lv60000w328appuchpc","modified":0,"renderable":0},{"_id":"source/_posts/-/1.jpeg","slug":"1.jpeg","post":"ckhvqydbn00006z28dot614mu","modified":0,"renderable":0},{"_id":"source/_posts/-/2.jpeg","slug":"2.jpeg","post":"ckhvqydbn00006z28dot614mu","modified":0,"renderable":0},{"_id":"source/_posts/GPU-in-Pytorch-/1.png","slug":"1.png","post":"ckhyotdja0000l9289pxq20m8","modified":0,"renderable":0},{"_id":"source/_posts/132-Palindrome-Partitioning-II/1.png","slug":"1.png","post":"ckisn8crf0000vy28agpvc03h","modified":0,"renderable":0},{"_id":"source/_posts/132-Palindrome-Partitioning-II/2.png","slug":"2.png","post":"ckisn8crf0000vy28agpvc03h","modified":0,"renderable":0},{"_id":"source/_posts/132-Palindrome-Partitioning-II/3.png","slug":"3.png","post":"ckisn8crf0000vy28agpvc03h","modified":0,"renderable":0},{"_id":"source/_posts/132-Palindrome-Partitioning-II/4.png","slug":"4.png","post":"ckisn8crf0000vy28agpvc03h","modified":0,"renderable":0}],"PostCategory":[{"post_id":"ckg7lu78w0001bz2813ba5wh9","category_id":"ckg7piwa500006a2813an1zrb","_id":"ckg7piwa700016a285sew2411"},{"post_id":"ckg7qjivj00037j28eqt5h8o6","category_id":"ckg7qrrd000047j280hei7e4u","_id":"ckg7qrrd200077j2815sh1w8k"},{"post_id":"ckgt6w3by0000wx280fap2hbl","category_id":"ckg7qrrd000047j280hei7e4u","_id":"ckgt6w3c20002wx28byyididl"},{"post_id":"ckh35zvbu0000u7282nma27nl","category_id":"ckh35zvby0001u72804px1qo7","_id":"ckh35zvc10004u7286ara9hbw"},{"post_id":"ckhlu9lv60000w328appuchpc","category_id":"ckhlubjrc0000y9282so58qf8","_id":"ckhludw3200011e288weserfg"},{"post_id":"ckhvqydbn00006z28dot614mu","category_id":"ckhvqydbp00016z281mnxdhf3","_id":"ckhvqydbs00046z28hojpcuoy"},{"post_id":"ckhyotdja0000l9289pxq20m8","category_id":"ckhyotdje0002l928gyqa3gxs","_id":"ckhyotdji0006l928chmj50lm"},{"post_id":"ckiedp6df0000ue287z2u4kkg","category_id":"ckg7qrrd000047j280hei7e4u","_id":"ckiedp6dh0003ue28bxwgcd1k"},{"post_id":"ckiijvpg20000ce28c4jz8x92","category_id":"ckhvqydbp00016z281mnxdhf3","_id":"ckiioltfh0002mm281hyw65zr"},{"post_id":"ckisn8crf0000vy28agpvc03h","category_id":"ckhvqydbp00016z281mnxdhf3","_id":"ckisn8crr0003vy28b4m3ence"},{"post_id":"ckipop2xt0000ej28e6qn6mng","category_id":"ckhvqydbp00016z281mnxdhf3","_id":"ckisn8crs0005vy281q3i35ba"},{"post_id":"ckjb842170000pl28gqvdaaxk","category_id":"ckhvqydbp00016z281mnxdhf3","_id":"ckjb842180003pl28dfq44609"},{"post_id":"ckowlff4h0000ye2852873zj8","category_id":"ckg7qrrd000047j280hei7e4u","_id":"ckowlff4q0006ye2899dwgjcm"},{"post_id":"ckowlff4j0001ye28a2r33w49","category_id":"ckg7qrrd000047j280hei7e4u","_id":"ckowlff4r0008ye280z2g1w0d"},{"post_id":"ckowlff4o0003ye289kzd8aq8","category_id":"ckg7qrrd000047j280hei7e4u","_id":"ckowlff4s000cye285m277t5t"},{"post_id":"ckowlff4p0005ye28hvhw7t2d","category_id":"ckhvqydbp00016z281mnxdhf3","_id":"ckowlff4t000fye285lkdef1y"},{"post_id":"ckowlff4q0007ye28ellm242s","category_id":"ckhvqydbp00016z281mnxdhf3","_id":"ckowlff4u000jye287m7v3hgy"},{"post_id":"ckowlff4s000eye28dd924rjd","category_id":"ckhvqydbp00016z281mnxdhf3","_id":"ckowlff4y000oye2880aweale"},{"post_id":"ckowlff4u000iye288xs01w1p","category_id":"ckg7qrrd000047j280hei7e4u","_id":"ckowlff50000rye281yobgjd6"},{"post_id":"ckowlff4u000lye28c1bi3rap","category_id":"ckg7qrrd000047j280hei7e4u","_id":"ckowlff50000tye28bgo54k6g"},{"post_id":"ckowlff4x000nye2839rj25e2","category_id":"ckg7qrrd000047j280hei7e4u","_id":"ckowlff51000wye280o1o6xv3"},{"post_id":"ckowlff560018ye28068hhosu","category_id":"ckhvqydbp00016z281mnxdhf3","_id":"ckowlff5a001cye282x2988xk"},{"post_id":"ckowlff59001bye28ctkqepy1","category_id":"ckg7qrrd000047j280hei7e4u","_id":"ckowlff5d001fye28e2qn0xgw"}],"PostTag":[{"post_id":"ckg7lu78w0001bz2813ba5wh9","tag_id":"ckg7piagr00003v286tc5gsox","_id":"ckg7piagv00013v284nc01o56"},{"post_id":"ckg7qjivj00037j28eqt5h8o6","tag_id":"ckg7qrrd100057j289azi5q0k","_id":"ckg7qrrd100067j285lt81jqx"},{"post_id":"ckgt6w3by0000wx280fap2hbl","tag_id":"ckg7qrrd100057j289azi5q0k","_id":"ckgt6w3c10001wx28eo595uf9"},{"post_id":"ckh35zvbu0000u7282nma27nl","tag_id":"ckh35zvc00002u728a8q656mh","_id":"ckh35zvc20007u728fve34h0a"},{"post_id":"ckh35zvbu0000u7282nma27nl","tag_id":"ckh35zvc10003u7282616cu2s","_id":"ckh35zvc20008u7288k0q907w"},{"post_id":"ckh35zvbu0000u7282nma27nl","tag_id":"ckh35zvc10005u7281p3i2ffq","_id":"ckh35zvc20009u728720xdpaf"},{"post_id":"ckh35zvbu0000u7282nma27nl","tag_id":"ckh35zvc20006u7284k31d8oe","_id":"ckh35zvc2000au728gaocav7r"},{"post_id":"ckhlu9lv60000w328appuchpc","tag_id":"ckhlubjrc0001y928d4gv9u9l","_id":"ckhlubjrd0002y928dmdedxmp"},{"post_id":"ckhlu9lv60000w328appuchpc","tag_id":"ckhlue30200021e28486k1p79","_id":"ckhlue30300031e285vhycy46"},{"post_id":"ckhvqydbn00006z28dot614mu","tag_id":"ckhvqydbr00026z288h0ue571","_id":"ckhvqydbs00056z28fvjve3ff"},{"post_id":"ckhvqydbn00006z28dot614mu","tag_id":"ckhvqydbr00036z28g66r7hsq","_id":"ckhvqydbs00066z287q3d8g0m"},{"post_id":"ckhyotdja0000l9289pxq20m8","tag_id":"ckhyotdjg0003l928djuaby6g","_id":"ckhyotdjj000al928fghx5blk"},{"post_id":"ckhyotdja0000l9289pxq20m8","tag_id":"ckhyotdjh0005l928hv1rcwfl","_id":"ckhyotdjj000bl9280y7t97t2"},{"post_id":"ckhyotdja0000l9289pxq20m8","tag_id":"ckhyotdjj0007l928cxr4e0vg","_id":"ckhyotdjk000dl9284vfag7vy"},{"post_id":"ckiedp6df0000ue287z2u4kkg","tag_id":"ckhvqydbr00026z288h0ue571","_id":"ckiedp6dh0001ue28glzp1ror"},{"post_id":"ckiedp6df0000ue287z2u4kkg","tag_id":"ckhlue30200021e28486k1p79","_id":"ckiedp6dh0002ue28cbft5tkf"},{"post_id":"ckiedp6df0000ue287z2u4kkg","tag_id":"ckg7qrrd100057j289azi5q0k","_id":"ckiedp6dh0004ue2829v986c9"},{"post_id":"ckiijvpg20000ce28c4jz8x92","tag_id":"ckhvqydbr00026z288h0ue571","_id":"ckiioltfc0000mm28gddsbz0v"},{"post_id":"ckiijvpg20000ce28c4jz8x92","tag_id":"ckhlue30200021e28486k1p79","_id":"ckiioltfh0001mm2839g48sbz"},{"post_id":"ckisn8crf0000vy28agpvc03h","tag_id":"ckhvqydbr00026z288h0ue571","_id":"ckisn8crq0001vy282horerud"},{"post_id":"ckisn8crf0000vy28agpvc03h","tag_id":"ckhlue30200021e28486k1p79","_id":"ckisn8crr0002vy28a7ljcfyd"},{"post_id":"ckipop2xt0000ej28e6qn6mng","tag_id":"ckhvqydbr00026z288h0ue571","_id":"ckisn8crr0004vy287usp93bl"},{"post_id":"ckipop2xt0000ej28e6qn6mng","tag_id":"ckhlue30200021e28486k1p79","_id":"ckisn8crt0006vy2851tb3tdp"},{"post_id":"ckjb842170000pl28gqvdaaxk","tag_id":"ckhvqydbr00026z288h0ue571","_id":"ckjb842180001pl28212r6fpn"},{"post_id":"ckjb842170000pl28gqvdaaxk","tag_id":"ckhvqydbr00036z28g66r7hsq","_id":"ckjb842180002pl282e3rgz6c"},{"post_id":"ckowlff4j0001ye28a2r33w49","tag_id":"ckg7qrrd100057j289azi5q0k","_id":"ckowlff4p0004ye288z23440a"},{"post_id":"ckowlff4p0005ye28hvhw7t2d","tag_id":"ckhvqydbr00026z288h0ue571","_id":"ckowlff4r000aye284sbifesn"},{"post_id":"ckowlff4p0005ye28hvhw7t2d","tag_id":"ckhlue30200021e28486k1p79","_id":"ckowlff4s000dye28f4db6bcg"},{"post_id":"ckowlff4h0000ye2852873zj8","tag_id":"ckg7qrrd100057j289azi5q0k","_id":"ckowlff4u000hye289zli0c2z"},{"post_id":"ckowlff4h0000ye2852873zj8","tag_id":"ckowlff4l0002ye285qyw7hji","_id":"ckowlff4u000kye288jlk6h1h"},{"post_id":"ckowlff4q0007ye28ellm242s","tag_id":"ckhvqydbr00026z288h0ue571","_id":"ckowlff4w000mye28hrxgdf0r"},{"post_id":"ckowlff4q0007ye28ellm242s","tag_id":"ckhlue30200021e28486k1p79","_id":"ckowlff4z000qye284q1ag6zr"},{"post_id":"ckowlff4s000eye28dd924rjd","tag_id":"ckhvqydbr00026z288h0ue571","_id":"ckowlff50000sye282f1h4tb3"},{"post_id":"ckowlff4s000eye28dd924rjd","tag_id":"ckhlue30200021e28486k1p79","_id":"ckowlff50000uye288s6m6m5k"},{"post_id":"ckowlff4u000iye288xs01w1p","tag_id":"ckg7qrrd100057j289azi5q0k","_id":"ckowlff51000xye283qmk4419"},{"post_id":"ckowlff4o0003ye289kzd8aq8","tag_id":"ckg7qrrd100057j289azi5q0k","_id":"ckowlff51000yye284wls22og"},{"post_id":"ckowlff4o0003ye289kzd8aq8","tag_id":"ckowlff4r0009ye28502fahz6","_id":"ckowlff510010ye28c7fzh7aq"},{"post_id":"ckowlff4o0003ye289kzd8aq8","tag_id":"ckowlff4t000gye28fwmgcem9","_id":"ckowlff510011ye284b0aejg1"},{"post_id":"ckowlff4u000lye28c1bi3rap","tag_id":"ckg7qrrd100057j289azi5q0k","_id":"ckowlff520012ye28edbvb49e"},{"post_id":"ckowlff4u000lye28c1bi3rap","tag_id":"ckowlff4z000pye288tmjhtsj","_id":"ckowlff520013ye2887cs46ih"},{"post_id":"ckowlff4x000nye2839rj25e2","tag_id":"ckg7qrrd100057j289azi5q0k","_id":"ckowlff520014ye289k9la1zz"},{"post_id":"ckowlff4x000nye2839rj25e2","tag_id":"ckowlff4r0009ye28502fahz6","_id":"ckowlff520015ye287s3bbbek"},{"post_id":"ckowlff4x000nye2839rj25e2","tag_id":"ckowlff50000vye287pdpgozk","_id":"ckowlff520016ye284pb70suy"},{"post_id":"ckowlff4x000nye2839rj25e2","tag_id":"ckowlff51000zye2856h8flno","_id":"ckowlff530017ye28ftem3fcn"},{"post_id":"ckowlff560018ye28068hhosu","tag_id":"ckhvqydbr00026z288h0ue571","_id":"ckowlff580019ye2897f041k8"},{"post_id":"ckowlff560018ye28068hhosu","tag_id":"ckhlue30200021e28486k1p79","_id":"ckowlff59001aye2836zbg8fp"},{"post_id":"ckowlff59001bye28ctkqepy1","tag_id":"ckg7qrrd100057j289azi5q0k","_id":"ckowlff5c001dye280e5jd13y"},{"post_id":"ckowlff59001bye28ctkqepy1","tag_id":"ckowlff4r0009ye28502fahz6","_id":"ckowlff5d001eye282xkmf3qf"},{"post_id":"ckowlff59001bye28ctkqepy1","tag_id":"ckowlff4l0002ye285qyw7hji","_id":"ckowlff5d001gye28dfakhfcf"}],"Tag":[{"name":"test","_id":"ckg7piagr00003v286tc5gsox"},{"name":"","_id":"ckg7qrrd100057j289azi5q0k"},{"name":"ubuntu","_id":"ckh35zvc00002u728a8q656mh"},{"name":"","_id":"ckh35zvc10003u7282616cu2s"},{"name":"linux","_id":"ckh35zvc10005u7281p3i2ffq"},{"name":"grub","_id":"ckh35zvc20006u7284k31d8oe"},{"name":"-Algorithm","_id":"ckhlu9lvk0002w328hz4x9glf"},{"name":"Algorithm","_id":"ckhlubjrc0001y928d4gv9u9l"},{"name":"LeetCode","_id":"ckhlue30200021e28486k1p79"},{"name":"Algorithms","_id":"ckhvqydbr00026z288h0ue571"},{"name":"OS","_id":"ckhvqydbr00036z28g66r7hsq"},{"name":"Pytorch","_id":"ckhyotdjg0003l928djuaby6g"},{"name":"CUDA","_id":"ckhyotdjh0005l928hv1rcwfl"},{"name":"GPU","_id":"ckhyotdjj0007l928cxr4e0vg"},{"name":"NLP","_id":"ckhyotdjj000cl928cahc99hr"},{"name":"","_id":"ckowlff4l0002ye285qyw7hji"},{"name":"","_id":"ckowlff4r0009ye28502fahz6"},{"name":"","_id":"ckowlff4t000gye28fwmgcem9"},{"name":"1984","_id":"ckowlff4z000pye288tmjhtsj"},{"name":"","_id":"ckowlff50000vye287pdpgozk"},{"name":"","_id":"ckowlff51000zye2856h8flno"}]}}